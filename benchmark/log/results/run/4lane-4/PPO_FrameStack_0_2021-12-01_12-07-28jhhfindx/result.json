{"episode_reward_max": 402.5991356417633, "episode_reward_min": -417.4941851412999, "episode_reward_mean": 108.50011147976844, "episode_len_mean": 105.54054054054055, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-1": -108.12719352080205, "AGENT-0": -98.58506899834946, "AGENT-2": -98.52995903879659, "AGENT-3": -157.51992861280337}, "policy_reward_max": {"AGENT-1": -9.679817274559083, "AGENT-0": 227.09743101955092, "AGENT-2": 10.96174656614508, "AGENT-3": 203.51004006125424}, "policy_reward_mean": {"AGENT-1": -49.433491694371895, "AGENT-0": 90.9042813762955, "AGENT-2": -47.090159973697, "AGENT-3": 114.11948177154183}, "custom_metrics": {"mean_ego_speed_mean": 39.91947972972973, "mean_ego_speed_min": 25.9035, "mean_ego_speed_max": 45.05875, "distance_travelled_mean": 56.88918918918919, "distance_travelled_min": 42.28575, "distance_travelled_max": 62.09425}, "hist_stats": {"episode_reward": [283.4713184311275, 148.27539436409273, 282.7067399079913, -41.33210088016703, -47.63718524062186, -35.688347625375144, 200.8878333185744, -52.55530562293786, 307.17410720280867, -25.97704892884715, 263.3477922159757, -85.59473736872114, 295.26208666570164, -35.357436401464014, 402.5991356417633, 47.51422572720596, 345.5567425520096, -12.038740907070448, 352.2417284961287, -68.50728890969049, 325.95427209448223, 17.110820785674463, 229.5053134652256, -417.4941851412999, 197.7976193966663, -10.57656399868035, 242.28128060418084, -42.651802878994026, 230.79618180946184, -3.7632090950586665, 359.4827255467255, -357.26378603398183, 319.0920612802059, -31.88930844218968, 292.1193361544912, -172.15371032396502, 311.808166890003], "episode_lengths": [104, 134, 103, 113, 87, 105, 101, 107, 106, 102, 104, 104, 107, 99, 105, 96, 124, 107, 113, 102, 112, 112, 106, 85, 103, 109, 107, 107, 105, 99, 94, 89, 114, 120, 111, 98, 111], "policy_AGENT-1_reward": [-11.555308932197832, -90.26252200178823, -13.004103491739933, -94.18009916440111, -12.98321890315905, -87.96455550137566, -14.275634600515856, -87.25442644490343, -10.913837106578281, -87.98621622610976, -10.919141960519475, -88.73584985987276, -10.659969027386104, -86.5151018412686, -9.836215485797089, -89.12814657703177, -11.197405473406578, -83.31288117373362, -9.679817274559083, -84.75448093715741, -10.737794541804744, -86.30982549490884, -11.98574375028166, -98.60275842192655, -11.844558962772084, -84.90082626673095, -10.371333654720399, -88.87249203215714, -10.562951439806703, -88.5842886367012, -10.156921186833511, -108.12719352080205, -13.819206222574538, -88.70025761072141, -11.441926714391355, -87.42883467283174, -11.473347578293502], "policy_AGENT-0_reward": [135.33334072643447, 147.55241671411795, 135.97112690481845, 54.925748484993505, -13.164485238724074, 51.87974323570437, 93.84268328312127, 41.32413339133328, 146.40729949214767, 56.726658946539914, 124.36654135343281, 25.75620604918715, 140.47348951860997, 50.50658926481228, 227.09743101955092, 128.3680412710871, 166.02980798191138, 57.16042274023653, 168.0952111713765, 30.041601593993704, 156.19470827158509, 77.18570424440928, 106.3904967453471, -98.58506899834946, 90.08894615888829, 60.4509086354661, 112.40924069746843, 47.369454368020975, 105.66437333327471, 99.57288889709724, 205.33628716592014, -45.81165851137316, 155.49787730369786, 55.86707891410484, 138.5492559211073, -20.890347783019262, 149.47425765460304], "policy_AGENT-2_reward": [-11.620059906210077, -90.40226705385419, -12.918607981575162, -94.10900629954972, 10.96174656614508, -87.9477650167239, -14.150796246347065, -87.22787395792542, -10.862859391283749, -87.958113249907, -10.886861132093188, -88.57065751000559, -10.64349153295588, -86.62226602871075, -9.84213066446401, -89.06205822097232, -11.179042455846611, -83.37756941491054, -9.683705461942967, -84.75620330560217, -10.709787767332283, -86.28219091419558, -12.013883473587267, -98.52995903879659, -11.794528413056069, -84.93890979341556, -10.39828492825429, -88.82663429534742, -10.563473363442746, -88.57701932973767, -10.169378497195352, -45.80500538900323, -13.741901256465898, -88.72434308605213, -11.521096255572106, -87.44507024845358, -11.434864712145922], "policy_AGENT-3_reward": [171.31334654310095, 181.38776670561734, 172.65832447648782, 92.0312560987905, -32.45122766488383, 88.34422965701984, 135.47158088231595, 80.60286138855761, 182.5435042085229, 93.24062160062982, 160.78725395515553, 65.95556395197022, 176.09205770743367, 87.27334220370298, 195.18005077247338, 97.33638925412305, 201.9033824993515, 97.49128694133704, 203.51004006125424, 70.96179373907549, 191.2071461320342, 112.5171329503695, 147.11444394374726, -121.77639868222701, 131.34776061360648, 98.8122634260003, 150.6416584896871, 87.67786908048944, 146.25823327943672, 73.82520997428291, 174.472738064834, -157.51992861280337, 191.15529145554848, 89.66821334047928, 176.5331032033475, 23.61054238033971, 185.24212152583942]}, "sampler_perf": {"mean_env_wait_ms": 29.943859300086626, "mean_processing_ms": 2.02485115282001, "mean_inference_ms": 1.3954479138394114}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4000, "timers": {"sample_time_ms": 133639.571, "sample_throughput": 29.931, "load_time_ms": 807.588, "load_throughput": 4953.019, "learn_time_ms": 7008.874, "learn_throughput": 570.705, "update_time_ms": 5.442}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 34.02126693725586, "policy_loss": -0.013153113424777985, "vf_loss": 34.03334426879883, "vf_explained_var": 0.3772822916507721, "kl": 0.005356865003705025, "entropy": 1.3807815313339233, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 64.75053405761719, "policy_loss": -0.019855283200740814, "vf_loss": 64.7685775756836, "vf_explained_var": 0.2708289623260498, "kl": 0.00910306628793478, "entropy": 1.3771263360977173, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 67.0317611694336, "policy_loss": -0.025298506021499634, "vf_loss": 67.05536651611328, "vf_explained_var": 0.2442789077758789, "kl": 0.008505252189934254, "entropy": 1.3776382207870483, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 30.358800888061523, "policy_loss": -0.02217101864516735, "vf_loss": 30.379724502563477, "vf_explained_var": 0.5091757774353027, "kl": 0.006247921381145716, "entropy": 1.3799995183944702, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 4000, "num_steps_trained": 4000}, "done": false, "episodes_total": 37, "training_iteration": 1, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-11-42", "timestamp": 1638378702, "time_this_iter_s": 143.8724663257599, "time_total_s": 143.8724663257599, "pid": 51784, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b802b69e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b802b6560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2950>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b802d28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2c20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2950>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b802d28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2c20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2950>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b802d28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2c20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2950>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b802d28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b802d2c20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f9b80265b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 143.8724663257599, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 17.203398058252425, "ram_util_percent": 49.034466019417486}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 443.1728967063256, "episode_reward_min": -417.4941851412999, "episode_reward_mean": 121.31022080048321, "episode_len_mean": 108.02702702702703, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-0": -98.58506899834946, "AGENT-2": -98.52995903879659, "AGENT-3": -157.51992861280337, "AGENT-1": -108.12719352080205}, "policy_reward_max": {"AGENT-0": 227.12036255917783, "AGENT-2": 10.96174656614508, "AGENT-3": 249.2059944295345, "AGENT-1": -9.025194518278632}, "policy_reward_mean": {"AGENT-0": 98.44878234624815, "AGENT-2": -48.52130480605789, "AGENT-3": 121.32955566977189, "AGENT-1": -49.946812409478895}, "custom_metrics": {"mean_ego_speed_mean": 39.79916554054055, "mean_ego_speed_min": 25.9035, "mean_ego_speed_max": 45.64025, "distance_travelled_mean": 57.56787162162162, "distance_travelled_min": 42.28575, "distance_travelled_max": 62.09425}, "hist_stats": {"episode_reward": [-41.06990112593471, 308.13711770262864, 90.49017517292096, 363.39922054415376, -49.907621583885025, 259.55196331988503, -45.388882469910456, 443.1728967063256, -10.570492978895196, 251.81006906812095, 2.399387498997541, 368.189714842348, 22.5721986124371, 236.043181515539, 9.836096539354925, 233.5443987245829, -29.70220085388268, 326.7723839972328, 45.29235324902137, -64.92181863288485, -2.880200625211657, 261.1062716522187, -164.63976267147768, 401.4734328702189, 95.07111670060252, 256.9995951634878, -74.12182098201848, 309.1828422853047, -65.78721461685244, 229.01730457774667, 46.81261714726852, 344.05383689175034, 14.084671960332734, 309.28504502459714, -41.454195464681284, 288.8452916775794, 35.7531430453045, 283.4713184311275, 148.27539436409273, 282.7067399079913, -41.33210088016703, -47.63718524062186, -35.688347625375144, 200.8878333185744, -52.55530562293786, 307.17410720280867, -25.97704892884715, 263.3477922159757, -85.59473736872114, 295.26208666570164, -35.357436401464014, 402.5991356417633, 47.51422572720596, 345.5567425520096, -12.038740907070448, 352.2417284961287, -68.50728890969049, 325.95427209448223, 17.110820785674463, 229.5053134652256, -417.4941851412999, 197.7976193966663, -10.57656399868035, 242.28128060418084, -42.651802878994026, 230.79618180946184, -3.7632090950586665, 359.4827255467255, -357.26378603398183, 319.0920612802059, -31.88930844218968, 292.1193361544912, -172.15371032396502, 311.808166890003], "episode_lengths": [101, 109, 124, 115, 109, 109, 108, 140, 115, 111, 130, 135, 114, 109, 102, 113, 102, 120, 116, 87, 95, 108, 100, 112, 106, 110, 110, 104, 103, 106, 109, 93, 117, 110, 109, 106, 122, 104, 134, 103, 113, 87, 105, 101, 107, 106, 102, 104, 104, 107, 99, 105, 96, 124, 107, 113, 102, 112, 112, 106, 85, 103, 109, 107, 107, 105, 99, 94, 89, 114, 120, 111, 98, 111], "policy_AGENT-0_reward": [53.305440924706154, 146.83899135202, 152.64116789709232, 172.4706974683437, 45.105269326212806, 121.51503414923873, 44.22715011335256, 214.18847131841125, 65.80080099795484, 117.01700910745546, 70.7342258011943, 177.59593746472427, 78.67016727429771, 112.84785688085441, 115.45185005992174, 111.04448733073846, 48.024713556885445, 156.4740547931444, 87.39163921165564, -13.722042227341243, 99.11936962594112, 121.74435696216995, -14.972421337852381, 227.12036255917783, 152.27653446185712, 120.2821018960121, 34.952487232995466, 147.04669238632724, 33.17945769781659, 105.24922389587198, 126.8232289911563, 197.62178326142336, 77.922066189323, 147.72899120195703, 43.71076819467039, 138.291040740462, 86.03251593925681, 135.33334072643447, 147.55241671411795, 135.97112690481845, 54.925748484993505, -13.164485238724074, 51.87974323570437, 93.84268328312127, 41.32413339133328, 146.40729949214767, 56.726658946539914, 124.36654135343281, 25.75620604918715, 140.47348951860997, 50.50658926481228, 227.09743101955092, 128.3680412710871, 166.02980798191138, 57.16042274023653, 168.0952111713765, 30.041601593993704, 156.19470827158509, 77.18570424440928, 106.3904967453471, -98.58506899834946, 90.08894615888829, 60.4509086354661, 112.40924069746843, 47.369454368020975, 105.66437333327471, 99.57288889709724, 205.33628716592014, -45.81165851137316, 155.49787730369786, 55.86707891410484, 138.5492559211073, -20.890347783019262, 149.47425765460304], "policy_AGENT-2_reward": [-91.92834661008028, -10.808503990687363, -89.7970346754982, -9.053379740952014, -89.2734644839656, -10.962480579952567, -86.6540414855707, -10.13376565632454, -88.49454189764074, -10.69213756720447, -86.55803615195585, -10.46728462423427, -85.93099307809636, -13.983986062121545, -95.96921319953981, -13.275557757594376, -81.7433037417563, -10.393457528645063, -82.69880919554217, 5.599207665551913, -87.41874277946901, -10.826964912570975, -89.38798761837555, -11.082066323566643, -89.02017166490577, -11.357631812446629, -91.12796085292251, -10.4277229697569, -86.65771157953944, -10.511853008075152, -87.35602158700692, -10.382449587374495, -87.26590602416562, -10.835971774143285, -83.84313521109591, -11.906566445935313, -85.61264210833443, -11.620059906210077, -90.40226705385419, -12.918607981575162, -94.10900629954972, 10.96174656614508, -87.9477650167239, -14.150796246347065, -87.22787395792542, -10.862859391283749, -87.958113249907, -10.886861132093188, -88.57065751000559, -10.64349153295588, -86.62226602871075, -9.84213066446401, -89.06205822097232, -11.179042455846611, -83.37756941491054, -9.683705461942967, -84.75620330560217, -10.709787767332283, -86.28219091419558, -12.013883473587267, -98.52995903879659, -11.794528413056069, -84.93890979341556, -10.39828492825429, -88.82663429534742, -10.563473363442746, -88.57701932973767, -10.169378497195352, -45.80500538900323, -13.741901256465898, -88.72434308605213, -11.521096255572106, -87.44507024845358, -11.434864712145922], "policy_AGENT-3_reward": [89.49833511106095, 182.82204920618258, 117.51314232909817, 209.00709733504084, 83.5510879422955, 159.8743596412638, 83.70076055860112, 249.2059944295345, 100.6991089842524, 156.04183791496365, 104.76077732230428, 211.42235617044818, 115.76890503756526, 151.1710367253978, 86.47126381584323, 149.072408742216, 85.60031359770329, 191.01639175331312, 123.26169793569132, -43.37539954828291, 72.86183800769507, 161.0838604233139, 29.161974919670186, 196.5317807170469, 120.84561290370965, 159.469472605541, 73.22744194770547, 183.00943396842584, 74.32123580585832, 144.73434664408637, 94.64367444671322, 167.12497598082194, 110.65585455688094, 183.20851721242676, 82.56090890520008, 174.47491558215333, 120.96692438432842, 171.31334654310095, 181.38776670561734, 172.65832447648782, 92.0312560987905, -32.45122766488383, 88.34422965701984, 135.47158088231595, 80.60286138855761, 182.5435042085229, 93.24062160062982, 160.78725395515553, 65.95556395197022, 176.09205770743367, 87.27334220370298, 195.18005077247338, 97.33638925412305, 201.9033824993515, 97.49128694133704, 203.51004006125424, 70.96179373907549, 191.2071461320342, 112.5171329503695, 147.11444394374726, -121.77639868222701, 131.34776061360648, 98.8122634260003, 150.6416584896871, 87.67786908048944, 146.25823327943672, 73.82520997428291, 174.472738064834, -157.51992861280337, 191.15529145554848, 89.66821334047928, 176.5331032033475, 23.61054238033971, 185.24212152583942], "policy_AGENT-1_reward": [-91.9453305516216, -10.715418864886542, -89.86710037777137, -9.025194518278632, -89.29051436842768, -10.874949890664865, -86.66275165629338, -10.087803385295551, -88.57586106346164, -10.556640387093662, -86.53757947254519, -10.361294168590284, -85.93588062132952, -13.991726028591577, -96.11780413687026, -13.296939590777518, -81.58392426671502, -10.324605020579806, -82.66217470278326, -13.423584522812629, -87.44266547937887, -10.894980820694407, -89.4413286349197, -11.096644082439113, -89.03085900005834, -11.394347525618528, -91.17378930979693, -10.44556109969154, -86.63019654098787, -10.454412954136691, -87.298264703594, -10.310472763120544, -87.22734276170556, -10.816491615643107, -83.88273735345575, -12.014098199100646, -85.63365516994635, -11.555308932197832, -90.26252200178823, -13.004103491739933, -94.18009916440111, -12.98321890315905, -87.96455550137566, -14.275634600515856, -87.25442644490343, -10.913837106578281, -87.98621622610976, -10.919141960519475, -88.73584985987276, -10.659969027386104, -86.5151018412686, -9.836215485797089, -89.12814657703177, -11.197405473406578, -83.31288117373362, -9.679817274559083, -84.75448093715741, -10.737794541804744, -86.30982549490884, -11.98574375028166, -98.60275842192655, -11.844558962772084, -84.90082626673095, -10.371333654720399, -88.87249203215714, -10.562951439806703, -88.5842886367012, -10.156921186833511, -108.12719352080205, -13.819206222574538, -88.70025761072141, -11.441926714391355, -87.42883467283174, -11.473347578293502]}, "sampler_perf": {"mean_env_wait_ms": 29.98294921433209, "mean_processing_ms": 2.0348358410372667, "mean_inference_ms": 1.3645584482150976}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8000, "timers": {"sample_time_ms": 133763.824, "sample_throughput": 29.903, "load_time_ms": 409.686, "load_throughput": 9763.579, "learn_time_ms": 6164.977, "learn_throughput": 648.826, "update_time_ms": 5.368}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 30.455665588378906, "policy_loss": -0.016840599477291107, "vf_loss": 30.471153259277344, "vf_explained_var": 0.7032073140144348, "kl": 0.006771950516849756, "entropy": 1.3703081607818604, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 64.33360290527344, "policy_loss": -0.01608981564640999, "vf_loss": 64.34837341308594, "vf_explained_var": 0.4258170425891876, "kl": 0.00660513574257493, "entropy": 1.3694734573364258, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 57.42586135864258, "policy_loss": -0.023273130878806114, "vf_loss": 57.44804763793945, "vf_explained_var": 0.5246532559394836, "kl": 0.005393740721046925, "entropy": 1.3741896152496338, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 27.161344528198242, "policy_loss": -0.02314233034849167, "vf_loss": 27.182998657226562, "vf_explained_var": 0.7536824941635132, "kl": 0.00745715806260705, "entropy": 1.3719607591629028, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 8000, "num_steps_trained": 8000}, "done": false, "episodes_total": 74, "training_iteration": 2, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-14-02", "timestamp": 1638378842, "time_this_iter_s": 139.24515795707703, "time_total_s": 283.1176242828369, "pid": 51784, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b80265ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b8024b050>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b5f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b5f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b5f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8024b5f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f9b802650e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 283.1176242828369, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 16.803030303030305, "ram_util_percent": 49.300000000000004}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 24.014978041846426, "episode_reward_min": -465.714850294071, "episode_reward_mean": -87.57446505973921, "episode_len_mean": 107.4054054054054, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-0": -127.51276278901335, "AGENT-3": -157.48708802715447, "AGENT-2": -105.703408964798, "AGENT-1": -127.56708441667274}, "policy_reward_max": {"AGENT-0": 119.37462628261213, "AGENT-3": 122.97517481504607, "AGENT-2": -57.62267170157351, "AGENT-1": -91.41149917074249}, "policy_reward_mean": {"AGENT-0": 41.54460716425364, "AGENT-3": 64.89310187197417, "AGENT-2": -95.7343239807798, "AGENT-1": -98.27785011518718}, "custom_metrics": {"mean_ego_speed_mean": 38.29717567567567, "mean_ego_speed_min": 30.519750000000002, "mean_ego_speed_max": 47.04625, "distance_travelled_mean": 58.01528378378379, "distance_travelled_min": 53.063, "distance_travelled_max": 61.355}, "hist_stats": {"episode_reward": [2.4518689441714443, -36.28549650659493, -31.742361510132845, -55.96164022864312, -172.65322522966113, -5.141142840620141, -41.108708647181345, -127.25457907729862, 2.0150384328927515, -47.870361754522676, -172.43264903690843, 4.700736094662547, -57.0537007903934, -99.67510162609717, -381.5211039804739, -21.05520382855614, -169.79866452976682, -138.37814912528052, -83.08057135263863, -60.9221633560073, -16.291486129520848, -6.710172823230458, -15.072291674388808, -122.33252915909934, -135.4963161516431, -465.714850294071, -27.23380380322758, -103.97233745217498, -120.49677839008697, 24.014978041846426, -110.72103778728052, -112.93646103620804, -81.05838537411952, -76.35668711330473, -39.610560014505126, -105.03922451864081, -32.460083581644646], "episode_lengths": [121, 123, 109, 104, 105, 87, 112, 115, 91, 108, 102, 107, 111, 109, 92, 99, 102, 107, 112, 109, 122, 123, 108, 114, 106, 85, 119, 96, 108, 116, 103, 105, 103, 116, 106, 106, 113], "policy_AGENT-0_reward": [81.80132143786899, 62.57153838970239, 64.68010910610622, 50.23011555185104, -12.10781633203414, 113.27090348750046, 62.359725284699344, 15.168198225680065, 112.06145741701609, 54.97751408416651, -12.802746469472297, 119.37462628261213, 56.34143390671611, 29.910566719954936, -57.69721842958239, 97.348049556162, -7.466155598900762, 5.296267671833945, 34.60823791374183, 51.932939015047985, 73.73044047963089, 74.28218060572354, 70.44114271392876, 15.070683501771484, 12.386730718468158, -127.51276278901335, 68.66798874370835, 59.32961843077448, 24.64688230661875, 86.876722437355, 18.757192810965513, 14.387104290015934, 38.88863759826422, 47.96000005172796, 56.86467290040531, 23.15960452488021, 57.35455853148902], "policy_AGENT-3_reward": [116.587159618902, 97.09408957195882, 100.70671463118904, 85.8848706967736, 29.040661029961072, 65.82344142537438, 97.82837897653512, 50.09847425570136, 81.86986294397099, 90.81607442141282, 29.124758556606494, 89.16751664560834, 92.0532369649319, 69.18670959299772, -157.48708802715447, 69.66192696261065, 34.33838751706134, 46.00712190011307, 73.17381938194853, 87.85236116634414, 108.86109451829796, 109.33366842292688, 106.63306941902371, 53.639655736810965, 51.3798963574313, -125.80728119381418, 104.31614804826975, 32.228456563321984, 63.12196858778732, 122.97517481504607, 58.82611322984489, 55.61867238765305, 73.57629606937877, 87.26969804179515, 92.42615915240442, 62.52145340758972, 95.29604746642919], "policy_AGENT-2_reward": [-97.95779159095568, -97.97242442071511, -98.54410385844767, -96.04710338455553, -94.83690816766364, -92.1641973906035, -100.63728920400857, -96.23110725906207, -95.93378781896183, -96.85911172743292, -94.38059905746002, -101.88807782685612, -102.68071200340987, -99.41247424682544, -57.62267170157351, -94.09856161200722, -98.3219990536642, -94.83431867840827, -95.46650097922117, -100.33465876721183, -99.40622576116155, -95.15794412379933, -96.04514267309496, -95.50488004384765, -99.56985913109767, -84.82772189457063, -100.11907496116629, -97.76314103068643, -104.07853901060776, -92.94246377128951, -94.13777331911554, -91.53073854313455, -96.7833971758864, -105.703408964798, -94.45456754635379, -95.38176910496838, -92.53894148422994], "policy_AGENT-1_reward": [-97.97882052164371, -97.97870004754122, -98.58508138898031, -96.02952309271231, -94.74916175992439, -92.07129036289138, -100.65952370440748, -96.29014429961782, -95.98249410913256, -96.80483853266887, -94.37406206658244, -101.95332900670198, -102.76765965863143, -99.35990369222469, -108.71412582216345, -93.96661873532157, -98.34889739426305, -94.84722001881909, -95.39612766910805, -100.37280477018787, -99.47679536628803, -95.16807772808151, -96.1013611342461, -95.53798835383391, -99.69308409644509, -127.56708441667274, -100.09886563403931, -97.7672714155851, -104.18709027388525, -92.89445543926516, -94.16657050897524, -91.41149917074249, -96.73992186587603, -105.88297624202981, -94.44682452096094, -95.33851334614224, -92.57174809533288]}, "sampler_perf": {"mean_env_wait_ms": 30.980810765116495, "mean_processing_ms": 2.047518675579366, "mean_inference_ms": 1.436369325541997}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12000, "timers": {"sample_time_ms": 138389.202, "sample_throughput": 28.904, "load_time_ms": 829.835, "load_throughput": 4820.234, "learn_time_ms": 6782.978, "learn_throughput": 589.711, "update_time_ms": 5.437}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 41.41194534301758, "policy_loss": -0.02071615867316723, "vf_loss": 41.43054962158203, "vf_explained_var": 0.80165696144104, "kl": 0.01056875754147768, "entropy": 1.3635125160217285, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 99.44960021972656, "policy_loss": -0.022206958383321762, "vf_loss": 99.47074127197266, "vf_explained_var": 0.13238947093486786, "kl": 0.00538476649671793, "entropy": 1.375593900680542, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 105.3624496459961, "policy_loss": -0.022016039118170738, "vf_loss": 105.3832015991211, "vf_explained_var": 0.21542076766490936, "kl": 0.006273722741752863, "entropy": 1.3732240200042725, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 33.48778533935547, "policy_loss": -0.017979685217142105, "vf_loss": 33.50410461425781, "vf_explained_var": 0.8728153109550476, "kl": 0.008312570862472057, "entropy": 1.3661872148513794, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 12000, "num_steps_trained": 12000}, "done": false, "episodes_total": 111, "training_iteration": 3, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-28-41", "timestamp": 1638379721, "time_this_iter_s": 148.40572667121887, "time_total_s": 431.5233509540558, "pid": 53883, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b80109b00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b80109170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80109e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80109e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80109e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80109e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f9b800b0a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 148.40572667121887, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.051162790697674, "ram_util_percent": 65.57860465116279}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 27.630276344908637, "episode_reward_min": -465.714850294071, "episode_reward_mean": -88.53331237409435, "episode_len_mean": 107.44594594594595, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-0": -127.51276278901335, "AGENT-3": -157.48708802715447, "AGENT-2": -129.88366759363805, "AGENT-1": -127.56708441667274}, "policy_reward_max": {"AGENT-0": 121.6225411120378, "AGENT-3": 126.89261087265979, "AGENT-2": -45.449274218883765, "AGENT-1": -87.56880828110408}, "policy_reward_mean": {"AGENT-0": 39.37220684190581, "AGENT-3": 66.10585734707236, "AGENT-2": -96.09401066124721, "AGENT-1": -97.9173659018253}, "custom_metrics": {"mean_ego_speed_mean": 38.54074662162162, "mean_ego_speed_min": 30.183, "mean_ego_speed_max": 47.04625, "distance_travelled_mean": 57.6310777027027, "distance_travelled_min": 42.00675, "distance_travelled_max": 61.45625}, "hist_stats": {"episode_reward": [-95.18354996510391, -19.470556985273554, -152.10748157201425, -172.76024571935295, 27.630276344908637, -128.76576238585196, -133.75341529132638, -131.69138149478846, -73.63319439441993, -229.26951834438094, -80.07662279635996, -64.5085226508391, -38.121291521671225, -19.21092982905615, -120.97846326661983, -43.808830683960224, -43.329929341469466, -387.2354844721285, 21.864343294335015, -131.05591084469702, -35.499533828433925, -9.431619452400327, -49.15731625754341, -26.314823952148693, -104.24831158974935, -49.220985252137616, -33.20604157074368, -39.34260373133924, -53.787796310760434, -24.713489097623167, -434.1802336488099, -33.43512650617371, -36.989860391775885, -66.31561699122993, -127.08081785113433, -28.039452467917485, -144.77980765264041, 2.4518689441714443, -36.28549650659493, -31.742361510132845, -55.96164022864312, -172.65322522966113, -5.141142840620141, -41.108708647181345, -127.25457907729862, 2.0150384328927515, -47.870361754522676, -172.43264903690843, 4.700736094662547, -57.0537007903934, -99.67510162609717, -381.5211039804739, -21.05520382855614, -169.79866452976682, -138.37814912528052, -83.08057135263863, -60.9221633560073, -16.291486129520848, -6.710172823230458, -15.072291674388808, -122.33252915909934, -135.4963161516431, -465.714850294071, -27.23380380322758, -103.97233745217498, -120.49677839008697, 24.014978041846426, -110.72103778728052, -112.93646103620804, -81.05838537411952, -76.35668711330473, -39.610560014505126, -105.03922451864081, -32.460083581644646], "episode_lengths": [106, 122, 96, 104, 119, 107, 108, 101, 110, 107, 105, 110, 119, 102, 115, 117, 122, 85, 96, 105, 107, 105, 113, 113, 97, 99, 105, 114, 102, 120, 79, 114, 106, 109, 113, 115, 110, 121, 123, 109, 104, 105, 87, 112, 115, 91, 108, 102, 107, 111, 109, 92, 99, 102, 107, 112, 109, 122, 123, 108, 114, 106, 85, 119, 96, 108, 116, 103, 105, 103, 116, 106, 106, 113], "policy_AGENT-0_reward": [30.826458692069345, 70.23645246259468, 11.697589094943169, -5.385663214820674, 90.31752686970495, 19.579581614220707, 7.783723642271511, 7.64938304011168, 41.87561671032564, -39.00111861051646, 40.463495373139885, 49.04614899128926, 59.65278124986487, 110.65521466194377, 18.83698372603545, 57.54306018567665, 59.42925426843739, -105.97354139444045, 121.6225411120378, 7.675884405924961, 56.00322191946773, 70.086766643401, 56.18834986170876, 61.44550355645191, 49.50653885522508, 49.49810553155557, 64.45039674757015, 60.501989579674905, 52.90730935786514, 69.554179942005, -109.78357911738192, 52.0210882483961, 59.47837509477913, 42.80539983984791, 11.670141408168767, 66.7044183422872, 8.823262531808226, 81.80132143786899, 62.57153838970239, 64.68010910610622, 50.23011555185104, -12.10781633203414, 113.27090348750046, 62.359725284699344, 15.168198225680065, 112.06145741701609, 54.97751408416651, -12.802746469472297, 119.37462628261213, 56.34143390671611, 29.910566719954936, -57.69721842958239, 97.348049556162, -7.466155598900762, 5.296267671833945, 34.60823791374183, 51.932939015047985, 73.73044047963089, 74.28218060572354, 70.44114271392876, 15.070683501771484, 12.386730718468158, -127.51276278901335, 68.66798874370835, 59.32961843077448, 24.64688230661875, 86.876722437355, 18.757192810965513, 14.387104290015934, 38.88863759826422, 47.96000005172796, 56.86467290040531, 23.15960452488021, 57.35455853148902], "policy_AGENT-3_reward": [69.63731203669826, 107.19049456157987, 48.470901757310685, 36.11748775803862, 126.89261087265979, 59.57857646362512, 46.414168286129396, 48.525740325824955, 80.57632147217717, 2.0432846293968865, 76.31177339962261, 84.46731613668459, 95.86406645365649, 81.28535459645988, 57.95288107221259, 92.18709458961085, 95.01577089135823, -129.76805210784323, 90.62507762921241, 49.22294152531213, 91.75427836762455, 106.21990293999914, 92.44155799039375, 98.39541762736361, 25.819681534262145, 86.60953722250977, 100.62580923433102, 95.96292343723846, 89.71696516164761, 105.22468499103881, -84.86165707481273, 89.63931903887052, 95.18144307957667, 81.4449414745655, 49.519597395314314, 102.45621519920896, 46.026934451450934, 116.587159618902, 97.09408957195882, 100.70671463118904, 85.8848706967736, 29.040661029961072, 65.82344142537438, 97.82837897653512, 50.09847425570136, 81.86986294397099, 90.81607442141282, 29.124758556606494, 89.16751664560834, 92.0532369649319, 69.18670959299772, -157.48708802715447, 69.66192696261065, 34.33838751706134, 46.00712190011307, 73.17381938194853, 87.85236116634414, 108.86109451829796, 109.33366842292688, 106.63306941902371, 53.639655736810965, 51.3798963574313, -125.80728119381418, 104.31614804826975, 32.228456563321984, 63.12196858778732, 122.97517481504607, 58.82611322984489, 55.61867238765305, 73.57629606937877, 87.26969804179515, 92.42615915240442, 62.52145340758972, 95.29604746642919], "policy_AGENT-2_reward": [-97.85801328799505, -98.45030120067835, -106.1520558094495, -101.69825436332911, -94.7728442961908, -103.88080533678938, -93.97321221327209, -93.94329525000879, -98.04151008584886, -96.17803810891235, -98.39427440497747, -98.97381068120256, -96.83232246886986, -105.49792449844242, -98.86047761589451, -96.79441495759255, -98.87061472236488, -45.449274218883765, -95.17129884199485, -94.0514119356941, -91.6903637581282, -92.89368362808652, -98.87271703953122, -93.08628632242616, -89.80626691307583, -92.68145882851722, -99.08788661313822, -97.88586657077522, -98.19392634522953, -99.73488353134883, -129.88366759363805, -87.52672551233623, -95.7969237389088, -95.3097904401858, -94.15602020974265, -98.56839010938026, -99.76779019060129, -97.95779159095568, -97.97242442071511, -98.54410385844767, -96.04710338455553, -94.83690816766364, -92.1641973906035, -100.63728920400857, -96.23110725906207, -95.93378781896183, -96.85911172743292, -94.38059905746002, -101.88807782685612, -102.68071200340987, -99.41247424682544, -57.62267170157351, -94.09856161200722, -98.3219990536642, -94.83431867840827, -95.46650097922117, -100.33465876721183, -99.40622576116155, -95.15794412379933, -96.04514267309496, -95.50488004384765, -99.56985913109767, -84.82772189457063, -100.11907496116629, -97.76314103068643, -104.07853901060776, -92.94246377128951, -94.13777331911554, -91.53073854313455, -96.7833971758864, -105.703408964798, -94.45456754635379, -95.38176910496838, -92.53894148422994], "policy_AGENT-1_reward": [-97.78930740587663, -98.44720280876976, -106.12391661481857, -101.79381589924186, -94.80701710126539, -104.04311512690855, -93.97809500645522, -93.92320961071626, -98.04362249107402, -96.13364625434897, -98.45761716414484, -99.04817709761042, -96.80581675632293, -105.65357458901737, -98.90785044897339, -96.7445705016551, -98.9043397789002, -106.04461675096124, -95.21197660492004, -93.90332484024012, -91.5666703573981, -92.84460540771386, -98.91450707011472, -93.06945881353795, -89.76826506616081, -92.64716917768541, -99.1943609395066, -97.9216501774774, -98.21814448504395, -99.75747049931829, -109.65132986297718, -87.56880828110408, -95.852754827223, -95.25616786545777, -94.11453644487477, -98.63169590003339, -99.86221444529843, -97.97882052164371, -97.97870004754122, -98.58508138898031, -96.02952309271231, -94.74916175992439, -92.07129036289138, -100.65952370440748, -96.29014429961782, -95.98249410913256, -96.80483853266887, -94.37406206658244, -101.95332900670198, -102.76765965863143, -99.35990369222469, -108.71412582216345, -93.96661873532157, -98.34889739426305, -94.84722001881909, -95.39612766910805, -100.37280477018787, -99.47679536628803, -95.16807772808151, -96.1013611342461, -95.53798835383391, -99.69308409644509, -127.56708441667274, -100.09886563403931, -97.7672714155851, -104.18709027388525, -92.89445543926516, -94.16657050897524, -91.41149917074249, -96.73992186587603, -105.88297624202981, -94.44682452096094, -95.33851334614224, -92.57174809533288]}, "sampler_perf": {"mean_env_wait_ms": 30.790948001574744, "mean_processing_ms": 2.0401768213603475, "mean_inference_ms": 1.4056508984568779}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16000, "timers": {"sample_time_ms": 136370.678, "sample_throughput": 29.332, "load_time_ms": 420.898, "load_throughput": 9503.483, "learn_time_ms": 5986.512, "learn_throughput": 668.169, "update_time_ms": 5.367}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 32.842262268066406, "policy_loss": -0.018632400780916214, "vf_loss": 32.85947036743164, "vf_explained_var": 0.8827111124992371, "kl": 0.007110884878784418, "entropy": 1.3592458963394165, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 88.52787780761719, "policy_loss": -0.03993630409240723, "vf_loss": 88.56555938720703, "vf_explained_var": 0.12132930755615234, "kl": 0.011234103702008724, "entropy": 1.3697444200515747, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 84.20880126953125, "policy_loss": -0.03412950411438942, "vf_loss": 84.24119567871094, "vf_explained_var": 0.3284510374069214, "kl": 0.008708172477781773, "entropy": 1.3583465814590454, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 19.25527572631836, "policy_loss": -0.024377446621656418, "vf_loss": 19.27764892578125, "vf_explained_var": 0.9397146105766296, "kl": 0.010022393427789211, "entropy": 1.355003833770752, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 16000, "num_steps_trained": 16000}, "done": false, "episodes_total": 148, "training_iteration": 4, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-31-01", "timestamp": 1638379861, "time_this_iter_s": 139.5774073600769, "time_total_s": 571.1007583141327, "pid": 53883, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b800cb050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b800cb170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb710>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb710>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb710>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800cb710>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f9b800b0050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 287.9831340312958, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 17.543718592964822, "ram_util_percent": 65.80402010050251}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 63.905213284339325, "episode_reward_min": -513.8650305294175, "episode_reward_mean": -85.53998018309147, "episode_len_mean": 107.58, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-0": -150.2124659137836, "AGENT-3": -157.48708802715447, "AGENT-2": -129.88366759363805, "AGENT-1": -127.56708441667274}, "policy_reward_max": {"AGENT-0": 142.24187622764563, "AGENT-3": 138.34937306284723, "AGENT-2": -45.449274218883765, "AGENT-1": -87.56880828110408}, "policy_reward_mean": {"AGENT-0": 41.46726337454962, "AGENT-3": 67.48470842338531, "AGENT-2": -96.56806722376503, "AGENT-1": -97.92388475726142}, "custom_metrics": {"mean_ego_speed_mean": 38.514262499999994, "mean_ego_speed_min": 30.183, "mean_ego_speed_max": 46.128750000000004, "distance_travelled_mean": 58.035282500000015, "distance_travelled_min": 24.581, "distance_travelled_max": 61.96175}, "hist_stats": {"episode_reward": [-81.47736781784332, -94.56916117779205, -120.99510323125634, -53.05669736582698, -92.44100481686954, -41.72509889968894, -0.45371591099324604, 21.379677730167366, -107.01450056168696, -135.87074576077845, -37.54892418598705, 21.969908989396664, -98.45384683860226, 63.905213284339325, -80.56389279689375, -161.11365606677273, -30.2671608736755, -135.928095094001, -513.8650305294175, -78.47036860201628, -134.17124216645442, -53.4909705820291, 49.15364958793587, -61.132818817526825, -40.17681656985003, 2.5545629438160873, -28.78329891344392, -54.51775916241542, -34.90050037408994, -166.61476457659114, -37.63864900633203, -97.56340012078465, -120.35889373212393, -96.38916486802876, -66.5346306365893, -4.428379993207066, 13.036487433247306, 4.700736094662547, -57.0537007903934, -99.67510162609717, -381.5211039804739, -21.05520382855614, -169.79866452976682, -138.37814912528052, -83.08057135263863, -60.9221633560073, -16.291486129520848, -6.710172823230458, -15.072291674388808, -122.33252915909934, -135.4963161516431, -465.714850294071, -27.23380380322758, -103.97233745217498, -120.49677839008697, 24.014978041846426, -110.72103778728052, -112.93646103620804, -81.05838537411952, -76.35668711330473, -39.610560014505126, -105.03922451864081, -32.460083581644646, -95.18354996510391, -19.470556985273554, -152.10748157201425, -172.76024571935295, 27.630276344908637, -128.76576238585196, -133.75341529132638, -131.69138149478846, -73.63319439441993, -229.26951834438094, -80.07662279635996, -64.5085226508391, -38.121291521671225, -19.21092982905615, -120.97846326661983, -43.808830683960224, -43.329929341469466, -387.2354844721285, 21.864343294335015, -131.05591084469702, -35.499533828433925, -9.431619452400327, -49.15731625754341, -26.314823952148693, -104.24831158974935, -49.220985252137616, -33.20604157074368, -39.34260373133924, -53.787796310760434, -24.713489097623167, -434.1802336488099, -33.43512650617371, -36.989860391775885, -66.31561699122993, -127.08081785113433, -28.039452467917485, -144.77980765264041], "episode_lengths": [111, 105, 104, 119, 116, 118, 116, 123, 106, 103, 106, 98, 118, 102, 108, 108, 126, 108, 22, 93, 103, 104, 128, 112, 138, 101, 121, 110, 100, 103, 112, 112, 106, 106, 100, 115, 103, 107, 111, 109, 92, 99, 102, 107, 112, 109, 122, 123, 108, 114, 106, 85, 119, 96, 108, 116, 103, 105, 103, 116, 106, 106, 113, 106, 122, 96, 104, 119, 107, 108, 101, 110, 107, 105, 110, 119, 102, 115, 117, 122, 85, 96, 105, 107, 105, 113, 113, 97, 99, 105, 114, 102, 120, 79, 114, 106, 109, 113, 115, 110], "policy_AGENT-0_reward": [39.965267470950224, 25.887831516526177, 15.196090887742493, 53.815764299370336, 41.081276842837, 57.22697249538951, 74.77461301847059, 91.59997322077194, 24.90706638194402, 11.336819718104302, 99.23523651301404, 124.585047787137, 30.477148105525387, 142.24187622764563, 33.13977765563742, 3.992786615652733, 65.69823673125549, 6.9998844648818945, -150.2124659137836, 73.30826776635499, 7.253447839057188, 52.314517219787504, 103.82284363728385, 50.537556641626416, 62.37877881365682, 116.0916384268036, 64.08414643580727, 46.03957657546441, 94.51555233312537, -5.40804369645528, 61.95100602675095, 25.911808389273773, 25.01365130887484, 26.54587022789464, 41.742585414933146, 71.6897424069191, 115.6512015307873, 119.37462628261213, 56.34143390671611, 29.910566719954936, -57.69721842958239, 97.348049556162, -7.466155598900762, 5.296267671833945, 34.60823791374183, 51.932939015047985, 73.73044047963089, 74.28218060572354, 70.44114271392876, 15.070683501771484, 12.386730718468158, -127.51276278901335, 68.66798874370835, 59.32961843077448, 24.64688230661875, 86.876722437355, 18.757192810965513, 14.387104290015934, 38.88863759826422, 47.96000005172796, 56.86467290040531, 23.15960452488021, 57.35455853148902, 30.826458692069345, 70.23645246259468, 11.697589094943169, -5.385663214820674, 90.31752686970495, 19.579581614220707, 7.783723642271511, 7.64938304011168, 41.87561671032564, -39.00111861051646, 40.463495373139885, 49.04614899128926, 59.65278124986487, 110.65521466194377, 18.83698372603545, 57.54306018567665, 59.42925426843739, -105.97354139444045, 121.6225411120378, 7.675884405924961, 56.00322191946773, 70.086766643401, 56.18834986170876, 61.44550355645191, 49.50653885522508, 49.49810553155557, 64.45039674757015, 60.501989579674905, 52.90730935786514, 69.554179942005, -109.78357911738192, 52.0210882483961, 59.47837509477913, 42.80539983984791, 11.670141408168767, 66.7044183422872, 8.823262531808226], "policy_AGENT-3_reward": [77.72487722327222, 66.04936969526973, 56.325839560108356, 89.20181898249643, 77.55032153206054, 91.67348258906738, 111.06261240949664, 126.71718361960178, 63.63987194248938, 52.27244006775004, 69.64480795147509, 93.42866997780494, 67.0449354116273, 111.2819703946386, 72.53695811425575, 42.991386173972906, 99.89037774652806, 48.73903250143835, -150.2273256782277, 45.85128272760645, 49.98887444459152, 88.35368229655394, 138.34937306284723, 87.93985505888824, 90.84303267128374, 83.85401925109899, 100.46767528347056, 83.34256574120361, 65.12102367667426, 34.863171197883574, 98.23341653802427, 63.89110084014909, 64.28440918413295, 65.68569127116011, 78.61387352123751, 108.65615520079021, 85.62405260084175, 89.16751664560834, 92.0532369649319, 69.18670959299772, -157.48708802715447, 69.66192696261065, 34.33838751706134, 46.00712190011307, 73.17381938194853, 87.85236116634414, 108.86109451829796, 109.33366842292688, 106.63306941902371, 53.639655736810965, 51.3798963574313, -125.80728119381418, 104.31614804826975, 32.228456563321984, 63.12196858778732, 122.97517481504607, 58.82611322984489, 55.61867238765305, 73.57629606937877, 87.26969804179515, 92.42615915240442, 62.52145340758972, 95.29604746642919, 69.63731203669826, 107.19049456157987, 48.470901757310685, 36.11748775803862, 126.89261087265979, 59.57857646362512, 46.414168286129396, 48.525740325824955, 80.57632147217717, 2.0432846293968865, 76.31177339962261, 84.46731613668459, 95.86406645365649, 81.28535459645988, 57.95288107221259, 92.18709458961085, 95.01577089135823, -129.76805210784323, 90.62507762921241, 49.22294152531213, 91.75427836762455, 106.21990293999914, 92.44155799039375, 98.39541762736361, 25.819681534262145, 86.60953722250977, 100.62580923433102, 95.96292343723846, 89.71696516164761, 105.22468499103881, -84.86165707481273, 89.63931903887052, 95.18144307957667, 81.4449414745655, 49.519597395314314, 102.45621519920896, 46.026934451450934], "policy_AGENT-2_reward": [-99.5321689841162, -93.26037435003187, -96.28489029672073, -98.03497757279953, -105.46041920210124, -95.32850106286475, -93.14756529318694, -98.42681118298029, -97.78283442223203, -99.69000359882375, -103.2106928984459, -98.0378356534637, -97.99683774363584, -94.82726227866416, -93.1394094043095, -104.0437007455215, -97.9096428132681, -95.85654798744415, -106.69683132306784, -98.78070156707827, -95.67152421018369, -97.11544308681734, -96.50026204349415, -99.74876433975703, -96.72037032368175, -98.67023657891673, -96.6564968499438, -91.9915112911434, -97.25382774447664, -98.0061503878978, -98.86366664146283, -93.68823342566876, -104.7556459888196, -94.3148784723978, -93.46707389100999, -92.43591279213848, -94.10635087550975, -101.88807782685612, -102.68071200340987, -99.41247424682544, -57.62267170157351, -94.09856161200722, -98.3219990536642, -94.83431867840827, -95.46650097922117, -100.33465876721183, -99.40622576116155, -95.15794412379933, -96.04514267309496, -95.50488004384765, -99.56985913109767, -84.82772189457063, -100.11907496116629, -97.76314103068643, -104.07853901060776, -92.94246377128951, -94.13777331911554, -91.53073854313455, -96.7833971758864, -105.703408964798, -94.45456754635379, -95.38176910496838, -92.53894148422994, -97.85801328799505, -98.45030120067835, -106.1520558094495, -101.69825436332911, -94.7728442961908, -103.88080533678938, -93.97321221327209, -93.94329525000879, -98.04151008584886, -96.17803810891235, -98.39427440497747, -98.97381068120256, -96.83232246886986, -105.49792449844242, -98.86047761589451, -96.79441495759255, -98.87061472236488, -45.449274218883765, -95.17129884199485, -94.0514119356941, -91.6903637581282, -92.89368362808652, -98.87271703953122, -93.08628632242616, -89.80626691307583, -92.68145882851722, -99.08788661313822, -97.88586657077522, -98.19392634522953, -99.73488353134883, -129.88366759363805, -87.52672551233623, -95.7969237389088, -95.3097904401858, -94.15602020974265, -98.56839010938026, -99.76779019060129], "policy_AGENT-1_reward": [-99.63534352794963, -93.24598803955595, -96.23214338238654, -98.03930307489422, -105.61218398966591, -95.29705292128105, -93.14337604577346, -98.51066792722622, -97.77860446388848, -99.79000194780892, -103.2182757520301, -98.00597312208163, -97.97909261211925, -94.79137105928058, -93.10121916247712, -104.05412811087699, -97.946132538191, -95.81046407287693, -106.72840761433835, -98.84921752889969, -95.74204023991949, -97.04372701155303, -96.51830506870101, -99.86146617828435, -96.67825773110886, -98.72085815517019, -96.67862378277789, -91.90839018793983, -97.28324863941285, -98.06374169012146, -98.95940492964431, -93.6780759245386, -104.90130823631198, -94.30584789468553, -93.42401568175015, -92.3383648087779, -94.1324158228721, -101.95332900670198, -102.76765965863143, -99.35990369222469, -108.71412582216345, -93.96661873532157, -98.34889739426305, -94.84722001881909, -95.39612766910805, -100.37280477018787, -99.47679536628803, -95.16807772808151, -96.1013611342461, -95.53798835383391, -99.69308409644509, -127.56708441667274, -100.09886563403931, -97.7672714155851, -104.18709027388525, -92.89445543926516, -94.16657050897524, -91.41149917074249, -96.73992186587603, -105.88297624202981, -94.44682452096094, -95.33851334614224, -92.57174809533288, -97.78930740587663, -98.44720280876976, -106.12391661481857, -101.79381589924186, -94.80701710126539, -104.04311512690855, -93.97809500645522, -93.92320961071626, -98.04362249107402, -96.13364625434897, -98.45761716414484, -99.04817709761042, -96.80581675632293, -105.65357458901737, -98.90785044897339, -96.7445705016551, -98.9043397789002, -106.04461675096124, -95.21197660492004, -93.90332484024012, -91.5666703573981, -92.84460540771386, -98.91450707011472, -93.06945881353795, -89.76826506616081, -92.64716917768541, -99.1943609395066, -97.9216501774774, -98.21814448504395, -99.75747049931829, -109.65132986297718, -87.56880828110408, -95.852754827223, -95.25616786545777, -94.11453644487477, -98.63169590003339, -99.86221444529843]}, "sampler_perf": {"mean_env_wait_ms": 30.7432623955906, "mean_processing_ms": 2.0388048307278357, "mean_inference_ms": 1.3820986126538748}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timers": {"sample_time_ms": 136702.623, "sample_throughput": 29.261, "load_time_ms": 283.978, "load_throughput": 14085.611, "learn_time_ms": 5798.07, "learn_throughput": 689.885, "update_time_ms": 5.263}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 36.96391677856445, "policy_loss": -0.018528301268815994, "vf_loss": 36.98084259033203, "vf_explained_var": 0.9062859416007996, "kl": 0.008017140440642834, "entropy": 1.3542211055755615, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 76.09880065917969, "policy_loss": -0.013470548205077648, "vf_loss": 76.11123657226562, "vf_explained_var": 0.07903444766998291, "kl": 0.0051787057891488075, "entropy": 1.3728461265563965, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 73.1637191772461, "policy_loss": -0.026760313659906387, "vf_loss": 73.18877410888672, "vf_explained_var": 0.14693981409072876, "kl": 0.008496487513184547, "entropy": 1.34799325466156, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 10.432352066040039, "policy_loss": -0.02057521790266037, "vf_loss": 10.4509859085083, "vf_explained_var": 0.9773923754692078, "kl": 0.009712951257824898, "entropy": 1.3427973985671997, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 20000, "num_steps_trained": 20000}, "done": false, "episodes_total": 185, "training_iteration": 5, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-33-25", "timestamp": 1638380005, "time_this_iter_s": 142.82107591629028, "time_total_s": 713.921834230423, "pid": 53883, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b800f7290>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b800f7320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800b0b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800b03b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800b0b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800b03b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800b0b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800b03b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7050>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b800f7dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b800b0b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b800b03b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f9b800cb9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 430.80420994758606, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 18.0409756097561, "ram_util_percent": 65.95170731707314}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 580.1184397798088, "episode_reward_min": 356.97312443803514, "episode_reward_mean": 467.66270590933124, "episode_len_mean": 110.38888888888889, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-0": 126.1944029805127, "AGENT-2": 26.435069364803347, "AGENT-1": 26.56801724409432, "AGENT-3": 165.07351872099665}, "policy_reward_max": {"AGENT-0": 277.41027801748385, "AGENT-2": 37.22556222897459, "AGENT-1": 37.276818823488384, "AGENT-3": 259.84728207869637}, "policy_reward_mean": {"AGENT-0": 190.78121417542363, "AGENT-2": 31.092112219727344, "AGENT-1": 31.102037078094252, "AGENT-3": 214.68734243608594}, "custom_metrics": {"mean_ego_speed_mean": 42.474111111111114, "mean_ego_speed_min": 36.15725, "mean_ego_speed_max": 44.821, "distance_travelled_mean": 57.32254166666668, "distance_travelled_min": 53.17575, "distance_travelled_max": 61.502250000000004}, "hist_stats": {"episode_reward": [471.33875492780436, 356.97312443803514, 529.1751466463124, 458.00084486147136, 528.7548104111719, 477.0371373629378, 471.71007591287923, 462.5444336330334, 440.45437521888624, 372.7639812099571, 552.1220433771721, 550.6126929337166, 448.20892326769336, 475.0636831554665, 467.39383758319707, 493.9696304268178, 384.4904866362745, 504.3431588807289, 391.3346018147286, 372.81843764933416, 491.0307839668194, 464.9783562297087, 549.0229385836682, 546.8720988502267, 413.3534583096612, 425.62969140153126, 378.89213271007117, 448.1051362823571, 471.47344053903964, 500.3491845907334, 483.07438650237316, 493.6763170031151, 524.8582547992273, 580.1184397798088, 441.3062505802684, 414.00636225969185], "episode_lengths": [97, 109, 100, 100, 127, 117, 107, 112, 119, 101, 99, 104, 111, 130, 118, 115, 105, 110, 106, 103, 99, 105, 103, 128, 111, 115, 109, 108, 110, 115, 117, 112, 120, 121, 102, 109], "policy_AGENT-0_reward": [210.4913273832089, 126.1944029805127, 253.47879735896666, 174.01875456692414, 215.86798335448913, 189.90652337233428, 187.64747396838095, 182.27871225544447, 175.6590927594683, 130.53336800671588, 259.4802756394886, 260.5974959077704, 178.4908822184537, 191.7708633925512, 186.424896881595, 197.3968623759058, 141.88537789488709, 197.13619799708775, 145.40882692781514, 130.03988370030663, 226.81903613014106, 182.58314508337818, 257.178623586529, 224.9912251882311, 161.17076441492736, 161.5567871401392, 141.07853450196558, 175.713598981875, 186.88049254278263, 199.8281842542523, 194.2455187644848, 198.69060163569372, 210.84818192447383, 277.41027801748385, 174.70346853210998, 159.71727067447748], "policy_AGENT-2_reward": [37.19757399050391, 32.83182155053238, 26.435069364803347, 36.75396275360869, 30.98196363477464, 30.968597559135755, 30.480429869968845, 30.29820701004523, 27.00814020344634, 35.34247010791239, 31.837649179998273, 30.5912561713046, 27.80984933601699, 28.80783963392754, 29.600494801076948, 31.797675180479466, 29.567614182380638, 37.22556222897459, 30.45986713066636, 35.48252600655645, 32.5203304463357, 31.738110542672267, 33.15582168061774, 31.017792490632434, 26.787677374825062, 32.83050318581465, 28.283754488619792, 30.641871460342234, 31.02097334280458, 32.35505398576911, 29.610785315929462, 30.18936204965105, 33.81201933951893, 28.39527772214859, 27.780104535651436, 27.698032052737872], "policy_AGENT-1_reward": [37.276818823488384, 32.87338118599391, 26.56801724409432, 36.702002536536185, 31.039854736442862, 30.89082898955104, 30.550798820069826, 30.271212087199523, 27.086886483718, 35.25472654708687, 31.856336985168344, 30.5487733946963, 27.868655037319915, 28.748571288807245, 29.718167499678888, 31.72619901830542, 29.5936129976363, 37.20064093954142, 30.432145303047164, 35.29021792050645, 32.51678887737598, 31.69256715076935, 33.2228277752148, 31.015799092666935, 26.9015750082252, 32.83167156860292, 28.301149988902665, 30.779541294698102, 31.063850207652, 32.215470041125116, 29.692047974835674, 30.09745911044575, 33.861044560146375, 28.464715383663254, 27.784198941887325, 27.734779996293064], "policy_AGENT-3_reward": [186.3730347306032, 165.07351872099665, 222.6932626784482, 210.52612500440216, 250.86500868546548, 225.2711874419168, 223.03137325445968, 219.69630228034384, 210.70025577225329, 171.63341654824174, 228.94778157251775, 228.87516745994557, 214.03953667590307, 225.73640884018116, 221.65027840084645, 233.0488938521269, 183.44388156137038, 232.78075771512528, 185.0337624531998, 172.00581002196463, 199.17462851296713, 218.96453345288919, 225.46566554130686, 259.84728207869637, 198.49344151168376, 198.4107295069747, 181.22869373058313, 210.97012454544142, 222.50812444580052, 235.9504763095871, 229.52603444712355, 234.698894207325, 246.3370089750886, 245.84816865651308, 211.03847857061942, 198.85627953618345]}, "sampler_perf": {"mean_env_wait_ms": 30.819148547766783, "mean_processing_ms": 2.0764381162704932, "mean_inference_ms": 1.360914463461771}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timers": {"sample_time_ms": 137520.703, "sample_throughput": 29.087, "load_time_ms": 805.495, "load_throughput": 4965.889, "learn_time_ms": 6678.165, "learn_throughput": 598.967, "update_time_ms": 5.884}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 26.403339385986328, "policy_loss": -0.02043743059039116, "vf_loss": 26.422117233276367, "vf_explained_var": 0.9060682654380798, "kl": 0.008299493230879307, "entropy": 1.35612154006958, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.3409165143966675, "policy_loss": -0.03571057319641113, "vf_loss": 0.3746289908885956, "vf_explained_var": 0.6598603129386902, "kl": 0.009990639053285122, "entropy": 1.368982195854187, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.5873072147369385, "policy_loss": -0.027542581781744957, "vf_loss": 0.6126744747161865, "vf_explained_var": 0.8645613193511963, "kl": 0.01087652612477541, "entropy": 1.3703068494796753, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.26207971572876, "policy_loss": -0.028466198593378067, "vf_loss": 4.288686275482178, "vf_explained_var": 0.9828392863273621, "kl": 0.009297062642872334, "entropy": 1.354490876197815, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 20000, "num_steps_trained": 20000}, "done": false, "episodes_total": 184, "training_iteration": 5, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-39-44", "timestamp": 1638380384, "time_this_iter_s": 147.40343832969666, "time_total_s": 718.5041966438293, "pid": 54806, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b80079710>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b80079830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80027170>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80027170>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80027170>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8006c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80027170>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f8644680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 147.40343832969666, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.078403755868543, "ram_util_percent": 67.77042253521124}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 582.3172156423383, "episode_reward_min": -549.8983138481094, "episode_reward_mean": 13.26044684152302, "episode_len_mean": 107.29729729729729, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-2": -21.156125189182323, "AGENT-1": -21.266038817945528, "AGENT-0": -273.4461644798546, "AGENT-3": -234.02998536112693}, "policy_reward_max": {"AGENT-2": 45.42542112841945, "AGENT-1": 25.390920724884367, "AGENT-0": 294.52701151295327, "AGENT-3": 266.5813681661704}, "policy_reward_mean": {"AGENT-2": 0.0778788253408874, "AGENT-1": -0.466616223096236, "AGENT-0": -4.04355908048279, "AGENT-3": 17.692743319761178}, "custom_metrics": {"mean_ego_speed_mean": 37.755648648648645, "mean_ego_speed_min": 28.53575, "mean_ego_speed_max": 43.68725, "distance_travelled_mean": 58.606006756756756, "distance_travelled_min": 54.2445, "distance_travelled_max": 61.053749999999994}, "hist_stats": {"episode_reward": [437.06594711616447, -330.2219868646977, 400.85059109625035, -398.4116430674647, 404.92665515410636, -412.9646599493401, 423.5889946649931, -435.088409495462, 386.61077985336027, -549.8983138481094, 287.9927819521084, -367.7656565383187, 381.5764213671642, -470.3362593312637, 582.3172156423383, -321.5783892886021, 316.481493147222, -391.34421744860157, 426.47022905010033, -415.37050373613897, 362.857593523002, -473.8324933055175, 392.511978242624, -382.5071575092176, 525.6680268246009, -429.85087464563776, 356.0168443578654, -465.6237819450119, 99.08903904092992, 380.8489540664866, 415.99374062227145, -408.3629239767361, 302.38937203158275, -428.0124214663698, 303.4294963996611, -486.421851119298, 471.5419225193077], "episode_lengths": [125, 90, 107, 102, 98, 107, 112, 106, 110, 111, 108, 95, 126, 102, 124, 92, 104, 93, 128, 103, 117, 104, 110, 98, 126, 110, 112, 103, 88, 114, 103, 104, 106, 117, 104, 107, 104], "policy_AGENT-2_reward": [13.265445179872206, -18.183609876356584, 15.53173703725161, -19.07896270016907, 17.318526794445894, -16.082123960198725, 13.215770346331126, -19.24591977564342, 16.274431243567562, -21.156125189182323, 14.03023106247897, -16.25384004872632, 14.186245696686754, -19.404736294530665, 12.962342799212822, -18.599267153022584, 15.489999095166791, -20.511412240146534, 11.91750441787789, -19.39636740753489, 14.353666077188006, -17.08614234058835, 16.894803598417482, -18.727054865410953, 14.023068330452102, -19.137991319449387, 15.505706147649894, -19.579984273474164, 45.42542112841945, 16.16319323263236, 13.980609900023158, -17.30246124538489, 11.426164277943712, -19.203072279319642, 13.705301136152126, -18.65818742976239, 14.818607434743805], "policy_AGENT-1_reward": [13.33016415823171, -18.18569558335983, 15.513288068572523, -19.044373136590462, 17.331611891550683, -16.048675977253623, 13.13457252623258, -19.250575836234898, 16.221983071267474, -21.266038817945528, 14.075765938914975, -16.22590906011219, 14.20841801025657, -19.292225005638485, 12.979764990940382, -18.675577460783874, 15.499298922772036, -20.540673385772944, 11.838833498308624, -19.397513424698698, 14.403517265577026, -17.141884049065972, 16.90594122422275, -18.752675807538566, 14.039786127528151, -19.096406255877845, 15.613860367674462, -19.626641373415502, 25.390920724884367, 16.20254347150425, 13.944236142040872, -17.309763551245343, 11.419047508646589, -19.286867184962997, 13.654802097023088, -18.67520274520785, 14.843542394994776], "policy_AGENT-0_reward": [187.53590290615244, -135.50822924722863, 166.88121650206404, -196.1281397451218, 198.39332518371594, -206.1470896727483, 180.63123475284561, -213.9790848355718, 157.60478163911523, -273.4461644798546, 109.80088458403293, -155.44653768125943, 160.08198778398764, -237.25333423593503, 294.52701151295327, -130.52364593732943, 121.93195327129233, -163.23225124359803, 183.64050233875764, -204.25778540074552, 149.10566378931406, -240.47639868473158, 160.05012919093224, -195.28181898225978, 231.02380420045006, -211.3017198772684, 143.56004726225154, -233.96764400216932, 25.13333466571101, 155.38048677326637, 208.78080540492508, -202.3864868977285, 117.86672300551487, -209.9981071423061, 118.3013925404494, -246.14171964816748, 235.63328442842882], "policy_AGENT-3_reward": [222.9344348719082, -158.34445215775287, 202.92434948836228, -164.16016748558314, 171.88319128439426, -174.68677033913917, 216.6074170395837, -182.61282904801203, 196.50958389940993, -234.02998536112693, 150.08590036668187, -179.8393697482207, 193.0997698762333, -194.38596379515974, 261.84809633923163, -153.779898737466, 163.560241857991, -187.05988057908402, 219.0733887951566, -172.31883750315967, 184.99474639092261, -199.12806823113144, 198.66110422905106, -149.7456078540087, 266.5813681661704, -180.31475719304228, 181.33723058028966, -192.44951229595284, 3.1393625219151033, 193.1027305890838, 179.28808917528244, -171.3642122823773, 161.67743723947768, -179.52437485978098, 157.7680006260366, -202.94674129616075, 206.24648826114014]}, "sampler_perf": {"mean_env_wait_ms": 32.08594726223077, "mean_processing_ms": 2.0809814769665733, "mean_inference_ms": 1.4403360958428302}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timers": {"sample_time_ms": 142953.425, "sample_throughput": 27.981, "load_time_ms": 831.251, "load_throughput": 4812.026, "learn_time_ms": 6914.584, "learn_throughput": 578.487, "update_time_ms": 5.676}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 18.719194412231445, "policy_loss": -0.02392967790365219, "vf_loss": 18.740747451782227, "vf_explained_var": 0.9104058146476746, "kl": 0.011895284056663513, "entropy": 1.3559428453445435, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.1626446694135666, "policy_loss": -0.03286999091506004, "vf_loss": 0.19253337383270264, "vf_explained_var": 0.9808275103569031, "kl": 0.014906478114426136, "entropy": 1.3613367080688477, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.19577062129974365, "policy_loss": -0.04057750850915909, "vf_loss": 0.2344907969236374, "vf_explained_var": 0.9689696431159973, "kl": 0.00928666815161705, "entropy": 1.371561050415039, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.5532782077789307, "policy_loss": -0.03321249783039093, "vf_loss": 2.5832695960998535, "vf_explained_var": 0.9861326217651367, "kl": 0.016105884686112404, "entropy": 1.3559061288833618, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 20000, "num_steps_trained": 20000}, "done": false, "episodes_total": 185, "training_iteration": 5, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-44-17", "timestamp": 1638380657, "time_this_iter_s": 153.15815091133118, "time_total_s": 724.2589092254639, "pid": 55618, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f86524d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f8652200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80093200>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b80093320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b80093440>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80093560>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80093200>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b80093320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b80093440>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80093560>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80093200>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b80093320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b80093440>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80093560>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b80093200>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b80093320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b80093440>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b80093560>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f8600200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 153.15815091133118, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 17.84977375565611, "ram_util_percent": 67.5823529411765}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -334.4328263103739, "episode_reward_min": -561.6424659867012, "episode_reward_mean": -451.5390154273152, "episode_len_mean": 102.94736842105263, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-2": -32.95085989549459, "AGENT-1": -33.10813972487492, "AGENT-3": -247.24571728551908, "AGENT-0": -280.51467552998923}, "policy_reward_max": {"AGENT-2": -16.606730411028853, "AGENT-1": -16.616510460992167, "AGENT-3": -147.3513176589087, "AGENT-0": -122.82193174810538}, "policy_reward_mean": {"AGENT-2": -23.65232049820951, "AGENT-1": -23.65137641688285, "AGENT-3": -187.79388828133742, "AGENT-0": -216.44143023088546}, "custom_metrics": {"mean_ego_speed_mean": 34.214855263157894, "mean_ego_speed_min": 28.1525, "mean_ego_speed_max": 40.322250000000004, "distance_travelled_mean": 57.61977631578947, "distance_travelled_min": 53.0975, "distance_travelled_max": 61.529250000000005}, "hist_stats": {"episode_reward": [-453.7330386141199, -396.2180056221354, -423.9167023984908, -451.22576993269485, -505.7930986764729, -459.310285667153, -431.0879734755065, -465.3363519273885, -412.06289294794476, -440.48735167440987, -426.4324837622577, -476.0949481243436, -491.6003657073888, -476.7682645004791, -488.14941470111427, -435.9213589486862, -376.44477298135047, -467.0005535437194, -524.1332272629666, -438.50240118152954, -433.0513444124005, -541.9831522577316, -405.16126364220816, -436.3859362402224, -429.1967099108537, -426.6547751115484, -417.1714507594672, -461.0107674219916, -425.71128668507123, -429.82561613637864, -454.0122042776052, -334.4328263103739, -561.6424659867012, -459.7536899374068, -451.9227162010599, -479.3428722563845, -497.6883412274652, -473.31590581295575], "episode_lengths": [101, 99, 102, 100, 107, 117, 102, 99, 102, 103, 95, 113, 105, 109, 105, 99, 100, 104, 106, 99, 111, 108, 98, 103, 103, 98, 106, 101, 101, 100, 108, 90, 110, 103, 97, 103, 105, 100], "policy_AGENT-2_reward": [-17.267563109002765, -27.080022326021822, -18.788436191589167, -30.645738730787222, -20.517611519828442, -26.473394713581655, -16.99001993686231, -30.29082440882413, -18.48714848237246, -27.185469819507123, -19.270275252191425, -27.12203159097247, -18.74677611335847, -27.408639716031786, -20.61766578454318, -29.035486722951706, -18.127556042128216, -32.95085989549459, -22.053421123312212, -30.12133636951947, -17.955144981639602, -27.95861387017255, -19.92011027589089, -26.42700338321721, -16.732088686928574, -30.548830850904586, -17.123293091001212, -28.229215095648996, -17.324159328403468, -28.862972976598755, -16.606730411028853, -27.48647246087666, -20.699575882363533, -28.373098689799416, -20.416073421491912, -29.122941279349668, -17.52683210465814, -28.294744293106522], "policy_AGENT-1_reward": [-17.28998291970744, -27.117931975982362, -18.826388730050716, -30.627005169180382, -20.474825592121274, -26.464299423431235, -17.012444067302326, -30.3440792431304, -18.43379968834138, -27.125391279404326, -19.271275099510675, -27.167126182351712, -18.68207767583897, -27.506558776949117, -20.548414271969364, -29.066302631487712, -18.133764502130646, -33.10813972487492, -21.962145550342367, -30.180449603861124, -18.017677276229666, -27.8805638614234, -19.86839304663707, -26.35621177620432, -16.70645402679378, -30.579096206482916, -17.085706771809832, -28.210086972439555, -17.31243548534788, -28.923410526179477, -16.616510460992167, -27.528099832899443, -20.625577605303736, -28.32095270895551, -20.353399196119202, -29.148105626946723, -17.632425875618587, -28.24479447719662], "policy_AGENT-3_reward": [-188.25019128722656, -189.06507325312884, -171.1745112128664, -178.1558428348371, -247.24571728551908, -188.41750635830516, -177.41062881357163, -180.39207289709935, -171.37120660741647, -177.25848754903635, -206.67795877038228, -195.54737059250112, -206.24425311175912, -195.43526256033746, -203.0842737924611, -172.31532495231966, -147.3513176589087, -184.76988624381067, -220.28674998544608, -172.78916541820197, -183.19721266375748, -223.08427931366975, -160.14076002045715, -175.82118466899558, -181.29828001359124, -165.9813110144386, -175.76052046955235, -179.90793633537314, -172.82626833493268, -169.75783847823794, -194.5769814654326, -156.59632226849257, -239.80263696904458, -180.09874018665306, -218.2763169040463, -188.4105291345118, -211.39709682226714, -185.9907384422321], "policy_AGENT-0_reward": [-230.92530129818297, -152.95497806700226, -215.1273662639844, -211.79718319788995, -217.5549442790042, -217.9550851718349, -219.67488065777033, -224.30937537833435, -203.77073816981448, -208.91800302646217, -181.2129746401736, -226.25841975851858, -247.9272588064319, -226.41780344716085, -243.8990608521408, -205.50424464192704, -192.83213477818265, -216.17166767953915, -259.8309106038657, -205.41144978994691, -213.88130949077402, -263.05969521246544, -205.232000299223, -207.78153641180506, -214.4598871835404, -199.54553703972246, -207.2019304271039, -224.66352901853006, -218.2484235363871, -202.28139415536248, -226.21198194015165, -122.82193174810538, -280.51467552998923, -222.96089835199885, -192.87692667940246, -232.66129621557604, -251.13198642492137, -230.78562860042084]}, "sampler_perf": {"mean_env_wait_ms": 31.341055100394964, "mean_processing_ms": 2.119577577548514, "mean_inference_ms": 1.4019084554766155}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timers": {"sample_time_ms": 139942.003, "sample_throughput": 28.583, "load_time_ms": 805.3, "load_throughput": 4967.09, "learn_time_ms": 6735.195, "learn_throughput": 593.895, "update_time_ms": 5.148}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.8514602184295654, "policy_loss": -0.021211447194218636, "vf_loss": 2.870142936706543, "vf_explained_var": 0.9559993147850037, "kl": 0.012643800117075443, "entropy": 1.3625746965408325, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.5049906373023987, "policy_loss": -0.0354224294424057, "vf_loss": 0.5386182069778442, "vf_explained_var": 0.9298700094223022, "kl": 0.008974334225058556, "entropy": 1.3664783239364624, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.19112220406532288, "policy_loss": -0.02304569073021412, "vf_loss": 0.2119850069284439, "vf_explained_var": 0.9340699911117554, "kl": 0.010914493352174759, "entropy": 1.3668688535690308, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.9500977993011475, "policy_loss": -0.027818648144602776, "vf_loss": 0.9747860431671143, "vf_explained_var": 0.9764294028282166, "kl": 0.015652315691113472, "entropy": 1.3575361967086792, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 20000, "num_steps_trained": 20000}, "done": false, "episodes_total": 186, "training_iteration": 5, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_12-49-26", "timestamp": 1638380966, "time_this_iter_s": 149.92458820343018, "time_total_s": 721.0253465175629, "pid": 56405, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b80109f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b8006c710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8008bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8008bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8008bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f9b8008bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f9b8008b200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f8621200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 149.92458820343018, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.123502304147465, "ram_util_percent": 71.77142857142856}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 514.6996447728533, "episode_reward_min": -850.9027952438937, "episode_reward_mean": -386.6171127831742, "episode_len_mean": 98.775, "episodes_this_iter": 40, "policy_reward_min": {"AGENT-0": -347.3451495833698, "AGENT-2": -125.68803060200875, "AGENT-1": -106.42980879967537, "AGENT-3": -306.90315367587294}, "policy_reward_max": {"AGENT-0": 137.63415794351374, "AGENT-2": 109.07181725068915, "AGENT-1": 178.73601225665263, "AGENT-3": 165.83184746261404}, "policy_reward_mean": {"AGENT-0": -177.18068596612952, "AGENT-2": -27.39375622378511, "AGENT-1": -25.98709652832981, "AGENT-3": -156.0555740649298}, "custom_metrics": {"mean_ego_speed_mean": 38.6120375, "mean_ego_speed_min": 29.30975, "mean_ego_speed_max": 44.76625, "distance_travelled_mean": 56.14565625, "distance_travelled_min": 25.753249999999998, "distance_travelled_max": 76.87875000000001}, "hist_stats": {"episode_reward": [-238.485209254479, -751.0587265794281, -231.3446154373948, -717.2229105006868, -206.25066951133428, -736.2437156700413, -207.45760632537193, -703.8942750678445, 214.86428066305157, -175.82980032475217, -696.2108672688921, 514.6996447728533, -723.2818959551441, -196.49125075707155, -385.00035910795077, 15.055590415916, -739.5843415136321, -195.45698825012573, -638.0359234885934, -178.5878153634182, -501.124287016141, -266.42764743911295, -754.5909346095931, -257.05067033022937, 135.37838321881122, -208.9970461791315, -652.2927931574275, -216.5996939658418, -708.7601390902923, -254.261256797122, -766.327692003555, -200.91633937452133, -701.8046231685124, -230.4705440327398, -850.9027952438937, -37.27698893416158, -760.4036257228037, -279.0162783244683, -727.9792701318138, -249.0428145000791], "episode_lengths": [110, 102, 102, 98, 102, 108, 95, 98, 64, 97, 100, 112, 99, 104, 64, 101, 105, 98, 97, 102, 86, 115, 103, 108, 121, 99, 96, 102, 98, 109, 106, 99, 103, 97, 106, 30, 102, 107, 103, 103], "policy_AGENT-0_reward": [-164.79905253141862, -297.33840231436966, -159.42088315658032, -285.2550378993362, -160.77447518871801, -288.72630684964054, -119.36437600702047, -266.5942832624336, 44.170921452607566, -100.82336949784835, -231.87599720753553, 137.63415794351374, -284.8908796959066, -145.68438120394353, -106.52190805214069, 36.59478595168839, -286.17881278806175, -144.84189527855392, -207.85417495807616, -143.33209471788618, -101.59348876965225, -180.08321196506415, -304.75964984608277, -173.2861108194768, 39.82808718998461, -160.4652241892905, -213.13326103498986, -160.70883605556907, -281.88255168673084, -171.42785730333551, -293.0018103206727, -145.36521747354442, -269.8040087960771, -135.24439514242812, -347.3451495833698, -48.12336002514069, -310.3949374203209, -192.51601448363408, -285.2728785002377, -176.771097157888], "policy_AGENT-2_reward": [30.04143725552535, -100.9578117461396, 27.617159238126103, -95.58393539061572, 35.676800582177705, -95.2276579578054, 28.329893029100788, -102.0761716539093, 44.24831746298302, 30.35305012065954, -98.19746080906889, 32.49762711007306, -98.69186600893008, 31.50811377741711, -106.41133350696184, -46.40226775699061, -99.13500989589163, 29.527289569821598, -93.53636524097936, 31.254529328929365, -125.68803060200875, 31.469175226185264, -93.98159777256399, 29.183738047828932, 109.07181725068915, 33.21591498297244, -95.55934476211391, 30.1765834930036, -94.22402965333964, 28.58278189315234, -105.83634888651304, 28.214261705242933, -97.16380263107494, 33.00652395230583, -98.30587103183262, 29.50247565988575, -90.92450095829706, 32.19352433077121, -94.87260897721751, 31.354752273998244], "policy_AGENT-1_reward": [30.115986271048502, -100.94088202803853, 27.694413954061744, -95.54082989028484, 35.63038860097184, -95.19458755264654, 28.224665316361634, -102.17423146052859, 44.216095066227034, 30.421260743300337, -98.16095559571357, 178.73601225665263, -98.74640676918617, 31.68597469041015, -106.42980879967537, 36.84916328268163, -99.19357588101374, 29.5862605693175, -93.50868041151435, 31.211304976271855, -101.44896500198767, 31.477534535848896, -93.84116807513593, 29.215461626813248, -88.95368775364494, 33.33460469632825, -95.49516800905693, 30.12284555194107, -94.08446421757642, 28.60755023521333, -105.94774501403397, 28.26810044580252, -97.20716122677342, 32.91095154241342, -98.3486209528188, 29.548257837984924, -90.74391322395223, 32.06955105337714, -94.7846493023389, 31.3352567797008], "policy_AGENT-3_reward": [-133.84358024963424, -251.82163049088035, -127.23530547300238, -240.84310732044997, -116.78338350576587, -257.0951633099487, -144.64778866381386, -233.04958869097368, 82.22894668123405, -135.7807416908638, -267.9764536565747, 165.83184746261404, -240.95274348112142, -114.0009580209553, -65.63730874917289, -11.986091061463284, -255.07694294866565, -109.72864311071083, -243.1367028780234, -97.72155495073316, -172.3938026424922, -149.29114523608294, -262.00851891581067, -142.16375918539475, 75.43216653178254, -115.0823416691417, -248.105019351267, -116.19028695521743, -238.56909353264518, -140.02373162215216, -261.5417877823349, -112.03348405202237, -237.6296505145868, -161.14362438503085, -306.90315367587294, -48.20436240689155, -268.34027412023323, -150.7633392249826, -253.04913335201942, -134.96172639589022]}, "sampler_perf": {"mean_env_wait_ms": 31.678929802061056, "mean_processing_ms": 2.2181131576961413, "mean_inference_ms": 1.525393786116917}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timers": {"sample_time_ms": 142192.914, "sample_throughput": 28.131, "load_time_ms": 800.647, "load_throughput": 4995.959, "learn_time_ms": 6914.368, "learn_throughput": 578.506, "update_time_ms": 6.031}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 12.94311809539795, "policy_loss": -0.027995657175779343, "vf_loss": 12.968940734863281, "vf_explained_var": 0.9095960259437561, "kl": 0.010869033634662628, "entropy": 1.3654884099960327, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 34.79874038696289, "policy_loss": -0.03746017441153526, "vf_loss": 34.83430099487305, "vf_explained_var": 0.8142441511154175, "kl": 0.009465496987104416, "entropy": 1.3488109111785889, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 38.82655334472656, "policy_loss": -0.029700733721256256, "vf_loss": 38.854251861572266, "vf_explained_var": 0.8102909922599792, "kl": 0.010034478269517422, "entropy": 1.349120020866394, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 12.790045738220215, "policy_loss": -0.03551010414958, "vf_loss": 12.822870254516602, "vf_explained_var": 0.916663646697998, "kl": 0.013420927338302135, "entropy": 1.358444094657898, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 20000, "num_steps_trained": 20000}, "done": false, "episodes_total": 188, "training_iteration": 5, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-00-39", "timestamp": 1638381639, "time_this_iter_s": 152.33839297294617, "time_total_s": 723.4391512870789, "pid": 58064, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f9b800804d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f9b80080170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f85428c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f85429e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f854e440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f854e710>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f85428c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f85429e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f854e440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f854e710>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f85428c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f85429e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f854e440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f854e710>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f85428c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f85429e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f854e440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f854e710>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f856e4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 152.33839297294617, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 17.784545454545455, "ram_util_percent": 80.13590909090908}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -142.20913830622837, "episode_reward_min": -596.7541334531448, "episode_reward_mean": -380.10692597585444, "episode_len_mean": 103.44736842105263, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-3": -250.81191976144646, "AGENT-2": -29.953704832746308, "AGENT-1": -30.056913019177163, "AGENT-0": -289.33292418740155}, "policy_reward_max": {"AGENT-3": -64.67847525615232, "AGENT-2": 16.181328831437508, "AGENT-1": 16.012842603604753, "AGENT-0": -64.67275446021128}, "policy_reward_mean": {"AGENT-3": -169.68266962919185, "AGENT-2": -6.769554667472997, "AGENT-1": -5.732955296027194, "AGENT-0": -197.9217463831625}, "custom_metrics": {"mean_ego_speed_mean": 33.59140789473684, "mean_ego_speed_min": 29.317500000000003, "mean_ego_speed_max": 39.06275, "distance_travelled_mean": 56.46488157894737, "distance_travelled_min": 36.411750000000005, "distance_travelled_max": 60.9645}, "hist_stats": {"episode_reward": [-191.40438379907522, -537.7293121073795, -270.9110236658604, -418.305235203709, -332.67975466945757, -477.9862803343443, -278.0396061192272, -464.40915374464373, -313.3238356112747, -482.5020550612223, -294.10692683468426, -399.8086544046917, -305.97873885533255, -596.7541334531448, -280.2909598626203, -445.17761894467594, -348.14262148248275, -539.5676240421544, -375.000617102208, -488.2961953374345, -310.75591411046946, -499.5504209096168, -310.4444850353622, -451.0858750547988, -282.15558294762445, -451.536409460789, -299.65512463039164, -538.2748453566156, -311.0419666644317, -583.5645638739841, -142.20913830622837, -290.82859834907833, -373.91883100336486, -293.909339364588, -484.2256960707416, -272.92941713031803, -501.98996780556564, -205.57228037287888], "episode_lengths": [91, 108, 101, 99, 109, 104, 107, 107, 108, 105, 98, 108, 109, 111, 102, 105, 105, 106, 110, 105, 105, 106, 101, 102, 105, 105, 103, 107, 108, 115, 57, 111, 90, 107, 111, 103, 104, 93], "policy_AGENT-3_reward": [-124.74703710597576, -217.40405005937697, -129.94339849949228, -166.36207786205142, -164.92910780413843, -188.6856359012062, -138.3169448952258, -188.88727859049874, -152.69274494205305, -194.62518592227315, -138.13480046540556, -191.56971145620625, -152.37444048031722, -250.81191976144646, -136.9457467787672, -180.66388712028194, -169.6950372621716, -222.61372685152483, -181.101295401691, -196.5311874030505, -152.27140136326236, -205.17470023171634, -145.92768384572082, -177.49608347543762, -140.9181422038181, -180.20450588155865, -144.1794314553397, -223.6442911709821, -154.8884862012218, -243.82926684209733, -64.67847525615232, -144.94430993251544, -169.11532976625423, -143.40539284559227, -197.1135424958837, -133.26785629902048, -203.5241254069736, -136.3232066725892], "policy_AGENT-2_reward": [12.024055221907009, -28.485742889477336, 12.064383805830994, -26.312359250869896, 14.945466667757538, -28.422840176036456, 15.022238673387164, -27.48259983075028, 11.478050593883072, -24.630461957036708, 12.154972124151147, -26.573633512545214, 14.595940946088346, -28.28240889959285, 12.920012803167218, -26.17873814922014, 16.063672953275756, -26.87469583332774, 13.746316506028327, -26.39786791530253, 13.124570419004483, -28.16365999050926, 12.105730446746085, -25.823341649118824, 15.65510688999294, -29.66881307243869, 15.579469884276643, -24.794075968656802, 14.954158003408242, -29.405918110150797, -26.105733763014083, 14.646615204359858, -29.211242521164987, 12.10216812510178, -29.953704832746308, 12.720677679484208, -26.5601748213033, 16.181328831437508], "policy_AGENT-1_reward": [12.05511525584065, -28.44169975960937, 12.165530356903014, -26.377489728482768, 14.912237026577756, -28.38039779953808, 14.974711672912457, -27.527271004036937, 11.587415501321335, -24.60599364850347, 12.203415442426275, -26.62828140335361, 14.566480606103333, -28.326880604704442, 13.003753012114057, -26.14102206596831, 15.921684022955974, -26.796680555229635, 13.66900400058853, -26.420094481859618, 13.129962827428441, -28.09527843372949, 12.139936498398072, -25.765169937066304, 15.603429613969254, -29.775464833493075, 15.530753338510483, -24.78447206330119, 14.94088783185237, -29.319228729337, 13.24782517314932, 14.747719681757715, -29.276284903259246, 12.1820425762345, -30.056913019177163, 12.8603368964273, -26.58876221745925, 16.012842603604753], "policy_AGENT-0_reward": [-90.73651717084707, -263.3978193989158, -165.1975393291022, -199.253308362305, -197.60835055965418, -232.497406457564, -169.719611570301, -220.5120043193579, -183.69655676442613, -238.64041353340917, -180.33051393585612, -155.0370280325868, -182.76671992720716, -289.33292418740155, -169.26897889913442, -212.19397160920573, -210.4329411965425, -263.282520802072, -221.31464220713377, -238.94704553722207, -184.73904599364002, -238.11678225366148, -188.7624681347856, -222.0012799931758, -172.49597724776856, -211.88762567329883, -186.58591639783907, -265.0520061536751, -186.04852629847062, -281.010150192399, -64.67275446021128, -175.2786233026805, -146.3159738126866, -174.78815722033195, -227.10153572293456, -165.24257540720905, -245.31690535982963, -101.4432451353321]}, "sampler_perf": {"mean_env_wait_ms": 30.519029910014417, "mean_processing_ms": 2.1271196730999136, "mean_inference_ms": 1.4020922898471546}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timers": {"sample_time_ms": 136694.508, "sample_throughput": 29.262, "load_time_ms": 777.871, "load_throughput": 5142.242, "learn_time_ms": 6734.288, "learn_throughput": 593.975, "update_time_ms": 5.09}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.7565412521362305, "policy_loss": -0.01799376867711544, "vf_loss": 3.772688627243042, "vf_explained_var": 0.9385201930999756, "kl": 0.009231679141521454, "entropy": 1.3699108362197876, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.39562076330184937, "policy_loss": -0.0355679914355278, "vf_loss": 0.42886286973953247, "vf_explained_var": 0.8976520895957947, "kl": 0.011629516258835793, "entropy": 1.352089762687683, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.536932945251465, "policy_loss": -0.03838604316115379, "vf_loss": 4.572906970977783, "vf_explained_var": 0.8194454312324524, "kl": 0.012060309760272503, "entropy": 1.371169924736023, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.8266537189483643, "policy_loss": -0.0270500760525465, "vf_loss": 2.851327896118164, "vf_explained_var": 0.9298190474510193, "kl": 0.011878165416419506, "entropy": 1.3543506860733032, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 20000, "num_steps_trained": 20000}, "done": false, "episodes_total": 186, "training_iteration": 5, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-04-58", "timestamp": 1638381898, "time_this_iter_s": 146.76025223731995, "time_total_s": 717.8610105514526, "pid": 58275, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f8569320>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f8569440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8569680>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff710>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff5f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8569680>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff710>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff5f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8569680>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff710>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff5f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8569680>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff710>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84ff5f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f852d290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 146.76025223731995, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.49858490566038, "ram_util_percent": 81.95283018867926}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -142.20913830622837, "episode_reward_min": -663.8300893238709, "episode_reward_mean": -391.42474203686305, "episode_len_mean": 103.97368421052632, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-3": -270.50011349149986, "AGENT-1": -31.78119139176834, "AGENT-2": -209.86497289376769, "AGENT-0": -309.86214984899885}, "policy_reward_max": {"AGENT-3": -64.67847525615232, "AGENT-1": 16.012842603604753, "AGENT-2": 16.181328831437508, "AGENT-0": -64.67275446021128}, "policy_reward_mean": {"AGENT-3": -176.2604738371249, "AGENT-1": -6.343382852946936, "AGENT-2": -9.811117397982919, "AGENT-0": -199.00976794880833}, "custom_metrics": {"mean_ego_speed_mean": 33.51791118421052, "mean_ego_speed_min": 28.25, "mean_ego_speed_max": 39.06275, "distance_travelled_mean": 57.13007565789473, "distance_travelled_min": 36.411750000000005, "distance_travelled_max": 76.785}, "hist_stats": {"episode_reward": [-428.0958458411945, -663.8300893238709, -464.5244038802647, -314.86525516336343, -451.2264779747378, -301.6575468846095, -619.144747668608, -224.57634194231275, -439.8031197262914, -232.41212985195807, -574.3091694011343, -421.4696994901496, -542.9324610367491, -209.94489238764822, -463.58103407705437, -301.07630920173006, -550.9555280170798, -212.49175303005245, -450.2368590392134, -341.45100564708747, -461.4068860586368, -263.4497100248805, -410.92625395158586, -303.32116444656845, -401.1983154259661, -279.1517107636714, -480.1462391418051, -293.6311684826048, -428.10762976859, -324.3178858606997, -604.2962223778462, -270.06068424482004, -409.1133774289914, -199.16891932640758, -589.0025242397745, -397.3146104734396, -632.5932067652853, -348.42602935244, -191.40438379907522, -537.7293121073795, -270.9110236658604, -418.305235203709, -332.67975466945757, -477.9862803343443, -278.0396061192272, -464.40915374464373, -313.3238356112747, -482.5020550612223, -294.10692683468426, -399.8086544046917, -305.97873885533255, -596.7541334531448, -280.2909598626203, -445.17761894467594, -348.14262148248275, -539.5676240421544, -375.000617102208, -488.2961953374345, -310.75591411046946, -499.5504209096168, -310.4444850353622, -451.0858750547988, -282.15558294762445, -451.536409460789, -299.65512463039164, -538.2748453566156, -311.0419666644317, -583.5645638739841, -142.20913830622837, -290.82859834907833, -373.91883100336486, -293.909339364588, -484.2256960707416, -272.92941713031803, -501.98996780556564, -205.57228037287888], "episode_lengths": [114, 110, 100, 104, 102, 107, 115, 95, 101, 103, 113, 111, 105, 93, 98, 107, 107, 93, 106, 102, 108, 100, 98, 103, 99, 105, 103, 108, 103, 111, 113, 100, 98, 89, 114, 110, 116, 107, 91, 108, 101, 99, 109, 104, 107, 107, 108, 105, 98, 108, 109, 111, 102, 105, 105, 106, 110, 105, 105, 106, 101, 102, 105, 105, 103, 107, 108, 115, 57, 111, 90, 107, 111, 103, 104, 93], "policy_AGENT-3_reward": [-173.84377464691133, -213.14356502738147, -218.82178265055205, -150.1690931434942, -182.33689125001752, -146.58684601770872, -261.8010195465552, -142.68782844665108, -175.54849910591747, -107.6427291912177, -239.9027977542503, -202.4086982610827, -224.32227857817338, -130.88094559530043, -217.96857755323103, -149.78330413625807, -228.98705432402417, -136.9174232350858, -183.11627337715495, -200.13468680289037, -186.687333686544, -127.84117109865755, -196.8176100976789, -143.09601486042948, -192.13178083656464, -138.9740501117736, -196.84151404860032, -144.8294876468596, -203.61235966416902, -160.26548148090225, -255.6287562064461, -124.16913877022564, -190.6508787009565, -124.22774960074871, -246.6618374365878, -193.449638114149, -270.50011349149986, -164.465581215552, -124.74703710597576, -217.40405005937697, -129.94339849949228, -166.36207786205142, -164.92910780413843, -188.6856359012062, -138.3169448952258, -188.88727859049874, -152.69274494205305, -194.62518592227315, -138.13480046540556, -191.56971145620625, -152.37444048031722, -250.81191976144646, -136.9457467787672, -180.66388712028194, -169.6950372621716, -222.61372685152483, -181.101295401691, -196.5311874030505, -152.27140136326236, -205.17470023171634, -145.92768384572082, -177.49608347543762, -140.9181422038181, -180.20450588155865, -144.1794314553397, -223.6442911709821, -154.8884862012218, -243.82926684209733, -64.67847525615232, -144.94430993251544, -169.11532976625423, -143.40539284559227, -197.1135424958837, -133.26785629902048, -203.5241254069736, -136.3232066725892], "policy_AGENT-1_reward": [-26.34681228506564, 13.647162463518692, -26.86048464889723, 13.927445219254741, -26.979452773370532, 11.246244044394963, -28.026205864863503, 13.160580652136156, -28.050593917035922, 14.51114738657905, -28.416966914190734, 12.213802988339596, -26.13911155596429, 13.745543473562828, -26.51956181248135, 14.990299881484498, -26.564358795142674, 13.640247045460868, -26.182657011734005, 15.673963124403981, -28.239534749033055, 12.751553265728182, -26.32129550722038, 13.263896111918086, -26.258071255933327, 15.142410771277591, -26.689738828301586, 13.901726762717793, -27.781994499824954, 13.645391422392134, -28.409788549339055, 12.153849234233066, -31.78119139176834, 13.517650847463571, -28.99335153124079, 14.110010819194052, -26.112194102243407, 11.185644904657117, 12.05511525584065, -28.44169975960937, 12.165530356903014, -26.377489728482768, 14.912237026577756, -28.38039779953808, 14.974711672912457, -27.527271004036937, 11.587415501321335, -24.60599364850347, 12.203415442426275, -26.62828140335361, 14.566480606103333, -28.326880604704442, 13.003753012114057, -26.14102206596831, 15.921684022955974, -26.796680555229635, 13.66900400058853, -26.420094481859618, 13.129962827428441, -28.09527843372949, 12.139936498398072, -25.765169937066304, 15.603429613969254, -29.775464833493075, 15.530753338510483, -24.78447206330119, 14.94088783185237, -29.319228729337, 13.24782517314932, 14.747719681757715, -29.276284903259246, 12.1820425762345, -30.056913019177163, 12.8603368964273, -26.58876221745925, 16.012842603604753], "policy_AGENT-2_reward": [-26.30810264669629, -209.86497289376769, -26.88650915342771, 13.942444228061358, -26.971193626328564, 11.15294803219823, -28.102796587905164, 13.200654743940545, -28.085203932734654, 14.548600225083556, -28.4480747751593, 12.177427255069373, -26.129414118437595, 13.689224190795343, -26.48354290030339, 15.098111060192547, -26.674976378950014, 13.570708396724699, -26.18157940188648, 15.78386846085067, -28.419121792091882, 12.707628598477882, -26.301993623905858, 13.259712122005544, -26.452218324334037, 15.149812032264144, -26.686776853008432, 13.939091648991452, -27.92742794281079, 13.5857731701071, -28.357332927832235, 12.074578967608767, -31.62744025502341, 13.519958678180995, -28.97121604410964, 14.148601438759398, -26.118749322543163, 11.047655369216649, 12.024055221907009, -28.485742889477336, 12.064383805830994, -26.312359250869896, 14.945466667757538, -28.422840176036456, 15.022238673387164, -27.48259983075028, 11.478050593883072, -24.630461957036708, 12.154972124151147, -26.573633512545214, 14.595940946088346, -28.28240889959285, 12.920012803167218, -26.17873814922014, 16.063672953275756, -26.87469583332774, 13.746316506028327, -26.39786791530253, 13.124570419004483, -28.16365999050926, 12.105730446746085, -25.823341649118824, 15.65510688999294, -29.66881307243869, 15.579469884276643, -24.794075968656802, 14.954158003408242, -29.405918110150797, -26.105733763014083, 14.646615204359858, -29.211242521164987, 12.10216812510178, -29.953704832746308, 12.720677679484208, -26.5601748213033, 16.181328831437508], "policy_AGENT-0_reward": [-201.59715626252125, -254.4687138662402, -191.9556274273879, -192.5660514671851, -214.93894032502118, -177.469892943494, -301.21472566928384, -108.2497488917385, -208.11882277060334, -153.82914827240288, -277.5413299575342, -243.45223147247566, -266.3416567841739, -106.49871445670597, -192.6093518110387, -181.38141600714908, -268.7291385189631, -102.78528523715211, -214.75634924843826, -172.7741504294519, -218.06089583096787, -161.0677207904291, -161.4853547227807, -186.7487578200625, -156.35624500913383, -170.46988345543957, -229.92820941189433, -176.6424992474545, -168.7858476617852, -191.28356897229676, -291.90034469422864, -170.11997367643625, -155.05386708124314, -101.9787792513034, -284.3761192278366, -232.12358461724412, -309.86214984899885, -206.19374841076188, -90.73651717084707, -263.3978193989158, -165.1975393291022, -199.253308362305, -197.60835055965418, -232.497406457564, -169.719611570301, -220.5120043193579, -183.69655676442613, -238.64041353340917, -180.33051393585612, -155.0370280325868, -182.76671992720716, -289.33292418740155, -169.26897889913442, -212.19397160920573, -210.4329411965425, -263.282520802072, -221.31464220713377, -238.94704553722207, -184.73904599364002, -238.11678225366148, -188.7624681347856, -222.0012799931758, -172.49597724776856, -211.88762567329883, -186.58591639783907, -265.0520061536751, -186.04852629847062, -281.010150192399, -64.67275446021128, -175.2786233026805, -146.3159738126866, -174.78815722033195, -227.10153572293456, -165.24257540720905, -245.31690535982963, -101.4432451353321]}, "sampler_perf": {"mean_env_wait_ms": 30.64872285409345, "mean_processing_ms": 2.133894187384772, "mean_inference_ms": 1.3787460839490673}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24000, "timers": {"sample_time_ms": 137423.481, "sample_throughput": 29.107, "load_time_ms": 394.129, "load_throughput": 10148.951, "learn_time_ms": 6339.648, "learn_throughput": 630.95, "update_time_ms": 5.099}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.0019583702087402, "policy_loss": -0.021952202543616295, "vf_loss": 2.0218770503997803, "vf_explained_var": 0.9606704115867615, "kl": 0.010167825035750866, "entropy": 1.3604539632797241, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.08683615922927856, "policy_loss": -0.038001902401447296, "vf_loss": 0.12082934379577637, "vf_explained_var": 0.9850645065307617, "kl": 0.020043514668941498, "entropy": 1.3225294351577759, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.27200907468795776, "policy_loss": -0.038575880229473114, "vf_loss": 0.3078770041465759, "vf_explained_var": 0.980060875415802, "kl": 0.013539706356823444, "entropy": 1.356637716293335, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 1.5715246200561523, "policy_loss": -0.0260759424418211, "vf_loss": 1.5949393510818481, "vf_explained_var": 0.9484944343566895, "kl": 0.013306536711752415, "entropy": 1.3481347560882568, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 24000, "num_steps_trained": 24000}, "done": false, "episodes_total": 224, "training_iteration": 6, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-07-22", "timestamp": 1638382042, "time_this_iter_s": 144.13029098510742, "time_total_s": 861.9913015365601, "pid": 58275, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f852d830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f852d950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f852db90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852dcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852ddd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852def0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f852db90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852dcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852ddd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852def0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f852db90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852dcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852ddd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852def0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f852db90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852dcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852ddd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852def0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f852d0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 290.89054322242737, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 18.638834951456314, "ram_util_percent": 81.66456310679612}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 324.8578708275969, "episode_reward_min": -187.68619894027734, "episode_reward_mean": 51.81031674660936, "episode_len_mean": 105.13157894736842, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-1": -101.92011686400181, "AGENT-0": -87.17719158056441, "AGENT-3": -47.92079027308018, "AGENT-2": -101.80398986616422}, "policy_reward_max": {"AGENT-1": 8.614480383643137, "AGENT-0": 219.418967452627, "AGENT-3": 199.5586826234673, "AGENT-2": 1.8192179016066206}, "policy_reward_mean": {"AGENT-1": -67.7335023469396, "AGENT-0": 88.09229149505795, "AGENT-3": 99.3506886744461, "AGENT-2": -67.89916107595509}, "custom_metrics": {"mean_ego_speed_mean": 38.01165789473685, "mean_ego_speed_min": 28.096, "mean_ego_speed_max": 44.9925, "distance_travelled_mean": 58.69032236842104, "distance_travelled_min": 52.9035, "distance_travelled_max": 76.76350000000001}, "hist_stats": {"episode_reward": [120.59799458739788, -13.829499372077457, 258.2956305178422, 12.086022919974729, 169.45796321361115, 42.60809526416692, 219.1047393910969, -65.40226304956136, 324.8578708275969, -44.478238215083515, 114.66851655341549, -160.234042253704, 185.5034085537142, -81.86292633708916, 233.89456612704433, -95.53965773687315, 280.1097303567678, 45.55960582807137, 230.15669492953714, -187.68619894027734, -124.66428356839486, -73.64024785755414, 120.46578782618002, -92.01021670912013, 115.71435955396288, -106.90494725263409, 171.4696921646299, 83.85961667161968, 222.243379666703, -141.0297315503312, 34.97320121274732, -95.52966457590631, 143.20388919190992, -104.54675307795338, 175.98818355661018, -113.26110077475363, 179.70624863399325, -15.113389906124073], "episode_lengths": [108, 93, 102, 98, 103, 100, 99, 111, 121, 96, 105, 116, 111, 108, 96, 107, 120, 97, 91, 100, 104, 102, 107, 108, 110, 119, 94, 125, 101, 104, 101, 115, 110, 108, 106, 101, 96, 102], "policy_AGENT-1_reward": [-40.374279365050604, -98.3877613255222, -40.61118970743679, -99.24658713145773, -40.22967808979516, -99.82674719057319, -41.2711869851658, -99.95011432013267, -40.72192020978111, -91.67825955324818, -40.61646752883935, -99.12737146328712, -42.56699707802131, -98.93752628847878, -40.93053677283754, -93.27205801637871, -41.37385879126859, -96.71962598699352, -39.92515736779366, -95.97000168492102, 8.614480383643137, -97.98477974480713, -40.630074824920435, -94.99184592595086, -38.65284135160512, -98.76682948973317, -41.60941704095225, -97.16850250391381, -42.95489304426855, -94.6183976907462, -40.569193075544014, -101.92011686400181, -41.67877232276626, -94.51874777933952, -40.35957068105523, -98.49235891076788, -40.6047249156698, -95.22917854432265], "policy_AGENT-0_reward": [79.8489690592922, 106.87132741172297, 185.62358861697436, 120.90056376014536, 106.68094785757395, 136.4943250119149, 164.81882380969398, 49.94499731777805, 219.418967452627, 94.3519700424764, 77.97774236190556, 0.18141223804644824, 117.52510844541737, 38.417910230039055, 173.44753603282172, 26.201305311426864, 163.42294161183398, 134.89275689688907, 170.21568931018663, -19.548831969573307, -87.17719158056441, 43.140755812529235, 80.99270640391421, 28.531847022712327, 77.03552054166475, 27.27557234184254, 140.51917096326724, 121.11851422932449, 168.44930643142982, 3.884441028025414, 35.01800561906817, 35.528484176496626, 92.58459453057765, 22.56998114921437, 109.60321945612242, 56.15379613458697, 142.27061593725992, 102.31968580553706], "policy_AGENT-3_reward": [121.45385438593334, 76.06658193649618, 153.83654105800085, 89.71195042032238, 143.1764538944706, 105.61380707883987, 136.8353415760048, 84.55008668614369, 186.84311356344512, 44.6145038702488, 117.9294378485654, 37.76680759477776, 153.2317796702194, 77.56935195575677, 142.33520554026867, 64.81142493415524, 199.5586826234673, 104.15724573507276, 139.83154869900775, 23.723336518329262, -47.92079027308018, 79.12733437761904, 120.7046567524242, 69.38848767507035, 115.86366023591629, 63.27375740055313, 114.14580873666561, 157.10603302894302, 139.70357322030875, 44.3126432320428, 81.10376664396463, 72.66595797776341, 134.0474425431271, 61.898171533264225, 147.15023338385225, 27.54286510294125, 118.5631523384784, 73.0323601295724], "policy_AGENT-2_reward": [-40.33054949277705, -98.3796473947746, -40.553309449696236, -99.27990412903529, -40.16976044863825, -99.67328963601447, -41.27823900943608, -99.94723273335089, -40.682289978694094, -91.76645257456055, -40.62219612821613, -99.054890623241, -42.686482483901194, -98.91266223440616, -40.957638673208464, -93.28032996607638, -41.49803508726498, -96.7707708168971, -39.965385711863604, -95.89070180411238, 1.8192179016066206, -97.92355830289516, -40.601500505237915, -94.93870548095194, -38.531979872013046, -98.68744750529676, -41.58587049435077, -97.19642808273376, -42.954606940767036, -94.60841811965321, -40.579377974741504, -101.80398986616422, -41.74937555902845, -94.49615798109255, -40.40569860230919, -98.4654031015137, -40.52279472607519, -95.23625729691071]}, "sampler_perf": {"mean_env_wait_ms": 31.455429218256967, "mean_processing_ms": 2.0644043243339545, "mean_inference_ms": 1.4489693392577452}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28000, "timers": {"sample_time_ms": 140380.32, "sample_throughput": 28.494, "load_time_ms": 823.637, "load_throughput": 4856.506, "learn_time_ms": 7032.588, "learn_throughput": 568.781, "update_time_ms": 5.398}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 44.43623352050781, "policy_loss": -0.02179393731057644, "vf_loss": 44.45587921142578, "vf_explained_var": 0.8803168535232544, "kl": 0.010694309137761593, "entropy": 1.33574378490448, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 66.66883087158203, "policy_loss": -0.03614969924092293, "vf_loss": 66.70282745361328, "vf_explained_var": 0.2544247806072235, "kl": 0.010762723162770271, "entropy": 1.3467679023742676, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 62.15105056762695, "policy_loss": -0.03398323431611061, "vf_loss": 62.18372344970703, "vf_explained_var": 0.3050468862056732, "kl": 0.006561814807355404, "entropy": 1.3312309980392456, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 18.213096618652344, "policy_loss": -0.02233320288360119, "vf_loss": 18.233476638793945, "vf_explained_var": 0.9319520592689514, "kl": 0.00977090373635292, "entropy": 1.3323365449905396, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 28000, "num_steps_trained": 28000}, "done": false, "episodes_total": 262, "training_iteration": 7, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-11-27", "timestamp": 1638382287, "time_this_iter_s": 150.65764474868774, "time_total_s": 1012.6489462852478, "pid": 59197, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f8569320>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f85693b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852d440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852d200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852d440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852d200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852d440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852d200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f852d440>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f852d200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f84e9b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 150.65764474868774, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.420183486238532, "ram_util_percent": 87.10366972477064}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -270.6525463361516, "episode_reward_min": -835.9739235135736, "episode_reward_mean": -488.2875260002925, "episode_len_mean": 102.89473684210526, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-3": -283.5663885315001, "AGENT-1": -107.42199430390633, "AGENT-2": -270.24776093849295, "AGENT-0": -318.75961810304494}, "policy_reward_max": {"AGENT-3": -109.16271081439538, "AGENT-1": -24.47075651503271, "AGENT-2": -24.502962606671662, "AGENT-0": -107.64040564983793}, "policy_reward_mean": {"AGENT-3": -199.85670342562477, "AGENT-1": -30.100535830592033, "AGENT-2": -37.8725118900019, "AGENT-0": -220.45777485407373}, "custom_metrics": {"mean_ego_speed_mean": 32.68627631578947, "mean_ego_speed_min": 24.354, "mean_ego_speed_max": 37.832, "distance_travelled_mean": 56.14365131578948, "distance_travelled_min": 25.77825, "distance_travelled_max": 70.39775}, "hist_stats": {"episode_reward": [-521.8809192451001, -457.0449896609586, -558.2913673198335, -547.7206445730523, -630.380967398908, -399.36717974609303, -835.9739235135736, -413.5299709978075, -526.6132157988521, -577.29682156725, -382.94396132742474, -596.2901984913042, -464.4630106260523, -497.6441148306536, -450.42399616570094, -389.5486386560395, -493.17347446961145, -447.0805793330341, -540.6469624795376, -492.14558712397735, -453.4509012381968, -502.638378413249, -463.1433025387347, -475.08465662885203, -544.6895985055467, -504.82299835265576, -518.7014894940284, -428.0795790932421, -437.8707594680977, -411.4000731411824, -588.9538769040549, -270.6525463361516, -352.56557995718674, -438.31401395629575, -428.76016288575323, -659.4227613957876, -444.01722002975396, -409.89756634757765], "episode_lengths": [112, 107, 109, 107, 116, 96, 118, 99, 113, 102, 94, 110, 104, 113, 105, 99, 113, 103, 108, 106, 101, 71, 109, 105, 106, 106, 119, 100, 99, 100, 113, 31, 91, 102, 104, 122, 101, 96], "policy_AGENT-3_reward": [-215.34802185521937, -184.92363392523305, -231.258941124669, -228.01053953360906, -266.573015911094, -187.26623732677203, -237.67954972101407, -197.8987097747493, -216.15673327167391, -203.86243284136495, -181.24607902202123, -248.56979720706516, -185.23342453391376, -205.17947049828783, -184.99858842216562, -184.121829309836, -201.46265888636094, -178.5079744893399, -225.20980231595598, -198.79514441619517, -183.35937193937804, -224.385996708538, -190.01292390635462, -193.31691223849046, -223.29612274760262, -206.01361659312386, -210.0137891054501, -168.27353415456193, -166.75912626168582, -150.92857004497324, -245.8736664993445, -109.16271081439538, -166.26019475112628, -175.45059941797746, -171.26320392861706, -283.5663885315001, -170.97610849950374, -193.3393096445783], "policy_AGENT-1_reward": [-29.955325953784193, -28.00124533263527, -28.165580698368924, -25.825562200581217, -29.940321195475388, -29.807417146253442, -26.134155918951997, -26.531684136787966, -27.374203409368825, -107.42199430390633, -27.34716883304211, -30.048409703168584, -30.541988174925166, -28.383115067966866, -24.597878406480064, -28.066662980712294, -29.91757348485691, -28.687497694441817, -24.47075651503271, -26.07616922393995, -26.910572045600933, -26.96169375437362, -26.123115497413053, -28.54282954448932, -28.420964956805584, -25.770950852825873, -33.67959246318932, -29.2728568626304, -29.69861884101478, -30.452450198565685, -28.341321395302046, -26.128805554851784, -27.377852449639104, -27.420616003218484, -26.005162989301624, -28.54174471231584, -27.852996993513347, -29.023506066765936], "policy_AGENT-2_reward": [-29.900686161618204, -28.040756931902287, -28.192737930323144, -25.930346159867142, -29.914887204551153, -29.738301477661206, -270.24776093849295, -26.51676849571151, -27.411481701764597, -158.37198877214087, -27.29074193710037, -30.08069758154313, -30.437908662317398, -28.458563995629902, -24.55365016501321, -28.091406124007946, -29.784218190215228, -28.750727836369602, -24.502962606671662, -26.131058145415412, -26.8874501041151, -26.94580525015362, -26.09028714944895, -28.536087106595364, -28.374040537263788, -25.72436927910196, -33.707360752778975, -29.18919232593435, -29.631863352776342, -30.54184121127814, -28.530863672030858, -26.161303147290575, -27.327251387822514, -27.51174569598093, -26.052763909405048, -28.555010048926192, -27.943030284728117, -29.097535586124724], "policy_AGENT-0_reward": [-246.67688527447854, -216.0793534711877, -270.6741075664727, -267.9541966789953, -303.9527430877872, -152.55522379540645, -301.9124569351142, -162.58280859055898, -255.67079741604482, -107.64040564983793, -147.05997153526067, -287.59129399952764, -218.24968925489605, -235.62296526876887, -216.27387917204211, -149.26874024148327, -232.0090239081785, -211.13437931288274, -266.4634410418772, -241.14321533842644, -216.29350714910305, -224.34488270018392, -220.91697598551792, -224.68882773927677, -264.5984702638748, -247.31406162760408, -241.30074717261, -201.3439957501155, -211.7811510126209, -199.4772116863653, -286.2080253373774, -109.19972681961393, -131.6002813685989, -207.9310528391189, -205.43903205842952, -318.75961810304494, -217.24508425200898, -158.43721505010893]}, "sampler_perf": {"mean_env_wait_ms": 31.91046308380639, "mean_processing_ms": 2.2107514998996836, "mean_inference_ms": 1.4701239975116698}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28000, "timers": {"sample_time_ms": 142891.113, "sample_throughput": 27.993, "load_time_ms": 807.189, "load_throughput": 4955.468, "learn_time_ms": 6773.316, "learn_throughput": 590.553, "update_time_ms": 5.83}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.006866455078125, "policy_loss": -0.02250455878674984, "vf_loss": 3.027193546295166, "vf_explained_var": 0.9670312404632568, "kl": 0.010888946242630482, "entropy": 1.3507888317108154, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.8081107139587402, "policy_loss": -0.012669817544519901, "vf_loss": 3.819859504699707, "vf_explained_var": 0.7474073767662048, "kl": 0.004605637397617102, "entropy": 1.3143796920776367, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 5.314201831817627, "policy_loss": -0.028737539425492287, "vf_loss": 5.341510772705078, "vf_explained_var": 0.7904912829399109, "kl": 0.0071449135430157185, "entropy": 1.3614236116409302, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.181273937225342, "policy_loss": -0.024429630488157272, "vf_loss": 4.203619480133057, "vf_explained_var": 0.9398937225341797, "kl": 0.010422212071716785, "entropy": 1.3304290771484375, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 28000, "num_steps_trained": 28000}, "done": false, "episodes_total": 262, "training_iteration": 7, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-16-05", "timestamp": 1638382565, "time_this_iter_s": 152.90191435813904, "time_total_s": 1014.8932158946991, "pid": 59741, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f856e560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f851a320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f849ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 152.90191435813904, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 23.447963800904976, "ram_util_percent": 90.9552036199095}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -270.6525463361516, "episode_reward_min": -835.9739235135736, "episode_reward_mean": -494.8040073043175, "episode_len_mean": 106.86486486486487, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -329.9148150639479, "AGENT-1": -107.42199430390633, "AGENT-2": -270.24776093849295, "AGENT-0": -361.345481128498}, "policy_reward_max": {"AGENT-3": -104.22030786583535, "AGENT-1": -24.21405021278671, "AGENT-2": -24.34970781518132, "AGENT-0": -84.72860142048636}, "policy_reward_mean": {"AGENT-3": -205.71659382566367, "AGENT-1": -30.057917812342954, "AGENT-2": -35.80934994328841, "AGENT-0": -223.22014572302243}, "custom_metrics": {"mean_ego_speed_mean": 32.194763513513514, "mean_ego_speed_min": 22.7285, "mean_ego_speed_max": 39.0065, "distance_travelled_mean": 56.65369256756756, "distance_travelled_min": 25.77825, "distance_travelled_max": 70.39775}, "hist_stats": {"episode_reward": [-470.5762597471834, -465.23717462876516, -520.7906002174209, -441.87903461664087, -418.24653141557445, -581.1273120482807, -397.1850952303471, -635.804956439402, -559.2596150164252, -565.7994168989752, -516.1551442237144, -338.6945300058822, -477.8418785141042, -497.31038301228074, -414.74111371391507, -379.58478421600955, -617.3855432517937, -441.6067380922919, -432.2391546130881, -639.2287577466607, -402.7746685454946, -433.93297483570285, -499.4457082032999, -518.6983769723313, -550.134621699272, -512.302395178114, -476.20183809329336, -582.3100152613165, -459.298068207754, -308.08381067502705, -730.9954731364629, -476.75688209077214, -758.7828649715636, -563.3816265634013, -515.4844794363481, -461.2927249894751, -521.8809192451001, -457.0449896609586, -558.2913673198335, -547.7206445730523, -630.380967398908, -399.36717974609303, -835.9739235135736, -413.5299709978075, -526.6132157988521, -577.29682156725, -382.94396132742474, -596.2901984913042, -464.4630106260523, -497.6441148306536, -450.42399616570094, -389.5486386560395, -493.17347446961145, -447.0805793330341, -540.6469624795376, -492.14558712397735, -453.4509012381968, -502.638378413249, -463.1433025387347, -475.08465662885203, -544.6895985055467, -504.82299835265576, -518.7014894940284, -428.0795790932421, -437.8707594680977, -411.4000731411824, -588.9538769040549, -270.6525463361516, -352.56557995718674, -438.31401395629575, -428.76016288575323, -659.4227613957876, -444.01722002975396, -409.89756634757765], "episode_lengths": [106, 138, 105, 106, 97, 111, 99, 122, 109, 110, 113, 86, 117, 105, 110, 100, 95, 94, 104, 122, 96, 97, 110, 112, 112, 137, 131, 114, 103, 97, 136, 115, 139, 145, 103, 102, 112, 107, 109, 107, 116, 96, 118, 99, 113, 102, 94, 110, 104, 113, 105, 99, 113, 103, 108, 106, 101, 71, 109, 105, 106, 106, 119, 100, 99, 100, 113, 31, 91, 102, 104, 122, 101, 96], "policy_AGENT-3_reward": [-188.65106459095605, -221.86335006009637, -210.45510949694616, -168.67651050713323, -195.54700431525455, -245.02619077670832, -187.4692717295471, -270.49536228754937, -226.43515095211978, -233.81732712446652, -211.3557673250834, -155.21760453289363, -197.08354967051312, -196.46106091185834, -199.56281524682868, -139.48978252633728, -211.74048718100735, -205.9652226143428, -206.0695982266846, -276.2426672106368, -189.49776360853264, -198.5409024987996, -205.0268592454545, -207.78784490780822, -227.98527989755192, -212.86096397241838, -196.56096133915284, -246.64073379379312, -179.00392406775316, -104.22030786583535, -323.38316709212074, -196.23384659368625, -329.9148150639479, -237.21419387617257, -243.2391284909763, -182.73762332440117, -215.34802185521937, -184.92363392523305, -231.258941124669, -228.01053953360906, -266.573015911094, -187.26623732677203, -237.67954972101407, -197.8987097747493, -216.15673327167391, -203.86243284136495, -181.24607902202123, -248.56979720706516, -185.23342453391376, -205.17947049828783, -184.99858842216562, -184.121829309836, -201.46265888636094, -178.5079744893399, -225.20980231595598, -198.79514441619517, -183.35937193937804, -224.385996708538, -190.01292390635462, -193.31691223849046, -223.29612274760262, -206.01361659312386, -210.0137891054501, -168.27353415456193, -166.75912626168582, -150.92857004497324, -245.8736664993445, -109.16271081439538, -166.26019475112628, -175.45059941797746, -171.26320392861706, -283.5663885315001, -170.97610849950374, -193.3393096445783], "policy_AGENT-1_reward": [-30.9335447578136, -29.299016273771947, -29.041364833201314, -28.568905140959792, -31.01665479825484, -26.41020863007204, -28.717114165405754, -28.784928468406154, -30.76841768934486, -27.915030755996245, -31.43987551794358, -29.625286304954344, -26.684846893182343, -36.122825608113985, -25.76769449777035, -25.99049973499422, -24.21405021278671, -28.051628674565386, -28.03156024912506, -26.086046282012575, -28.062086861875866, -30.58660982880937, -29.103579472278, -27.78141548038998, -25.90185911372759, -27.857674833033187, -26.56244319691513, -24.332137301429555, -28.48099293381824, -84.73186090964653, -25.74354345084613, -26.682285871218937, -33.77104278040857, -28.1794845025414, -27.674359132502715, -31.544681392765384, -29.955325953784193, -28.00124533263527, -28.165580698368924, -25.825562200581217, -29.940321195475388, -29.807417146253442, -26.134155918951997, -26.531684136787966, -27.374203409368825, -107.42199430390633, -27.34716883304211, -30.048409703168584, -30.541988174925166, -28.383115067966866, -24.597878406480064, -28.066662980712294, -29.91757348485691, -28.687497694441817, -24.47075651503271, -26.07616922393995, -26.910572045600933, -26.96169375437362, -26.123115497413053, -28.54282954448932, -28.420964956805584, -25.770950852825873, -33.67959246318932, -29.2728568626304, -29.69861884101478, -30.452450198565685, -28.341321395302046, -26.128805554851784, -27.377852449639104, -27.420616003218484, -26.005162989301624, -28.54174471231584, -27.852996993513347, -29.023506066765936], "policy_AGENT-2_reward": [-30.90822392674347, -29.273518279726186, -29.01047455392334, -28.4970486499866, -30.995852193321163, -26.467552581886203, -28.723769503505427, -28.875405692878033, -30.792261801333503, -28.024080986521284, -31.318830256614106, -29.56204235195389, -26.64623477178646, -36.16997949815748, -25.915343003956032, -26.018742460998634, -204.35372471387763, -28.035081275370718, -28.126522533966675, -26.071672623075276, -28.17648932640023, -30.616401327950776, -29.07699440366912, -27.87575181935396, -26.001414948330375, -27.889095214461587, -26.48800257909003, -24.34970781518132, -28.476801441745266, -34.403040479059, -25.752576244691276, -26.676487136538437, -33.751525998709056, -28.244571079813888, -27.717293500145445, -31.453929008548215, -29.900686161618204, -28.040756931902287, -28.192737930323144, -25.930346159867142, -29.914887204551153, -29.738301477661206, -270.24776093849295, -26.51676849571151, -27.411481701764597, -158.37198877214087, -27.29074193710037, -30.08069758154313, -30.437908662317398, -28.458563995629902, -24.55365016501321, -28.091406124007946, -29.784218190215228, -28.750727836369602, -24.502962606671662, -26.131058145415412, -26.8874501041151, -26.94580525015362, -26.09028714944895, -28.536087106595364, -28.374040537263788, -25.72436927910196, -33.707360752778975, -29.18919232593435, -29.631863352776342, -30.54184121127814, -28.530863672030858, -26.161303147290575, -27.327251387822514, -27.51174569598093, -26.052763909405048, -28.555010048926192, -27.943030284728117, -29.097535586124724], "policy_AGENT-0_reward": [-220.08342647167038, -184.8012900151705, -252.2836513333499, -216.13657031856124, -160.6870201087438, -283.22336005961455, -152.27493983188896, -307.64925999056845, -271.2637845736269, -276.04297803199063, -242.0406711240735, -124.28959681608025, -227.42724717862225, -228.55651699415068, -163.49526096536, -188.08575949367935, -177.07728114412217, -179.55480552801288, -170.0114736033115, -310.8283716309357, -157.0383287486858, -174.18906118014328, -236.23827508189817, -255.25336476477915, -270.2460677396624, -243.69466115820052, -226.59043097813492, -286.98743635091245, -223.33634976443716, -84.72860142048636, -356.116186348805, -227.16426248932822, -361.345481128498, -269.7433771048735, -216.8536983127228, -215.5564912637605, -246.67688527447854, -216.0793534711877, -270.6741075664727, -267.9541966789953, -303.9527430877872, -152.55522379540645, -301.9124569351142, -162.58280859055898, -255.67079741604482, -107.64040564983793, -147.05997153526067, -287.59129399952764, -218.24968925489605, -235.62296526876887, -216.27387917204211, -149.26874024148327, -232.0090239081785, -211.13437931288274, -266.4634410418772, -241.14321533842644, -216.29350714910305, -224.34488270018392, -220.91697598551792, -224.68882773927677, -264.5984702638748, -247.31406162760408, -241.30074717261, -201.3439957501155, -211.7811510126209, -199.4772116863653, -286.2080253373774, -109.19972681961393, -131.6002813685989, -207.9310528391189, -205.43903205842952, -318.75961810304494, -217.24508425200898, -158.43721505010893]}, "sampler_perf": {"mean_env_wait_ms": 31.491055457421822, "mean_processing_ms": 2.1540943295629864, "mean_inference_ms": 1.426087748136458}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 32000, "timers": {"sample_time_ms": 138417.284, "sample_throughput": 28.898, "load_time_ms": 409.032, "load_throughput": 9779.198, "learn_time_ms": 6018.668, "learn_throughput": 664.599, "update_time_ms": 5.736}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 1.6204653978347778, "policy_loss": -0.02143017016351223, "vf_loss": 1.6399835348129272, "vf_explained_var": 0.9785961508750916, "kl": 0.009559664875268936, "entropy": 1.3435614109039307, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.10000000149011612, "cur_lr": 9.999999747378752e-05, "total_loss": 4.073048114776611, "policy_loss": -0.015534467063844204, "vf_loss": 4.088032245635986, "vf_explained_var": 0.7843489646911621, "kl": 0.005505824461579323, "entropy": 1.3061919212341309, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 0.3482380509376526, "policy_loss": -0.05318380519747734, "vf_loss": 0.39950019121170044, "vf_explained_var": 0.8639650940895081, "kl": 0.009608408436179161, "entropy": 1.3525375127792358, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 1.082074761390686, "policy_loss": -0.03498394414782524, "vf_loss": 1.1140981912612915, "vf_explained_var": 0.9781818389892578, "kl": 0.014802242629230022, "entropy": 1.3147848844528198, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 32000, "num_steps_trained": 32000}, "done": false, "episodes_total": 298, "training_iteration": 8, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-18-24", "timestamp": 1638382704, "time_this_iter_s": 139.2413580417633, "time_total_s": 1154.1345739364624, "pid": 59741, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f84e9ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f84e90e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e94d0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e94d0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e94d0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f84e95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e94d0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f849a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 292.14327239990234, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 18.44170854271357, "ram_util_percent": 88.81256281407032}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -230.49105208676286, "episode_reward_min": -758.7828649715636, "episode_reward_mean": -501.9018930013398, "episode_len_mean": 107.64, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -329.9148150639479, "AGENT-1": -84.78649353171238, "AGENT-2": -204.35372471387763, "AGENT-0": -361.345481128498}, "policy_reward_max": {"AGENT-3": -16.51815696744444, "AGENT-1": -24.21405021278671, "AGENT-2": -24.320180291031377, "AGENT-0": -84.72860142048636}, "policy_reward_mean": {"AGENT-3": -213.74555222409032, "AGENT-1": -29.18263751750175, "AGENT-2": -30.09590397334803, "AGENT-0": -228.87779928639964}, "custom_metrics": {"mean_ego_speed_mean": 31.915720000000007, "mean_ego_speed_min": 22.7285, "mean_ego_speed_max": 39.0065, "distance_travelled_mean": 56.31804, "distance_travelled_min": 25.77825, "distance_travelled_max": 65.617}, "hist_stats": {"episode_reward": [-606.0696873715822, -602.3954967047958, -569.8729850744281, -663.2886376329816, -549.7643749989255, -630.082546377699, -741.9877675789171, -511.6082290907943, -411.53065094337, -596.4751246569429, -467.4388928769017, -440.62429536784094, -534.619478690631, -508.35329602473826, -515.9860693087264, -548.6587403924351, -466.0326540727568, -555.1441859692073, -507.8638399265152, -416.53861156294715, -687.7044038544924, -617.3437137766515, -461.4668214573374, -613.8021290344686, -636.4155885377663, -496.923062887633, -374.46715471858107, -436.625931143634, -563.2046232631883, -493.3452168826547, -607.3298949558356, -230.49105208676286, -501.0081136700504, -452.82691411626166, -451.1173799700891, -432.6925841836223, -524.6365716011694, -596.2901984913042, -464.4630106260523, -497.6441148306536, -450.42399616570094, -389.5486386560395, -493.17347446961145, -447.0805793330341, -540.6469624795376, -492.14558712397735, -453.4509012381968, -502.638378413249, -463.1433025387347, -475.08465662885203, -544.6895985055467, -504.82299835265576, -518.7014894940284, -428.0795790932421, -437.8707594680977, -411.4000731411824, -588.9538769040549, -270.6525463361516, -352.56557995718674, -438.31401395629575, -428.76016288575323, -659.4227613957876, -444.01722002975396, -409.89756634757765, -470.5762597471834, -465.23717462876516, -520.7906002174209, -441.87903461664087, -418.24653141557445, -581.1273120482807, -397.1850952303471, -635.804956439402, -559.2596150164252, -565.7994168989752, -516.1551442237144, -338.6945300058822, -477.8418785141042, -497.31038301228074, -414.74111371391507, -379.58478421600955, -617.3855432517937, -441.6067380922919, -432.2391546130881, -639.2287577466607, -402.7746685454946, -433.93297483570285, -499.4457082032999, -518.6983769723313, -550.134621699272, -512.302395178114, -476.20183809329336, -582.3100152613165, -459.298068207754, -308.08381067502705, -730.9954731364629, -476.75688209077214, -758.7828649715636, -563.3816265634013, -515.4844794363481, -461.2927249894751], "episode_lengths": [119, 79, 111, 121, 125, 119, 129, 119, 107, 113, 104, 106, 69, 105, 132, 80, 108, 111, 109, 106, 121, 116, 108, 127, 118, 111, 91, 100, 113, 107, 128, 78, 106, 99, 102, 113, 119, 110, 104, 113, 105, 99, 113, 103, 108, 106, 101, 71, 109, 105, 106, 106, 119, 100, 99, 100, 113, 31, 91, 102, 104, 122, 101, 96, 106, 138, 105, 106, 97, 111, 99, 122, 109, 110, 113, 86, 117, 105, 110, 100, 95, 94, 104, 122, 96, 97, 110, 112, 112, 137, 131, 114, 103, 97, 136, 115, 139, 145, 103, 102], "policy_AGENT-3_reward": [-290.1772679741623, -273.3571285600013, -237.93312739888714, -286.2434452154289, -230.48843893194328, -267.63070668532504, -326.00209632413754, -253.65773808978867, -197.19866909985197, -250.6740186364545, -186.96925067320245, -208.3280538702813, -238.50240591122363, -198.5253786014622, -216.21224084146792, -245.9103362136434, -188.88874098885074, -228.9372456492068, -211.55642598430035, -198.29568917416057, -299.56606255041964, -263.1467898336877, -182.98492362287482, -302.4507717923732, -307.24386198458427, -205.79789546283416, -177.62003465974976, -170.02781069483285, -280.7792756149554, -202.3442184860799, -295.07932235958873, -16.51815696744444, -206.76585529801923, -213.29772151148745, -214.43432175339154, -208.4603323996284, -219.74541380161253, -248.56979720706516, -185.23342453391376, -205.17947049828783, -184.99858842216562, -184.121829309836, -201.46265888636094, -178.5079744893399, -225.20980231595598, -198.79514441619517, -183.35937193937804, -224.385996708538, -190.01292390635462, -193.31691223849046, -223.29612274760262, -206.01361659312386, -210.0137891054501, -168.27353415456193, -166.75912626168582, -150.92857004497324, -245.8736664993445, -109.16271081439538, -166.26019475112628, -175.45059941797746, -171.26320392861706, -283.5663885315001, -170.97610849950374, -193.3393096445783, -188.65106459095605, -221.86335006009637, -210.45510949694616, -168.67651050713323, -195.54700431525455, -245.02619077670832, -187.4692717295471, -270.49536228754937, -226.43515095211978, -233.81732712446652, -211.3557673250834, -155.21760453289363, -197.08354967051312, -196.46106091185834, -199.56281524682868, -139.48978252633728, -211.74048718100735, -205.9652226143428, -206.0695982266846, -276.2426672106368, -189.49776360853264, -198.5409024987996, -205.0268592454545, -207.78784490780822, -227.98527989755192, -212.86096397241838, -196.56096133915284, -246.64073379379312, -179.00392406775316, -104.22030786583535, -323.38316709212074, -196.23384659368625, -329.9148150639479, -237.21419387617257, -243.2391284909763, -182.73762332440117], "policy_AGENT-1_reward": [-29.183300507794378, -27.827779552410266, -27.468997639853324, -26.502354788386203, -29.156856081420745, -28.511326849074717, -28.27554984658576, -25.98725421860373, -26.725880103961625, -28.99715571977494, -24.311220280589698, -29.790421635407633, -28.741654382219533, -33.95323989418635, -26.51515142349028, -28.538551443248558, -28.42433844126616, -28.672144339357043, -25.769647905337546, -27.817261451316668, -25.93571576374275, -25.958815777991163, -26.124432440382243, -28.154497113580387, -27.24523735168732, -26.6484636561927, -26.330934188665392, -25.58680567183586, -25.824598768201717, -27.440913223322553, -31.960404961489104, -84.78649353171238, -26.240179872295908, -28.853521349437194, -28.80553745243386, -26.011646169164372, -27.404208969531645, -30.048409703168584, -30.541988174925166, -28.383115067966866, -24.597878406480064, -28.066662980712294, -29.91757348485691, -28.687497694441817, -24.47075651503271, -26.07616922393995, -26.910572045600933, -26.96169375437362, -26.123115497413053, -28.54282954448932, -28.420964956805584, -25.770950852825873, -33.67959246318932, -29.2728568626304, -29.69861884101478, -30.452450198565685, -28.341321395302046, -26.128805554851784, -27.377852449639104, -27.420616003218484, -26.005162989301624, -28.54174471231584, -27.852996993513347, -29.023506066765936, -30.9335447578136, -29.299016273771947, -29.041364833201314, -28.568905140959792, -31.01665479825484, -26.41020863007204, -28.717114165405754, -28.784928468406154, -30.76841768934486, -27.915030755996245, -31.43987551794358, -29.625286304954344, -26.684846893182343, -36.122825608113985, -25.76769449777035, -25.99049973499422, -24.21405021278671, -28.051628674565386, -28.03156024912506, -26.086046282012575, -28.062086861875866, -30.58660982880937, -29.103579472278, -27.78141548038998, -25.90185911372759, -27.857674833033187, -26.56244319691513, -24.332137301429555, -28.48099293381824, -84.73186090964653, -25.74354345084613, -26.682285871218937, -33.77104278040857, -28.1794845025414, -27.674359132502715, -31.544681392765384], "policy_AGENT-2_reward": [-29.172044839868413, -27.886063461823923, -27.554381778203986, -26.552225722092047, -29.124674016926924, -28.527635538242777, -28.327027909027397, -26.00280623019863, -26.673070396251134, -29.031903008400924, -24.320180291031377, -29.9202945196776, -28.912804800528583, -33.936946877222695, -26.555084122705484, -28.568179458236894, -28.40602898867691, -28.743213938306774, -25.876637638522705, -27.869912164193625, -25.93438426171694, -26.069480519335173, -26.217534098082666, -28.172344256065088, -27.30499077503717, -26.600943359693503, -26.39160531031508, -25.601783828833064, -25.820827657779056, -27.47561248411335, -31.999334960504378, -44.22156927741467, -26.32648428425155, -28.916886047900466, -28.770430171665616, -25.999036062181556, -27.47059618756602, -30.08069758154313, -30.437908662317398, -28.458563995629902, -24.55365016501321, -28.091406124007946, -29.784218190215228, -28.750727836369602, -24.502962606671662, -26.131058145415412, -26.8874501041151, -26.94580525015362, -26.09028714944895, -28.536087106595364, -28.374040537263788, -25.72436927910196, -33.707360752778975, -29.18919232593435, -29.631863352776342, -30.54184121127814, -28.530863672030858, -26.161303147290575, -27.327251387822514, -27.51174569598093, -26.052763909405048, -28.555010048926192, -27.943030284728117, -29.097535586124724, -30.90822392674347, -29.273518279726186, -29.01047455392334, -28.4970486499866, -30.995852193321163, -26.467552581886203, -28.723769503505427, -28.875405692878033, -30.792261801333503, -28.024080986521284, -31.318830256614106, -29.56204235195389, -26.64623477178646, -36.16997949815748, -25.915343003956032, -26.018742460998634, -204.35372471387763, -28.035081275370718, -28.126522533966675, -26.071672623075276, -28.17648932640023, -30.616401327950776, -29.07699440366912, -27.87575181935396, -26.001414948330375, -27.889095214461587, -26.48800257909003, -24.34970781518132, -28.476801441745266, -34.403040479059, -25.752576244691276, -26.676487136538437, -33.751525998709056, -28.244571079813888, -27.717293500145445, -31.453929008548215], "policy_AGENT-0_reward": [-257.5370740497569, -273.3245251305606, -276.9164782574834, -323.99061190707414, -260.9944059686344, -305.41287730505644, -359.38309349916614, -205.9604305522032, -160.93303134330532, -287.77204729231244, -231.83824163207868, -172.58552534247403, -238.46261359665948, -241.93773065186733, -246.70359292106258, -245.6416732773065, -220.31354565396305, -268.79158204233704, -244.66112839835478, -162.55574877327612, -336.26824127861295, -302.1686276456376, -226.13993129599712, -255.02451587244997, -274.6214984264575, -237.87576040891304, -144.12458055985087, -215.40953094813213, -230.77992122225197, -236.08447268913918, -248.29083267425324, -84.96483231019147, -241.67559421548373, -181.7587852074368, -179.10709059259798, -172.2215695526479, -250.01635264245954, -287.59129399952764, -218.24968925489605, -235.62296526876887, -216.27387917204211, -149.26874024148327, -232.0090239081785, -211.13437931288274, -266.4634410418772, -241.14321533842644, -216.29350714910305, -224.34488270018392, -220.91697598551792, -224.68882773927677, -264.5984702638748, -247.31406162760408, -241.30074717261, -201.3439957501155, -211.7811510126209, -199.4772116863653, -286.2080253373774, -109.19972681961393, -131.6002813685989, -207.9310528391189, -205.43903205842952, -318.75961810304494, -217.24508425200898, -158.43721505010893, -220.08342647167038, -184.8012900151705, -252.2836513333499, -216.13657031856124, -160.6870201087438, -283.22336005961455, -152.27493983188896, -307.64925999056845, -271.2637845736269, -276.04297803199063, -242.0406711240735, -124.28959681608025, -227.42724717862225, -228.55651699415068, -163.49526096536, -188.08575949367935, -177.07728114412217, -179.55480552801288, -170.0114736033115, -310.8283716309357, -157.0383287486858, -174.18906118014328, -236.23827508189817, -255.25336476477915, -270.2460677396624, -243.69466115820052, -226.59043097813492, -286.98743635091245, -223.33634976443716, -84.72860142048636, -356.116186348805, -227.16426248932822, -361.345481128498, -269.7433771048735, -216.8536983127228, -215.5564912637605]}, "sampler_perf": {"mean_env_wait_ms": 31.232852130675155, "mean_processing_ms": 2.1229755194017312, "mean_inference_ms": 1.3919968802854965}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 36000, "timers": {"sample_time_ms": 137671.46, "sample_throughput": 29.055, "load_time_ms": 276.181, "load_throughput": 14483.261, "learn_time_ms": 5796.249, "learn_throughput": 690.101, "update_time_ms": 5.674}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.862983226776123, "policy_loss": -0.019549626857042313, "vf_loss": 3.88037109375, "vf_explained_var": 0.9656568765640259, "kl": 0.010806389153003693, "entropy": 1.3215352296829224, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.10000000149011612, "cur_lr": 9.999999747378752e-05, "total_loss": 3.7171220779418945, "policy_loss": -0.020309196785092354, "vf_loss": 3.736327648162842, "vf_explained_var": 0.8390915989875793, "kl": 0.011027242057025433, "entropy": 1.2790578603744507, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 1.3322819471359253, "policy_loss": -0.05295111611485481, "vf_loss": 1.3834421634674072, "vf_explained_var": 0.7363839149475098, "kl": 0.008954173885285854, "entropy": 1.3494817018508911, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.595069885253906, "policy_loss": -0.02580833248794079, "vf_loss": 6.618878364562988, "vf_explained_var": 0.9411547183990479, "kl": 0.010001084767282009, "entropy": 1.2830129861831665, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 36000, "num_steps_trained": 36000}, "done": false, "episodes_total": 335, "training_iteration": 9, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-20-46", "timestamp": 1638382846, "time_this_iter_s": 141.5662043094635, "time_total_s": 1295.700778245926, "pid": 59741, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f85693b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f85694d0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e69e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e69e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e69e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e69e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f849aef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 433.70947670936584, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 18.022660098522167, "ram_util_percent": 88.89999999999999}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -230.49105208676286, "episode_reward_min": -832.9673038247537, "episode_reward_mean": -529.0065245505389, "episode_len_mean": 116.88, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-3": -372.2829777070246, "AGENT-1": -84.78649353171238, "AGENT-2": -204.35372471387763, "AGENT-0": -404.60907755435795}, "policy_reward_max": {"AGENT-3": -16.51815696744444, "AGENT-1": -24.21405021278671, "AGENT-2": -24.320180291031377, "AGENT-0": -84.72860142048636}, "policy_reward_mean": {"AGENT-3": -229.21162634536043, "AGENT-1": -28.857978358968218, "AGENT-2": -29.781458594111463, "AGENT-0": -241.15546125209866}, "custom_metrics": {"mean_ego_speed_mean": 30.593667500000006, "mean_ego_speed_min": 21.442999999999998, "mean_ego_speed_max": 39.0065, "distance_travelled_mean": 56.62341249999999, "distance_travelled_min": 40.070750000000004, "distance_travelled_max": 65.617}, "hist_stats": {"episode_reward": [-553.2170885293447, -481.022794870967, -495.8340493539497, -574.3655504930379, -441.491824590515, -618.5715169547614, -462.9775709744781, -535.3843955075914, -441.6883410512889, -503.2314575284051, -516.736335300498, -487.39736302974313, -441.66606212384534, -455.06880740476447, -832.9673038247537, -538.7217182333978, -678.6709384748631, -776.9088179817484, -745.5959435529049, -611.0870365991219, -676.6530454122225, -474.1267601515876, -560.7710623801544, -423.3805558173408, -532.5913514591575, -694.0510162687415, -499.9432614028432, -615.5110334835742, -764.7428422949711, -436.57337132495854, -441.87903461664087, -418.24653141557445, -581.1273120482807, -397.1850952303471, -635.804956439402, -559.2596150164252, -565.7994168989752, -516.1551442237144, -338.6945300058822, -477.8418785141042, -497.31038301228074, -414.74111371391507, -379.58478421600955, -617.3855432517937, -441.6067380922919, -432.2391546130881, -639.2287577466607, -402.7746685454946, -433.93297483570285, -499.4457082032999, -518.6983769723313, -550.134621699272, -512.302395178114, -476.20183809329336, -582.3100152613165, -459.298068207754, -308.08381067502705, -730.9954731364629, -476.75688209077214, -758.7828649715636, -563.3816265634013, -515.4844794363481, -461.2927249894751, -606.0696873715822, -602.3954967047958, -569.8729850744281, -663.2886376329816, -549.7643749989255, -630.082546377699, -741.9877675789171, -511.6082290907943, -411.53065094337, -596.4751246569429, -467.4388928769017, -440.62429536784094, -534.619478690631, -508.35329602473826, -515.9860693087264, -548.6587403924351, -466.0326540727568, -555.1441859692073, -507.8638399265152, -416.53861156294715, -687.7044038544924, -617.3437137766515, -461.4668214573374, -613.8021290344686, -636.4155885377663, -496.923062887633, -374.46715471858107, -436.625931143634, -563.2046232631883, -493.3452168826547, -607.3298949558356, -230.49105208676286, -501.0081136700504, -452.82691411626166, -451.1173799700891, -432.6925841836223, -524.6365716011694], "episode_lengths": [93, 104, 109, 144, 165, 124, 116, 129, 102, 132, 119, 164, 106, 139, 149, 154, 137, 142, 136, 138, 200, 108, 162, 104, 115, 124, 110, 211, 165, 109, 106, 97, 111, 99, 122, 109, 110, 113, 86, 117, 105, 110, 100, 95, 94, 104, 122, 96, 97, 110, 112, 112, 137, 131, 114, 103, 97, 136, 115, 139, 145, 103, 102, 119, 79, 111, 121, 125, 119, 129, 119, 107, 113, 104, 106, 69, 105, 132, 80, 108, 111, 109, 106, 121, 116, 108, 127, 118, 111, 91, 100, 113, 107, 128, 78, 106, 99, 102, 113, 119], "policy_AGENT-3_reward": [-251.04908216175753, -195.19319269112782, -200.21563128241584, -244.53357412288779, -210.62195844629167, -262.8026691285435, -192.4480126605012, -225.76641334196825, -171.88901346985256, -243.1585744733529, -217.0811188529447, -233.69108440330908, -209.84118136772614, -221.45153397729823, -372.2829777070246, -227.147519980636, -296.6494674367764, -346.7222134021675, -328.47152536342753, -263.66604786464785, -331.07326778031825, -189.37445957553527, -234.64664710993938, -199.34069702526148, -222.65196541852163, -303.76368449408784, -200.77735642735064, -267.43895796920145, -340.3027942402585, -207.8551499661963, -168.67651050713323, -195.54700431525455, -245.02619077670832, -187.4692717295471, -270.49536228754937, -226.43515095211978, -233.81732712446652, -211.3557673250834, -155.21760453289363, -197.08354967051312, -196.46106091185834, -199.56281524682868, -139.48978252633728, -211.74048718100735, -205.9652226143428, -206.0695982266846, -276.2426672106368, -189.49776360853264, -198.5409024987996, -205.0268592454545, -207.78784490780822, -227.98527989755192, -212.86096397241838, -196.56096133915284, -246.64073379379312, -179.00392406775316, -104.22030786583535, -323.38316709212074, -196.23384659368625, -329.9148150639479, -237.21419387617257, -243.2391284909763, -182.73762332440117, -290.1772679741623, -273.3571285600013, -237.93312739888714, -286.2434452154289, -230.48843893194328, -267.63070668532504, -326.00209632413754, -253.65773808978867, -197.19866909985197, -250.6740186364545, -186.96925067320245, -208.3280538702813, -238.50240591122363, -198.5253786014622, -216.21224084146792, -245.9103362136434, -188.88874098885074, -228.9372456492068, -211.55642598430035, -198.29568917416057, -299.56606255041964, -263.1467898336877, -182.98492362287482, -302.4507717923732, -307.24386198458427, -205.79789546283416, -177.62003465974976, -170.02781069483285, -280.7792756149554, -202.3442184860799, -295.07932235958873, -16.51815696744444, -206.76585529801923, -213.29772151148745, -214.43432175339154, -208.4603323996284, -219.74541380161253], "policy_AGENT-1_reward": [-25.60765508375807, -28.93927306228054, -25.692590937277622, -26.228220942472102, -28.703341044606045, -28.675460809658496, -24.364529242667757, -26.472359721462347, -31.124123084287096, -26.02733114067324, -25.78748355254539, -28.09579484844986, -28.79157218345503, -26.12186023565909, -27.98869671111852, -26.255773758201762, -26.48456630243041, -25.783626429818035, -28.016923221376153, -26.297611597559886, -26.2667408071431, -26.97538006480265, -27.79103191523375, -30.21796377732411, -28.10018791032916, -26.046182626465598, -26.132173797462446, -27.466518589138744, -25.52060938585435, -28.14812966126317, -28.568905140959792, -31.01665479825484, -26.41020863007204, -28.717114165405754, -28.784928468406154, -30.76841768934486, -27.915030755996245, -31.43987551794358, -29.625286304954344, -26.684846893182343, -36.122825608113985, -25.76769449777035, -25.99049973499422, -24.21405021278671, -28.051628674565386, -28.03156024912506, -26.086046282012575, -28.062086861875866, -30.58660982880937, -29.103579472278, -27.78141548038998, -25.90185911372759, -27.857674833033187, -26.56244319691513, -24.332137301429555, -28.48099293381824, -84.73186090964653, -25.74354345084613, -26.682285871218937, -33.77104278040857, -28.1794845025414, -27.674359132502715, -31.544681392765384, -29.183300507794378, -27.827779552410266, -27.468997639853324, -26.502354788386203, -29.156856081420745, -28.511326849074717, -28.27554984658576, -25.98725421860373, -26.725880103961625, -28.99715571977494, -24.311220280589698, -29.790421635407633, -28.741654382219533, -33.95323989418635, -26.51515142349028, -28.538551443248558, -28.42433844126616, -28.672144339357043, -25.769647905337546, -27.817261451316668, -25.93571576374275, -25.958815777991163, -26.124432440382243, -28.154497113580387, -27.24523735168732, -26.6484636561927, -26.330934188665392, -25.58680567183586, -25.824598768201717, -27.440913223322553, -31.960404961489104, -84.78649353171238, -26.240179872295908, -28.853521349437194, -28.80553745243386, -26.011646169164372, -27.404208969531645], "policy_AGENT-2_reward": [-25.58513565997155, -28.89542259741582, -25.78001368063098, -26.2517661766622, -28.67913248983811, -28.66873104589649, -24.4563921233538, -26.585768448083066, -30.975687221306156, -26.114294770829463, -25.798783613473585, -28.069612147821132, -28.86835016618442, -26.088451258593338, -28.08655185225177, -26.32412553754791, -26.44744192309602, -25.877089877378754, -28.14055908930186, -26.374197461119973, -26.295087017232255, -26.918951895443318, -27.82642225200985, -30.36907089967494, -28.153904190346267, -26.110491650412843, -26.213769121130035, -27.588190948619935, -25.626130086023807, -28.177147744025536, -28.4970486499866, -30.995852193321163, -26.467552581886203, -28.723769503505427, -28.875405692878033, -30.792261801333503, -28.024080986521284, -31.318830256614106, -29.56204235195389, -26.64623477178646, -36.16997949815748, -25.915343003956032, -26.018742460998634, -204.35372471387763, -28.035081275370718, -28.126522533966675, -26.071672623075276, -28.17648932640023, -30.616401327950776, -29.07699440366912, -27.87575181935396, -26.001414948330375, -27.889095214461587, -26.48800257909003, -24.34970781518132, -28.476801441745266, -34.403040479059, -25.752576244691276, -26.676487136538437, -33.751525998709056, -28.244571079813888, -27.717293500145445, -31.453929008548215, -29.172044839868413, -27.886063461823923, -27.554381778203986, -26.552225722092047, -29.124674016926924, -28.527635538242777, -28.327027909027397, -26.00280623019863, -26.673070396251134, -29.031903008400924, -24.320180291031377, -29.9202945196776, -28.912804800528583, -33.936946877222695, -26.555084122705484, -28.568179458236894, -28.40602898867691, -28.743213938306774, -25.876637638522705, -27.869912164193625, -25.93438426171694, -26.069480519335173, -26.217534098082666, -28.172344256065088, -27.30499077503717, -26.600943359693503, -26.39160531031508, -25.601783828833064, -25.820827657779056, -27.47561248411335, -31.999334960504378, -44.22156927741467, -26.32648428425155, -28.916886047900466, -28.770430171665616, -25.999036062181556, -27.47059618756602], "policy_AGENT-0_reward": [-250.97521562385734, -227.99490652014262, -244.1458134536254, -277.35198925101525, -173.48739260977936, -298.42465597066274, -221.70863694795548, -256.5598539960779, -207.6995172758432, -207.931257143549, -248.0689492815344, -197.54087163016294, -174.1649584064796, -181.40696193321347, -404.60907755435795, -258.99429895701167, -329.08946281256055, -378.52588827238304, -360.96693587879946, -294.74917967579387, -293.01794980752925, -230.85796861580644, -270.5069611029712, -163.45282411508055, -253.68529393996033, -338.13065749777485, -246.81996205690018, -293.01736597661403, -373.2933085828352, -172.3929439534734, -216.13657031856124, -160.6870201087438, -283.22336005961455, -152.27493983188896, -307.64925999056845, -271.2637845736269, -276.04297803199063, -242.0406711240735, -124.28959681608025, -227.42724717862225, -228.55651699415068, -163.49526096536, -188.08575949367935, -177.07728114412217, -179.55480552801288, -170.0114736033115, -310.8283716309357, -157.0383287486858, -174.18906118014328, -236.23827508189817, -255.25336476477915, -270.2460677396624, -243.69466115820052, -226.59043097813492, -286.98743635091245, -223.33634976443716, -84.72860142048636, -356.116186348805, -227.16426248932822, -361.345481128498, -269.7433771048735, -216.8536983127228, -215.5564912637605, -257.5370740497569, -273.3245251305606, -276.9164782574834, -323.99061190707414, -260.9944059686344, -305.41287730505644, -359.38309349916614, -205.9604305522032, -160.93303134330532, -287.77204729231244, -231.83824163207868, -172.58552534247403, -238.46261359665948, -241.93773065186733, -246.70359292106258, -245.6416732773065, -220.31354565396305, -268.79158204233704, -244.66112839835478, -162.55574877327612, -336.26824127861295, -302.1686276456376, -226.13993129599712, -255.02451587244997, -274.6214984264575, -237.87576040891304, -144.12458055985087, -215.40953094813213, -230.77992122225197, -236.08447268913918, -248.29083267425324, -84.96483231019147, -241.67559421548373, -181.7587852074368, -179.10709059259798, -172.2215695526479, -250.01635264245954]}, "sampler_perf": {"mean_env_wait_ms": 30.746132395782237, "mean_processing_ms": 2.060843114083883, "mean_inference_ms": 1.3474548370227564}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 40000, "timers": {"sample_time_ms": 134256.5, "sample_throughput": 29.794, "load_time_ms": 209.234, "load_throughput": 19117.346, "learn_time_ms": 5542.665, "learn_throughput": 721.674, "update_time_ms": 5.645}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.843092679977417, "policy_loss": -0.02323187328875065, "vf_loss": 2.864100217819214, "vf_explained_var": 0.9824895858764648, "kl": 0.011122164316475391, "entropy": 1.287954330444336, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.10000000149011612, "cur_lr": 9.999999747378752e-05, "total_loss": 3.8984875679016113, "policy_loss": -0.006970285438001156, "vf_loss": 3.9048264026641846, "vf_explained_var": 0.8867015242576599, "kl": 0.006309740711003542, "entropy": 1.2602158784866333, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.470555305480957, "policy_loss": -0.02586495876312256, "vf_loss": 4.4943528175354, "vf_explained_var": 0.8858209848403931, "kl": 0.010338203981518745, "entropy": 1.3451541662216187, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.9418253898620605, "policy_loss": -0.027077414095401764, "vf_loss": 3.966374158859253, "vf_explained_var": 0.9538756012916565, "kl": 0.012644350528717041, "entropy": 1.2399122714996338, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 40000, "num_steps_trained": 40000}, "done": false, "episodes_total": 365, "training_iteration": 10, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-22-55", "timestamp": 1638382975, "time_this_iter_s": 128.82497215270996, "time_total_s": 1424.5257503986359, "pid": 59741, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f84e93b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f854e710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f856e9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f856ea70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8465050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f856e9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f856ea70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8465050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f856e9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f856ea70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8465050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f856e9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f856ea70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8529b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8465050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f851a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 562.5344488620758, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 18.128804347826087, "ram_util_percent": 88.92608695652174}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -230.49105208676286, "episode_reward_min": -1219.6288266832819, "episode_reward_mean": -572.3089387570658, "episode_len_mean": 130.52, "episodes_this_iter": 23, "policy_reward_min": {"AGENT-3": -561.6063208901154, "AGENT-1": -85.91639267608645, "AGENT-2": -88.58787305543936, "AGENT-0": -604.4801008209946}, "policy_reward_max": {"AGENT-3": -16.51815696744444, "AGENT-1": -24.311220280589698, "AGENT-2": -24.320180291031377, "AGENT-0": -84.72860142048636}, "policy_reward_mean": {"AGENT-3": -250.92456522662945, "AGENT-1": -29.201000104576266, "AGENT-2": -28.351429669673376, "AGENT-0": -263.83194375618666}, "custom_metrics": {"mean_ego_speed_mean": 29.007127500000003, "mean_ego_speed_min": 19.14075, "mean_ego_speed_max": 41.199, "distance_travelled_mean": 55.397235, "distance_travelled_min": 23.55775, "distance_travelled_max": 61.7405}, "hist_stats": {"episode_reward": [-382.74201267943124, -517.0082192377618, -712.6843766873168, -494.55559456124786, -255.91045278286492, -582.7263454866556, -735.6512183832323, -707.5663357737586, -761.825987662707, -809.566108665002, -235.54513959879674, -487.7716609610018, -1098.5282193847142, -1219.6288266832819, -645.6640405051719, -1028.995734743159, -933.6019923943954, -634.923972047027, -770.6316311798702, -603.7921347976512, -680.4056130927942, -684.1947648861452, -617.6997729483168, -476.20183809329336, -582.3100152613165, -459.298068207754, -308.08381067502705, -730.9954731364629, -476.75688209077214, -758.7828649715636, -563.3816265634013, -515.4844794363481, -461.2927249894751, -606.0696873715822, -602.3954967047958, -569.8729850744281, -663.2886376329816, -549.7643749989255, -630.082546377699, -741.9877675789171, -511.6082290907943, -411.53065094337, -596.4751246569429, -467.4388928769017, -440.62429536784094, -534.619478690631, -508.35329602473826, -515.9860693087264, -548.6587403924351, -466.0326540727568, -555.1441859692073, -507.8638399265152, -416.53861156294715, -687.7044038544924, -617.3437137766515, -461.4668214573374, -613.8021290344686, -636.4155885377663, -496.923062887633, -374.46715471858107, -436.625931143634, -563.2046232631883, -493.3452168826547, -607.3298949558356, -230.49105208676286, -501.0081136700504, -452.82691411626166, -451.1173799700891, -432.6925841836223, -524.6365716011694, -553.2170885293447, -481.022794870967, -495.8340493539497, -574.3655504930379, -441.491824590515, -618.5715169547614, -462.9775709744781, -535.3843955075914, -441.6883410512889, -503.2314575284051, -516.736335300498, -487.39736302974313, -441.66606212384534, -455.06880740476447, -832.9673038247537, -538.7217182333978, -678.6709384748631, -776.9088179817484, -745.5959435529049, -611.0870365991219, -676.6530454122225, -474.1267601515876, -560.7710623801544, -423.3805558173408, -532.5913514591575, -694.0510162687415, -499.9432614028432, -615.5110334835742, -764.7428422949711, -436.57337132495854], "episode_lengths": [121, 248, 96, 189, 25, 136, 195, 128, 208, 158, 24, 166, 213, 219, 306, 257, 196, 167, 138, 175, 150, 193, 120, 131, 114, 103, 97, 136, 115, 139, 145, 103, 102, 119, 79, 111, 121, 125, 119, 129, 119, 107, 113, 104, 106, 69, 105, 132, 80, 108, 111, 109, 106, 121, 116, 108, 127, 118, 111, 91, 100, 113, 107, 128, 78, 106, 99, 102, 113, 119, 93, 104, 109, 144, 165, 124, 116, 129, 102, 132, 119, 164, 106, 139, 149, 154, 137, 142, 136, 138, 200, 108, 162, 104, 115, 124, 110, 211, 165, 109], "policy_AGENT-3_reward": [-122.16000952811217, -218.76583743965514, -328.86143954491655, -234.5711628266146, -98.13625147200506, -249.87938495132926, -321.32635797607884, -308.6537259984993, -335.28085906834065, -361.5907455801365, -92.79030179120635, -231.70939442654446, -501.7191145310092, -561.6063208901154, -320.0854453025274, -501.5630031313171, -422.579989809562, -269.9551828564691, -341.90328466028905, -254.31081461223576, -298.7249271836273, -298.13420288538623, -265.3411189304584, -196.56096133915284, -246.64073379379312, -179.00392406775316, -104.22030786583535, -323.38316709212074, -196.23384659368625, -329.9148150639479, -237.21419387617257, -243.2391284909763, -182.73762332440117, -290.1772679741623, -273.3571285600013, -237.93312739888714, -286.2434452154289, -230.48843893194328, -267.63070668532504, -326.00209632413754, -253.65773808978867, -197.19866909985197, -250.6740186364545, -186.96925067320245, -208.3280538702813, -238.50240591122363, -198.5253786014622, -216.21224084146792, -245.9103362136434, -188.88874098885074, -228.9372456492068, -211.55642598430035, -198.29568917416057, -299.56606255041964, -263.1467898336877, -182.98492362287482, -302.4507717923732, -307.24386198458427, -205.79789546283416, -177.62003465974976, -170.02781069483285, -280.7792756149554, -202.3442184860799, -295.07932235958873, -16.51815696744444, -206.76585529801923, -213.29772151148745, -214.43432175339154, -208.4603323996284, -219.74541380161253, -251.04908216175753, -195.19319269112782, -200.21563128241584, -244.53357412288779, -210.62195844629167, -262.8026691285435, -192.4480126605012, -225.76641334196825, -171.88901346985256, -243.1585744733529, -217.0811188529447, -233.69108440330908, -209.84118136772614, -221.45153397729823, -372.2829777070246, -227.147519980636, -296.6494674367764, -346.7222134021675, -328.47152536342753, -263.66604786464785, -331.07326778031825, -189.37445957553527, -234.64664710993938, -199.34069702526148, -222.65196541852163, -303.76368449408784, -200.77735642735064, -267.43895796920145, -340.3027942402585, -207.8551499661963], "policy_AGENT-1_reward": [-85.91639267608645, -26.56989046730629, -27.536656728779803, -26.496732137450657, -29.843237212641107, -25.867104446515462, -30.190259259111084, -26.385224500400536, -31.13651916967197, -25.75284681173616, -24.936002822062292, -28.407954156598436, -26.10600912555485, -26.753997435433224, -26.77511386592874, -28.75333570564088, -27.873858886139914, -28.084622785762292, -26.090158207369846, -28.83542217175292, -25.837707256104814, -26.35607981306571, -27.285848133694373, -26.56244319691513, -24.332137301429555, -28.48099293381824, -84.73186090964653, -25.74354345084613, -26.682285871218937, -33.77104278040857, -28.1794845025414, -27.674359132502715, -31.544681392765384, -29.183300507794378, -27.827779552410266, -27.468997639853324, -26.502354788386203, -29.156856081420745, -28.511326849074717, -28.27554984658576, -25.98725421860373, -26.725880103961625, -28.99715571977494, -24.311220280589698, -29.790421635407633, -28.741654382219533, -33.95323989418635, -26.51515142349028, -28.538551443248558, -28.42433844126616, -28.672144339357043, -25.769647905337546, -27.817261451316668, -25.93571576374275, -25.958815777991163, -26.124432440382243, -28.154497113580387, -27.24523735168732, -26.6484636561927, -26.330934188665392, -25.58680567183586, -25.824598768201717, -27.440913223322553, -31.960404961489104, -84.78649353171238, -26.240179872295908, -28.853521349437194, -28.80553745243386, -26.011646169164372, -27.404208969531645, -25.60765508375807, -28.93927306228054, -25.692590937277622, -26.228220942472102, -28.703341044606045, -28.675460809658496, -24.364529242667757, -26.472359721462347, -31.124123084287096, -26.02733114067324, -25.78748355254539, -28.09579484844986, -28.79157218345503, -26.12186023565909, -27.98869671111852, -26.255773758201762, -26.48456630243041, -25.783626429818035, -28.016923221376153, -26.297611597559886, -26.2667408071431, -26.97538006480265, -27.79103191523375, -30.21796377732411, -28.10018791032916, -26.046182626465598, -26.132173797462446, -27.466518589138744, -25.52060938585435, -28.14812966126317], "policy_AGENT-2_reward": [-88.58787305543936, -26.54643862771924, -27.467868090425295, -26.566071085167668, -29.804471344059028, -25.986929978507984, -30.095606049187598, -26.502045440754117, -31.219068213582318, -25.75019007337403, -25.079882678811718, -28.47316031747368, -26.174026648341737, -26.788407536737576, -26.783565073227468, -28.80739982333333, -27.886977411496257, -28.128893744548424, -26.141637457057904, -28.88157548929729, -25.869141068713162, -26.382903149699022, -27.303267138592076, -26.48800257909003, -24.34970781518132, -28.476801441745266, -34.403040479059, -25.752576244691276, -26.676487136538437, -33.751525998709056, -28.244571079813888, -27.717293500145445, -31.453929008548215, -29.172044839868413, -27.886063461823923, -27.554381778203986, -26.552225722092047, -29.124674016926924, -28.527635538242777, -28.327027909027397, -26.00280623019863, -26.673070396251134, -29.031903008400924, -24.320180291031377, -29.9202945196776, -28.912804800528583, -33.936946877222695, -26.555084122705484, -28.568179458236894, -28.40602898867691, -28.743213938306774, -25.876637638522705, -27.869912164193625, -25.93438426171694, -26.069480519335173, -26.217534098082666, -28.172344256065088, -27.30499077503717, -26.600943359693503, -26.39160531031508, -25.601783828833064, -25.820827657779056, -27.47561248411335, -31.999334960504378, -44.22156927741467, -26.32648428425155, -28.916886047900466, -28.770430171665616, -25.999036062181556, -27.47059618756602, -25.58513565997155, -28.89542259741582, -25.78001368063098, -26.2517661766622, -28.67913248983811, -28.66873104589649, -24.4563921233538, -26.585768448083066, -30.975687221306156, -26.114294770829463, -25.798783613473585, -28.069612147821132, -28.86835016618442, -26.088451258593338, -28.08655185225177, -26.32412553754791, -26.44744192309602, -25.877089877378754, -28.14055908930186, -26.374197461119973, -26.295087017232255, -26.918951895443318, -27.82642225200985, -30.36907089967494, -28.153904190346267, -26.110491650412843, -26.213769121130035, -27.588190948619935, -25.626130086023807, -28.177147744025536], "policy_AGENT-0_reward": [-86.0777374197935, -245.12605270308117, -328.81841232319493, -206.92162851201476, -98.12649275415977, -280.99292611030296, -354.03899509885565, -346.0253398341044, -364.18954121111216, -396.4723261997556, -92.73895230671639, -199.18115206038524, -544.529069079809, -604.4801008209946, -272.0199162634885, -469.87199608286716, -455.2611662871971, -308.7552726602475, -376.4965508551525, -291.76432252436547, -329.97383758434864, -333.3215790379941, -297.76953874557165, -226.59043097813492, -286.98743635091245, -223.33634976443716, -84.72860142048636, -356.116186348805, -227.16426248932822, -361.345481128498, -269.7433771048735, -216.8536983127228, -215.5564912637605, -257.5370740497569, -273.3245251305606, -276.9164782574834, -323.99061190707414, -260.9944059686344, -305.41287730505644, -359.38309349916614, -205.9604305522032, -160.93303134330532, -287.77204729231244, -231.83824163207868, -172.58552534247403, -238.46261359665948, -241.93773065186733, -246.70359292106258, -245.6416732773065, -220.31354565396305, -268.79158204233704, -244.66112839835478, -162.55574877327612, -336.26824127861295, -302.1686276456376, -226.13993129599712, -255.02451587244997, -274.6214984264575, -237.87576040891304, -144.12458055985087, -215.40953094813213, -230.77992122225197, -236.08447268913918, -248.29083267425324, -84.96483231019147, -241.67559421548373, -181.7587852074368, -179.10709059259798, -172.2215695526479, -250.01635264245954, -250.97521562385734, -227.99490652014262, -244.1458134536254, -277.35198925101525, -173.48739260977936, -298.42465597066274, -221.70863694795548, -256.5598539960779, -207.6995172758432, -207.931257143549, -248.0689492815344, -197.54087163016294, -174.1649584064796, -181.40696193321347, -404.60907755435795, -258.99429895701167, -329.08946281256055, -378.52588827238304, -360.96693587879946, -294.74917967579387, -293.01794980752925, -230.85796861580644, -270.5069611029712, -163.45282411508055, -253.68529393996033, -338.13065749777485, -246.81996205690018, -293.01736597661403, -373.2933085828352, -172.3929439534734]}, "sampler_perf": {"mean_env_wait_ms": 30.398180947411014, "mean_processing_ms": 2.008871630069069, "mean_inference_ms": 1.3256117207784879}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 44000, "timers": {"sample_time_ms": 130993.182, "sample_throughput": 30.536, "load_time_ms": 169.103, "load_throughput": 23654.289, "learn_time_ms": 5360.233, "learn_throughput": 746.236, "update_time_ms": 5.63}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 5.355801105499268, "policy_loss": -0.03229127824306488, "vf_loss": 5.385072708129883, "vf_explained_var": 0.9735444784164429, "kl": 0.015097134746611118, "entropy": 1.1681972742080688, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.10000000149011612, "cur_lr": 9.999999747378752e-05, "total_loss": 0.17277701199054718, "policy_loss": -0.04269684478640556, "vf_loss": 0.2140236794948578, "vf_explained_var": 0.963566780090332, "kl": 0.014501858502626419, "entropy": 1.20527982711792, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.441488742828369, "policy_loss": -0.020980902016162872, "vf_loss": 4.460351943969727, "vf_explained_var": 0.8992563486099243, "kl": 0.010589954443275928, "entropy": 1.3362743854522705, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.26717472076416, "policy_loss": -0.029040444642305374, "vf_loss": 6.293656349182129, "vf_explained_var": 0.950729250907898, "kl": 0.012790020555257797, "entropy": 1.1928001642227173, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 44000, "num_steps_trained": 44000}, "done": false, "episodes_total": 388, "training_iteration": 11, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-24-58", "timestamp": 1638383098, "time_this_iter_s": 122.60310411453247, "time_total_s": 1547.1288545131683, "pid": 59741, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f852d560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f84e9b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f851a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f851a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f851a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f851a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f849a830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849a950>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f84e6b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 685.1375529766083, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 18.096571428571426, "ram_util_percent": 89.0}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -282.13053156454725, "episode_reward_min": -1153.2783450462478, "episode_reward_mean": -746.8450061626163, "episode_len_mean": 165.91666666666666, "episodes_this_iter": 24, "policy_reward_min": {"AGENT-2": -98.15176555934393, "AGENT-3": -591.138701095444, "AGENT-1": -98.16306878225592, "AGENT-0": -590.9607965579338}, "policy_reward_max": {"AGENT-2": 15.352813267224317, "AGENT-3": -162.27390676044564, "AGENT-1": 15.305629428625798, "AGENT-0": -138.7692775816305}, "policy_reward_mean": {"AGENT-2": -40.68158555727665, "AGENT-3": -324.12105976165486, "AGENT-1": -40.701622146742075, "AGENT-0": -341.34073869694265}, "custom_metrics": {"mean_ego_speed_mean": 26.229520833333336, "mean_ego_speed_min": 16.283749999999998, "mean_ego_speed_max": 43.604, "distance_travelled_mean": 56.75478125, "distance_travelled_min": 47.41649999999999, "distance_travelled_max": 61.70175}, "hist_stats": {"episode_reward": [-397.35356606080904, -743.7765730306646, -960.2764537657747, -997.1578775212904, -282.13053156454725, -872.3453120265341, -638.0378790535623, -978.9242833929319, -649.6238532343806, -703.1448345880093, -1153.2783450462478, -783.2059188909298, -326.7512865972357, -939.9261742373074, -558.5938020034572, -891.1067842686642, -576.8732969475506, -1151.2280917826433, -609.4004802863634, -855.2280507489211, -786.2463855441727, -698.6471480130481, -438.8381782930563, -932.1850410046911], "episode_lengths": [121, 158, 235, 136, 203, 218, 135, 228, 152, 103, 194, 109, 118, 124, 136, 165, 133, 156, 296, 109, 179, 293, 163, 118], "policy_AGENT-2_reward": [11.83371375837186, -97.28434426171552, 14.573158586915827, -95.69793404694883, 15.352813267224317, -90.94149474703477, 11.717990160328442, -94.93186773567103, 14.13667593777635, -87.52169676214767, 14.465815919597192, -96.90608607997862, 14.293757352849038, -92.81081956667973, 15.180343591518536, -97.87419655378619, 14.60085513497432, -95.3354748422849, 12.33697082496993, -98.15176555934393, 14.414185810810688, -97.71990096670922, 12.939684327583413, -97.02843692525911], "policy_AGENT-3_reward": [-190.6929437521545, -292.61418653049674, -476.5604042063483, -385.07206233618507, -174.01969667876708, -329.43514199357656, -314.00182401461245, -407.40762668500616, -319.7883186454811, -247.28055813807356, -591.138701095444, -278.8596319999658, -162.27390676044564, -356.801023555384, -277.3580733871353, -323.6584371485504, -283.7297064482881, -464.00776476393315, -336.66176216221845, -310.0423459623935, -425.1057702951154, -270.60277063525206, -211.8793996560605, -349.9133774288299], "policy_AGENT-1_reward": [11.90864310824021, -97.4437082092717, 14.592326722757267, -95.78162499551547, 15.305629428625798, -90.97950916082316, 11.795340325199748, -94.9639930849516, 14.144809802687956, -87.52219267460413, 14.355336687533518, -97.00218007670625, 14.282838130412946, -92.75848331651093, 15.11435464698445, -97.9178953955522, 14.548498129567172, -95.4245594725812, 12.35845320461291, -98.16306878225592, 14.453919501323744, -97.6604851511485, 12.948441728087182, -97.02982261792158], "policy_AGENT-0_reward": [-230.40297917526686, -256.43433402918134, -512.8815348690997, -420.6062561426414, -138.7692775816305, -360.98916612509925, -347.5493855244781, -381.62079588730245, -358.1170203293635, -280.82038701318385, -590.9607965579338, -310.43802073427895, -193.05397532005205, -397.5558477987333, -311.53042685482495, -371.65625517077495, -322.2929437638039, -496.4602927038428, -297.4341421537277, -348.8708704449276, -390.00872056119135, -232.6639912599384, -252.84690469266639, -388.21340403268056]}, "sampler_perf": {"mean_env_wait_ms": 27.79301241975044, "mean_processing_ms": 1.4588138038770644, "mean_inference_ms": 1.271393739471016}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 44000, "timers": {"sample_time_ms": 122612.45, "sample_throughput": 32.623, "load_time_ms": 837.265, "load_throughput": 4777.463, "learn_time_ms": 6287.823, "learn_throughput": 636.15, "update_time_ms": 5.484}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.699519634246826, "policy_loss": -0.031403180211782455, "vf_loss": 6.7280592918396, "vf_explained_var": 0.971294641494751, "kl": 0.014320219866931438, "entropy": 1.1971445083618164, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 38.075904846191406, "policy_loss": -0.03844207897782326, "vf_loss": 38.11110305786133, "vf_explained_var": 0.7042482495307922, "kl": 0.016178706660866737, "entropy": 1.3209787607192993, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 38.55587387084961, "policy_loss": -0.03964642807841301, "vf_loss": 38.59157180786133, "vf_explained_var": 0.7074964642524719, "kl": 0.01972837746143341, "entropy": 1.3289457559585571, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.650467395782471, "policy_loss": -0.03981277719140053, "vf_loss": 6.687198162078857, "vf_explained_var": 0.9513785243034363, "kl": 0.015412150882184505, "entropy": 1.22142493724823, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 44000, "num_steps_trained": 44000}, "done": false, "episodes_total": 389, "training_iteration": 11, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-28-14", "timestamp": 1638383294, "time_this_iter_s": 132.1523687839508, "time_total_s": 1556.6781191825867, "pid": 60632, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f8465440>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f8465170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8465f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84653b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f845ac20>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f845a0e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8465f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84653b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f845ac20>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f845a0e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8465f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84653b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f845ac20>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f845a0e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8465f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f84653b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f845ac20>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f845a0e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f83c59e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 132.1523687839508, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.43193717277487, "ram_util_percent": 90.80261780104709}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -75.00530364402908, "episode_reward_min": -1805.3232883880503, "episode_reward_mean": -878.5742349588453, "episode_len_mean": 179.79545454545453, "episodes_this_iter": 20, "policy_reward_min": {"AGENT-2": -223.14032987936935, "AGENT-3": -791.7800298967721, "AGENT-1": -124.101451077444, "AGENT-0": -829.4286029563259}, "policy_reward_max": {"AGENT-2": 15.694148525611778, "AGENT-3": -52.82820982313898, "AGENT-1": 15.638520405411079, "AGENT-0": -52.76424776682768}, "policy_reward_mean": {"AGENT-2": -43.067101991997696, "AGENT-3": -391.96420488805376, "AGENT-1": -40.82358400385646, "AGENT-0": -402.71934407493706}, "custom_metrics": {"mean_ego_speed_mean": 26.337539772727272, "mean_ego_speed_min": 16.283749999999998, "mean_ego_speed_max": 43.604, "distance_travelled_mean": 56.63505113636363, "distance_travelled_min": 23.276249999999997, "distance_travelled_max": 61.70175}, "hist_stats": {"episode_reward": [-1142.5690671767313, -952.0772619014307, -1378.6498273524703, -729.5132965766448, -574.8627042208965, -847.9550078783083, -1313.1807524648727, -1805.3232883880503, -592.1143650700233, -792.186183223773, -875.8153192818955, -1638.2567733859667, -1143.693919700248, -1587.2408595206646, -633.686583089708, -993.2681588857313, -1377.2510366447495, -1181.8552122556018, -75.00530364402908, -1098.4812696245988, -397.35356606080904, -743.7765730306646, -960.2764537657747, -997.1578775212904, -282.13053156454725, -872.3453120265341, -638.0378790535623, -978.9242833929319, -649.6238532343806, -703.1448345880093, -1153.2783450462478, -783.2059188909298, -326.7512865972357, -939.9261742373074, -558.5938020034572, -891.1067842686642, -576.8732969475506, -1151.2280917826433, -609.4004802863634, -855.2280507489211, -786.2463855441727, -698.6471480130481, -438.8381782930563, -932.1850410046911], "episode_lengths": [248, 417, 338, 80, 143, 82, 334, 265, 135, 118, 206, 245, 227, 214, 140, 131, 275, 161, 24, 146, 121, 158, 235, 136, 203, 218, 135, 228, 152, 103, 194, 109, 118, 124, 136, 165, 133, 156, 296, 109, 179, 293, 163, 118], "policy_AGENT-2_reward": [13.563055238103868, -87.80094690241052, 15.072776970236124, -223.14032987936935, 14.300643503498558, -91.2754412305666, 14.125871473666908, -92.12218762031071, 15.677582875320663, -94.32298369511177, 14.056187565428523, -96.65005643987318, 15.694148525611778, -100.23461447445797, 12.918877765802035, -90.02981368642006, 13.868121182182938, -95.2200152861725, 15.318877650805634, -92.39418780922348, 11.83371375837186, -97.28434426171552, 14.573158586915827, -95.69793404694883, 15.352813267224317, -90.94149474703477, 11.717990160328442, -94.93186773567103, 14.13667593777635, -87.52169676214767, 14.465815919597192, -96.90608607997862, 14.293757352849038, -92.81081956667973, 15.180343591518536, -97.87419655378619, 14.60085513497432, -95.3354748422849, 12.33697082496993, -98.15176555934393, 14.414185810810688, -97.71990096670922, 12.939684327583413, -97.02843692525911], "policy_AGENT-3_reward": [-596.2469445780563, -380.73604421309403, -682.4379183963424, -258.26321743624015, -285.6840577693747, -332.7391033653822, -682.0621445792096, -791.7800298967721, -294.6297074769992, -319.88129079347294, -433.88684290889927, -702.8418950068375, -570.1798962099682, -709.5551700334995, -346.7103375233228, -390.2032864178595, -718.0652417215301, -478.77483519194834, -52.82820982313898, -440.01340745270016, -190.6929437521545, -292.61418653049674, -476.5604042063483, -385.07206233618507, -174.01969667876708, -329.43514199357656, -314.00182401461245, -407.40762668500616, -319.7883186454811, -247.28055813807356, -591.138701095444, -278.8596319999658, -162.27390676044564, -356.801023555384, -277.3580733871353, -323.6584371485504, -283.7297064482881, -464.00776476393315, -336.66176216221845, -310.0423459623935, -425.1057702951154, -270.60277063525206, -211.8793996560605, -349.9133774288299], "policy_AGENT-1_reward": [13.617255163230087, -87.82008199678168, 15.091510186417107, -124.101451077444, 14.282647688914121, -91.32418052051413, 14.113940249136734, -91.99246791463935, 15.638520405411079, -94.219987515773, 14.13335570889931, -96.61608869091889, 15.631267961138722, -100.36905251873266, 12.917136956702715, -90.02190796234305, 13.863785425090033, -95.23252767907503, 15.268276295131951, -92.25871481172476, 11.90864310824021, -97.4437082092717, 14.592326722757267, -95.78162499551547, 15.305629428625798, -90.97950916082316, 11.795340325199748, -94.9639930849516, 14.144809802687956, -87.52219267460413, 14.355336687533518, -97.00218007670625, 14.282838130412946, -92.75848331651093, 15.11435464698445, -97.9178953955522, 14.548498129567172, -95.4245594725812, 12.35845320461291, -98.16306878225592, 14.453919501323744, -97.6604851511485, 12.948441728087182, -97.02982261792158], "policy_AGENT-0_reward": [-573.5024330000069, -395.7201887891436, -726.3761961127824, -124.00829818359077, -317.7619376439343, -332.61628276184575, -659.3584196084662, -829.4286029563259, -328.80076087375585, -283.76192121941546, -470.11801964732445, -742.1487332483349, -604.8394399770298, -677.0820224939739, -312.81226028889085, -423.0131508191079, -686.9177015304911, -512.6278340984057, -52.76424776682768, -473.8149595509503, -230.40297917526686, -256.43433402918134, -512.8815348690997, -420.6062561426414, -138.7692775816305, -360.98916612509925, -347.5493855244781, -381.62079588730245, -358.1170203293635, -280.82038701318385, -590.9607965579338, -310.43802073427895, -193.05397532005205, -397.5558477987333, -311.53042685482495, -371.65625517077495, -322.2929437638039, -496.4602927038428, -297.4341421537277, -348.8708704449276, -390.00872056119135, -232.6639912599384, -252.84690469266639, -388.21340403268056]}, "sampler_perf": {"mean_env_wait_ms": 28.273368092643373, "mean_processing_ms": 1.4154554724490471, "mean_inference_ms": 1.2756527258598809}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 48000, "timers": {"sample_time_ms": 126298.621, "sample_throughput": 31.671, "load_time_ms": 423.354, "load_throughput": 9448.357, "learn_time_ms": 5742.457, "learn_throughput": 696.566, "update_time_ms": 5.374}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 5.668157577514648, "policy_loss": -0.038217708468437195, "vf_loss": 5.703088760375977, "vf_explained_var": 0.9692600965499878, "kl": 0.016435151919722557, "entropy": 1.0873087644577026, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 5.311826229095459, "policy_loss": -0.049716006964445114, "vf_loss": 5.357344150543213, "vf_explained_var": 0.9659229516983032, "kl": 0.020993279293179512, "entropy": 1.092638611793518, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 31.69808006286621, "policy_loss": -0.032195933163166046, "vf_loss": 31.728580474853516, "vf_explained_var": 0.8144546151161194, "kl": 0.008479509502649307, "entropy": 1.3110432624816895, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 35.66674041748047, "policy_loss": -0.05890987068414688, "vf_loss": 35.72244644165039, "vf_explained_var": 0.7960984110832214, "kl": 0.01602262258529663, "entropy": 1.3296594619750977, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 48000, "num_steps_trained": 48000}, "done": false, "episodes_total": 409, "training_iteration": 12, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-30-29", "timestamp": 1638383429, "time_this_iter_s": 135.21568870544434, "time_total_s": 1691.893807888031, "pid": 60632, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f83c5f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f83d80e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8320>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8440>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8560>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8680>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8320>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8440>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8560>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8680>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8320>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8440>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8560>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8680>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8320>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8440>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8560>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83d8680>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f83c5830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 267.36805748939514, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 17.965803108808288, "ram_util_percent": 91.0}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -75.00530364402908, "episode_reward_min": -2702.7243526677817, "episode_reward_mean": -1000.894403322676, "episode_len_mean": 204.0701754385965, "episodes_this_iter": 13, "policy_reward_min": {"AGENT-2": -223.14032987936935, "AGENT-3": -1234.8992072468775, "AGENT-1": -170.0308560219698, "AGENT-0": -1274.7871394715826}, "policy_reward_max": {"AGENT-2": 15.694148525611778, "AGENT-3": -52.82820982313898, "AGENT-1": 15.638520405411079, "AGENT-0": -33.871397113227545}, "policy_reward_mean": {"AGENT-2": -44.10088940791565, "AGENT-3": -453.4521589976561, "AGENT-1": -43.831088699939194, "AGENT-0": -459.5102662171649}, "custom_metrics": {"mean_ego_speed_mean": 25.792622807017544, "mean_ego_speed_min": 13.23975, "mean_ego_speed_max": 43.779999999999994, "distance_travelled_mean": 56.95861403508772, "distance_travelled_min": 23.276249999999997, "distance_travelled_max": 61.70175}, "hist_stats": {"episode_reward": [-479.3071905579983, -2115.2832536310516, -371.70330187292035, -830.3736104741663, -268.55525624202386, -2702.7243526677817, -1746.7289379938525, -2561.293460391216, -709.4203665099352, -1730.0652416115056, -812.2388298476516, -2589.791370405184, -1476.2294789980579, -397.35356606080904, -743.7765730306646, -960.2764537657747, -997.1578775212904, -282.13053156454725, -872.3453120265341, -638.0378790535623, -978.9242833929319, -649.6238532343806, -703.1448345880093, -1153.2783450462478, -783.2059188909298, -326.7512865972357, -939.9261742373074, -558.5938020034572, -891.1067842686642, -576.8732969475506, -1151.2280917826433, -609.4004802863634, -855.2280507489211, -786.2463855441727, -698.6471480130481, -438.8381782930563, -932.1850410046911, -1142.5690671767313, -952.0772619014307, -1378.6498273524703, -729.5132965766448, -574.8627042208965, -847.9550078783083, -1313.1807524648727, -1805.3232883880503, -592.1143650700233, -792.186183223773, -875.8153192818955, -1638.2567733859667, -1143.693919700248, -1587.2408595206646, -633.686583089708, -993.2681588857313, -1377.2510366447495, -1181.8552122556018, -75.00530364402908, -1098.4812696245988], "episode_lengths": [494, 294, 90, 115, 88, 395, 344, 457, 436, 220, 158, 369, 261, 121, 158, 235, 136, 203, 218, 135, 228, 152, 103, 194, 109, 118, 124, 136, 165, 133, 156, 296, 109, 179, 293, 163, 118, 248, 417, 338, 80, 143, 82, 334, 265, 135, 118, 206, 245, 227, 214, 140, 131, 275, 161, 24, 146], "policy_AGENT-2_reward": [15.518150421736268, -97.78954607682786, -33.975962374106594, -92.77318915019072, -86.58591310565734, -96.51841741068898, 14.807812509623377, -89.88499108882411, 14.499973968763323, -96.17968843900228, 15.585032066387418, -98.87418082474308, 13.372710900237367, 11.83371375837186, -97.28434426171552, 14.573158586915827, -95.69793404694883, 15.352813267224317, -90.94149474703477, 11.717990160328442, -94.93186773567103, 14.13667593777635, -87.52169676214767, 14.465815919597192, -96.90608607997862, 14.293757352849038, -92.81081956667973, 15.180343591518536, -97.87419655378619, 14.60085513497432, -95.3354748422849, 12.33697082496993, -98.15176555934393, 14.414185810810688, -97.71990096670922, 12.939684327583413, -97.02843692525911, 13.563055238103868, -87.80094690241052, 15.072776970236124, -223.14032987936935, 14.300643503498558, -91.2754412305666, 14.125871473666908, -92.12218762031071, 15.677582875320663, -94.32298369511177, 14.056187565428523, -96.65005643987318, 15.694148525611778, -100.23461447445797, 12.918877765802035, -90.02981368642006, 13.868121182182938, -95.2200152861725, 15.318877650805634, -92.39418780922348], "policy_AGENT-3_reward": [-250.67677256052949, -941.83940367622, -133.66256426843657, -346.28538469228766, -114.35651101939206, -1234.8992072468775, -903.3277560075409, -1215.2508224745677, -359.53558560299354, -750.988682505857, -405.43805993988974, -1176.6246852197125, -767.4626125777287, -190.6929437521545, -292.61418653049674, -476.5604042063483, -385.07206233618507, -174.01969667876708, -329.43514199357656, -314.00182401461245, -407.40762668500616, -319.7883186454811, -247.28055813807356, -591.138701095444, -278.8596319999658, -162.27390676044564, -356.801023555384, -277.3580733871353, -323.6584371485504, -283.7297064482881, -464.00776476393315, -336.66176216221845, -310.0423459623935, -425.1057702951154, -270.60277063525206, -211.8793996560605, -349.9133774288299, -596.2469445780563, -380.73604421309403, -682.4379183963424, -258.26321743624015, -285.6840577693747, -332.7391033653822, -682.0621445792096, -791.7800298967721, -294.6297074769992, -319.88129079347294, -433.88684290889927, -702.8418950068375, -570.1798962099682, -709.5551700334995, -346.7103375233228, -390.2032864178595, -718.0652417215301, -478.77483519194834, -52.82820982313898, -440.01340745270016], "policy_AGENT-1_reward": [15.448787159575138, -97.80834193339965, -170.0308560219698, -92.67891089423006, -33.741435003746915, -96.51958853863655, 14.800130205819071, -89.82932623735209, 14.464811848614483, -96.17938436654774, 15.48892893951911, -98.96637116448542, 13.417196279990533, 11.90864310824021, -97.4437082092717, 14.592326722757267, -95.78162499551547, 15.305629428625798, -90.97950916082316, 11.795340325199748, -94.9639930849516, 14.144809802687956, -87.52219267460413, 14.355336687533518, -97.00218007670625, 14.282838130412946, -92.75848331651093, 15.11435464698445, -97.9178953955522, 14.548498129567172, -95.4245594725812, 12.35845320461291, -98.16306878225592, 14.453919501323744, -97.6604851511485, 12.948441728087182, -97.02982261792158, 13.617255163230087, -87.82008199678168, 15.091510186417107, -124.101451077444, 14.282647688914121, -91.32418052051413, 14.113940249136734, -91.99246791463935, 15.638520405411079, -94.219987515773, 14.13335570889931, -96.61608869091889, 15.631267961138722, -100.36905251873266, 12.917136956702715, -90.02190796234305, 13.863785425090033, -95.23252767907503, 15.268276295131951, -92.25871481172476], "policy_AGENT-0_reward": [-259.5973555787795, -977.8459619446048, -34.033919208407355, -298.636125737457, -33.871397113227545, -1274.7871394715826, -873.0091247017552, -1166.3283205904652, -378.84956672431844, -786.7174863000998, -437.8747309136688, -1215.3261331962433, -735.5567736005594, -230.40297917526686, -256.43433402918134, -512.8815348690997, -420.6062561426414, -138.7692775816305, -360.98916612509925, -347.5493855244781, -381.62079588730245, -358.1170203293635, -280.82038701318385, -590.9607965579338, -310.43802073427895, -193.05397532005205, -397.5558477987333, -311.53042685482495, -371.65625517077495, -322.2929437638039, -496.4602927038428, -297.4341421537277, -348.8708704449276, -390.00872056119135, -232.6639912599384, -252.84690469266639, -388.21340403268056, -573.5024330000069, -395.7201887891436, -726.3761961127824, -124.00829818359077, -317.7619376439343, -332.61628276184575, -659.3584196084662, -829.4286029563259, -328.80076087375585, -283.76192121941546, -470.11801964732445, -742.1487332483349, -604.8394399770298, -677.0820224939739, -312.81226028889085, -423.0131508191079, -686.9177015304911, -512.6278340984057, -52.76424776682768, -473.8149595509503]}, "sampler_perf": {"mean_env_wait_ms": 28.364353173095672, "mean_processing_ms": 1.3726868863732067, "mean_inference_ms": 1.2739376974535828}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 52000, "timers": {"sample_time_ms": 124924.535, "sample_throughput": 32.019, "load_time_ms": 284.932, "load_throughput": 14038.427, "learn_time_ms": 5476.767, "learn_throughput": 730.358, "update_time_ms": 5.343}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.9932947158813477, "policy_loss": -0.04131283238530159, "vf_loss": 3.0296337604522705, "vf_explained_var": 0.9874717593193054, "kl": 0.024869894608855247, "entropy": 0.8614518642425537, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 39.880916595458984, "policy_loss": -0.04464332386851311, "vf_loss": 39.92399597167969, "vf_explained_var": 0.7749649882316589, "kl": 0.007821275852620602, "entropy": 1.3321912288665771, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 47.86127853393555, "policy_loss": -0.033447157591581345, "vf_loss": 47.893341064453125, "vf_explained_var": 0.8000407218933105, "kl": 0.006944372784346342, "entropy": 1.316800832748413, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 6.577946662902832, "policy_loss": -0.04163568466901779, "vf_loss": 6.614393711090088, "vf_explained_var": 0.9601911306381226, "kl": 0.017293764278292656, "entropy": 0.9435971975326538, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 52000, "num_steps_trained": 52000}, "done": false, "episodes_total": 422, "training_iteration": 13, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-32-37", "timestamp": 1638383557, "time_this_iter_s": 127.15159034729004, "time_total_s": 1819.045398235321, "pid": 60632, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f849a3b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f851a9e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8621290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f85fc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8621290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f85fc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8621290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f85fc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f8621290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f852d320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f85fc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f84e6d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f83d8950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 394.5196478366852, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 18.1672131147541, "ram_util_percent": 91.10000000000002}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -75.00530364402908, "episode_reward_min": -3263.3020845507963, "episode_reward_mean": -1168.2284062531085, "episode_len_mean": 235.1764705882353, "episodes_this_iter": 11, "policy_reward_min": {"AGENT-3": -1551.3960041984205, "AGENT-0": -1523.8832001522956, "AGENT-2": -223.14032987936935, "AGENT-1": -170.0308560219698}, "policy_reward_max": {"AGENT-3": -52.82820982313898, "AGENT-0": -33.871397113227545, "AGENT-2": 15.694148525611778, "AGENT-1": 15.638520405411079}, "policy_reward_mean": {"AGENT-3": -537.8897320007662, "AGENT-0": -541.9547965345957, "AGENT-2": -44.304910715431895, "AGENT-1": -44.07896700231423}, "custom_metrics": {"mean_ego_speed_mean": 25.24469852941176, "mean_ego_speed_min": 11.522000000000002, "mean_ego_speed_max": 43.779999999999994, "distance_travelled_mean": 57.52406617647059, "distance_travelled_min": 23.276249999999997, "distance_travelled_max": 61.70175}, "hist_stats": {"episode_reward": [-2522.2154311051804, -2525.3892750782325, -2893.3964125313682, -2666.310855895116, -2961.8153464086136, -546.1920921689652, -724.0540346282752, -2451.889186631992, -835.6369193363973, -998.3489974838878, -3263.3020845507963, -397.35356606080904, -743.7765730306646, -960.2764537657747, -997.1578775212904, -282.13053156454725, -872.3453120265341, -638.0378790535623, -978.9242833929319, -649.6238532343806, -703.1448345880093, -1153.2783450462478, -783.2059188909298, -326.7512865972357, -939.9261742373074, -558.5938020034572, -891.1067842686642, -576.8732969475506, -1151.2280917826433, -609.4004802863634, -855.2280507489211, -786.2463855441727, -698.6471480130481, -438.8381782930563, -932.1850410046911, -1142.5690671767313, -952.0772619014307, -1378.6498273524703, -729.5132965766448, -574.8627042208965, -847.9550078783083, -1313.1807524648727, -1805.3232883880503, -592.1143650700233, -792.186183223773, -875.8153192818955, -1638.2567733859667, -1143.693919700248, -1587.2408595206646, -633.686583089708, -993.2681588857313, -1377.2510366447495, -1181.8552122556018, -75.00530364402908, -1098.4812696245988, -479.3071905579983, -2115.2832536310516, -371.70330187292035, -830.3736104741663, -268.55525624202386, -2702.7243526677817, -1746.7289379938525, -2561.293460391216, -709.4203665099352, -1730.0652416115056, -812.2388298476516, -2589.791370405184, -1476.2294789980579], "episode_lengths": [486, 374, 414, 509, 570, 529, 122, 494, 140, 171, 551, 121, 158, 235, 136, 203, 218, 135, 228, 152, 103, 194, 109, 118, 124, 136, 165, 133, 156, 296, 109, 179, 293, 163, 118, 248, 417, 338, 80, 143, 82, 334, 265, 135, 118, 206, 245, 227, 214, 140, 131, 275, 161, 24, 146, 494, 294, 90, 115, 88, 395, 344, 457, 436, 220, 158, 369, 261], "policy_AGENT-3_reward": [-1144.3776688093133, -1250.3959460658398, -1362.680618606484, -1372.2676449989235, -1407.3725402633202, -288.18148044630965, -289.0797130034023, -1220.2636167947685, -347.24915110465736, -496.46432889426205, -1551.3960041984205, -190.6929437521545, -292.61418653049674, -476.5604042063483, -385.07206233618507, -174.01969667876708, -329.43514199357656, -314.00182401461245, -407.40762668500616, -319.7883186454811, -247.28055813807356, -591.138701095444, -278.8596319999658, -162.27390676044564, -356.801023555384, -277.3580733871353, -323.6584371485504, -283.7297064482881, -464.00776476393315, -336.66176216221845, -310.0423459623935, -425.1057702951154, -270.60277063525206, -211.8793996560605, -349.9133774288299, -596.2469445780563, -380.73604421309403, -682.4379183963424, -258.26321743624015, -285.6840577693747, -332.7391033653822, -682.0621445792096, -791.7800298967721, -294.6297074769992, -319.88129079347294, -433.88684290889927, -702.8418950068375, -570.1798962099682, -709.5551700334995, -346.7103375233228, -390.2032864178595, -718.0652417215301, -478.77483519194834, -52.82820982313898, -440.01340745270016, -250.67677256052949, -941.83940367622, -133.66256426843657, -346.28538469228766, -114.35651101939206, -1234.8992072468775, -903.3277560075409, -1215.2508224745677, -359.53558560299354, -750.988682505857, -405.43805993988974, -1176.6246852197125, -767.4626125777287], "policy_AGENT-0_reward": [-1190.5271702299628, -1299.589146406713, -1335.9853877100954, -1321.798808091729, -1358.2032365960677, -285.78356399522403, -245.43727641341212, -1261.038010495898, -308.8771695063171, -529.718020376401, -1523.8832001522956, -230.40297917526686, -256.43433402918134, -512.8815348690997, -420.6062561426414, -138.7692775816305, -360.98916612509925, -347.5493855244781, -381.62079588730245, -358.1170203293635, -280.82038701318385, -590.9607965579338, -310.43802073427895, -193.05397532005205, -397.5558477987333, -311.53042685482495, -371.65625517077495, -322.2929437638039, -496.4602927038428, -297.4341421537277, -348.8708704449276, -390.00872056119135, -232.6639912599384, -252.84690469266639, -388.21340403268056, -573.5024330000069, -395.7201887891436, -726.3761961127824, -124.00829818359077, -317.7619376439343, -332.61628276184575, -659.3584196084662, -829.4286029563259, -328.80076087375585, -283.76192121941546, -470.11801964732445, -742.1487332483349, -604.8394399770298, -677.0820224939739, -312.81226028889085, -423.0131508191079, -686.9177015304911, -512.6278340984057, -52.76424776682768, -473.8149595509503, -259.5973555787795, -977.8459619446048, -34.033919208407355, -298.636125737457, -33.871397113227545, -1274.7871394715826, -873.0091247017552, -1166.3283205904652, -378.84956672431844, -786.7174863000998, -437.8747309136688, -1215.3261331962433, -735.5567736005594], "policy_AGENT-2_reward": [-93.68019854315438, 12.278316658153972, -97.34405468966257, 13.863883220922679, -98.10989756731347, 13.9109967039602, -94.77173561306476, 14.71675471443606, -89.78930739749603, 13.914565782556512, -93.97255566751565, 11.83371375837186, -97.28434426171552, 14.573158586915827, -95.69793404694883, 15.352813267224317, -90.94149474703477, 11.717990160328442, -94.93186773567103, 14.13667593777635, -87.52169676214767, 14.465815919597192, -96.90608607997862, 14.293757352849038, -92.81081956667973, 15.180343591518536, -97.87419655378619, 14.60085513497432, -95.3354748422849, 12.33697082496993, -98.15176555934393, 14.414185810810688, -97.71990096670922, 12.939684327583413, -97.02843692525911, 13.563055238103868, -87.80094690241052, 15.072776970236124, -223.14032987936935, 14.300643503498558, -91.2754412305666, 14.125871473666908, -92.12218762031071, 15.677582875320663, -94.32298369511177, 14.056187565428523, -96.65005643987318, 15.694148525611778, -100.23461447445797, 12.918877765802035, -90.02981368642006, 13.868121182182938, -95.2200152861725, 15.318877650805634, -92.39418780922348, 15.518150421736268, -97.78954607682786, -33.975962374106594, -92.77318915019072, -86.58591310565734, -96.51841741068898, 14.807812509623377, -89.88499108882411, 14.499973968763323, -96.17968843900228, 15.585032066387418, -98.87418082474308, 13.372710900237367], "policy_AGENT-1_reward": [-93.63039352274821, 12.317500736167503, -97.38635152513174, 13.89171397461156, -98.12967198191282, 13.861955568608392, -94.76530959839553, 14.695685944236857, -89.72129132792702, 13.918786004218378, -94.05032453256071, 11.90864310824021, -97.4437082092717, 14.592326722757267, -95.78162499551547, 15.305629428625798, -90.97950916082316, 11.795340325199748, -94.9639930849516, 14.144809802687956, -87.52219267460413, 14.355336687533518, -97.00218007670625, 14.282838130412946, -92.75848331651093, 15.11435464698445, -97.9178953955522, 14.548498129567172, -95.4245594725812, 12.35845320461291, -98.16306878225592, 14.453919501323744, -97.6604851511485, 12.948441728087182, -97.02982261792158, 13.617255163230087, -87.82008199678168, 15.091510186417107, -124.101451077444, 14.282647688914121, -91.32418052051413, 14.113940249136734, -91.99246791463935, 15.638520405411079, -94.219987515773, 14.13335570889931, -96.61608869091889, 15.631267961138722, -100.36905251873266, 12.917136956702715, -90.02190796234305, 13.863785425090033, -95.23252767907503, 15.268276295131951, -92.25871481172476, 15.448787159575138, -97.80834193339965, -170.0308560219698, -92.67891089423006, -33.741435003746915, -96.51958853863655, 14.800130205819071, -89.82932623735209, 14.464811848614483, -96.17938436654774, 15.48892893951911, -98.96637116448542, 13.417196279990533]}, "sampler_perf": {"mean_env_wait_ms": 28.451899180013633, "mean_processing_ms": 1.331431865241444, "mean_inference_ms": 1.2720736991523462}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 56000, "timers": {"sample_time_ms": 125359.281, "sample_throughput": 31.908, "load_time_ms": 216.066, "load_throughput": 18512.862, "learn_time_ms": 5392.692, "learn_throughput": 741.745, "update_time_ms": 5.384}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 1.6240990161895752, "policy_loss": -0.03396736457943916, "vf_loss": 1.6544523239135742, "vf_explained_var": 0.99106764793396, "kl": 0.012046734802424908, "entropy": 0.822471022605896, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 25.337106704711914, "policy_loss": -0.03611142560839653, "vf_loss": 25.371784210205078, "vf_explained_var": 0.8990911245346069, "kl": 0.00716883921995759, "entropy": 1.3309484720230103, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 25.181699752807617, "policy_loss": -0.043335821479558945, "vf_loss": 25.22384262084961, "vf_explained_var": 0.9003876447677612, "kl": 0.0059623075649142265, "entropy": 1.3343968391418457, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 4.384147644042969, "policy_loss": -0.04089559242129326, "vf_loss": 4.420574188232422, "vf_explained_var": 0.9714761972427368, "kl": 0.01489529199898243, "entropy": 0.8579707145690918, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 56000, "num_steps_trained": 56000}, "done": false, "episodes_total": 433, "training_iteration": 14, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-34-49", "timestamp": 1638383689, "time_this_iter_s": 131.83548045158386, "time_total_s": 1950.880878686905, "pid": 60632, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f83d8e60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f83d8b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83c5290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83c53b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83c54d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83c55f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83c5290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83c53b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83c54d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83c55f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83c5290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83c53b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83c54d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83c55f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83c5290>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83c53b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83c54d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83c55f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f845a0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 526.355128288269, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 18.15691489361702, "ram_util_percent": 91.10372340425536}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -307.361612267589, "episode_reward_min": -3453.443739646122, "episode_reward_mean": -2437.597358994719, "episode_len_mean": 414.5, "episodes_this_iter": 8, "policy_reward_min": {"AGENT-0": -1605.915813976947, "AGENT-3": -1657.6774840146063, "AGENT-2": -103.06749259205907, "AGENT-1": -103.2113827247297}, "policy_reward_max": {"AGENT-0": -126.1413482447828, "AGENT-3": -126.14275526460419, "AGENT-2": -24.21194013526126, "AGENT-1": -24.323885637609997}, "policy_reward_mean": {"AGENT-0": -1145.178781888727, "AGENT-3": -1168.5280673084749, "AGENT-2": -61.92239271110566, "AGENT-1": -61.96811708641255}, "custom_metrics": {"mean_ego_speed_mean": 21.49696875, "mean_ego_speed_min": 13.163, "mean_ego_speed_max": 37.589, "distance_travelled_mean": 47.48684375, "distance_travelled_min": 25.782, "distance_travelled_max": 60.969500000000004}, "hist_stats": {"episode_reward": [-2223.5850728506134, -1587.3832139963795, -2437.4159707421045, -307.361612267589, -3453.443739646122, -2805.7238855061046, -3383.0815935524156, -3302.7837833964195], "episode_lengths": [320, 364, 344, 36, 491, 765, 432, 564], "policy_AGENT-0_reward": [-1008.6236486895634, -769.2925853361295, -1119.9375846617515, -126.1413482447828, -1605.915813976947, -1350.853508778611, -1578.4631453349234, -1602.2026200871073], "policy_AGENT-3_reward": [-1008.6825488442571, -769.5548028873793, -1130.497381455677, -126.14275526460419, -1657.6774840146063, -1401.2435486627392, -1603.4649588332122, -1650.9610585053235], "policy_AGENT-2_reward": [-103.06749259205907, -24.21194013526126, -93.46629171146128, -27.550197030839634, -94.96449019129744, -26.784337678002583, -100.49297671190479, -24.841415638019168], "policy_AGENT-1_reward": [-103.2113827247297, -24.323885637609997, -93.5147129132202, -27.527311727362367, -94.8859514632691, -26.842490386754747, -100.66051267237943, -24.778689165974832]}, "sampler_perf": {"mean_env_wait_ms": 30.882632485093907, "mean_processing_ms": 0.6788669601436615, "mean_inference_ms": 1.3903920217264714}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 60000, "timers": {"sample_time_ms": 132281.589, "sample_throughput": 30.239, "load_time_ms": 798.108, "load_throughput": 5011.852, "learn_time_ms": 6817.843, "learn_throughput": 586.696, "update_time_ms": 5.757}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.964684963226318, "policy_loss": -0.023106742650270462, "vf_loss": 4.985496997833252, "vf_explained_var": 0.9621660709381104, "kl": 0.011475223116576672, "entropy": 0.6673856377601624, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 45.22639465332031, "policy_loss": -0.03984236344695091, "vf_loss": 45.26310729980469, "vf_explained_var": 0.44315004348754883, "kl": 0.01566094160079956, "entropy": 1.352837324142456, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 53.611839294433594, "policy_loss": -0.05850818753242493, "vf_loss": 53.66636657714844, "vf_explained_var": 0.5490342974662781, "kl": 0.01990574225783348, "entropy": 1.342986822128296, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.799924850463867, "policy_loss": -0.024617746472358704, "vf_loss": 9.821480751037598, "vf_explained_var": 0.9594417810440063, "kl": 0.015309198759496212, "entropy": 0.6287994980812073, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 60000, "num_steps_trained": 60000}, "done": false, "episodes_total": 441, "training_iteration": 15, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-37-50", "timestamp": 1638383870, "time_this_iter_s": 142.3227243423462, "time_total_s": 2093.203603029251, "pid": 60874, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f849aef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f83d89e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83863b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8386290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8386170>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83863b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8386290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8386170>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83863b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8386290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8386170>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f84e9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f83863b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8386290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8386170>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f839f8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 142.3227243423462, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.587864077669906, "ram_util_percent": 92.9621359223301}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -307.361612267589, "episode_reward_min": -4715.227142105473, "episode_reward_mean": -2850.141419582007, "episode_len_mean": 549.7142857142857, "episodes_this_iter": 6, "policy_reward_min": {"AGENT-0": -2285.9484588064124, "AGENT-3": -2238.067341569322, "AGENT-2": -103.06749259205907, "AGENT-1": -103.2113827247297}, "policy_reward_max": {"AGENT-0": -126.1413482447828, "AGENT-3": -126.14275526460419, "AGENT-2": -24.21194013526126, "AGENT-1": -24.323885637609997}, "policy_reward_mean": {"AGENT-0": -1354.2329767795381, "AGENT-3": -1371.3405813470963, "AGENT-2": -62.27389807611801, "AGENT-1": -62.293963379256304}, "custom_metrics": {"mean_ego_speed_mean": 19.77885714285714, "mean_ego_speed_min": 12.5415, "mean_ego_speed_max": 37.589, "distance_travelled_mean": 50.95658928571428, "distance_travelled_min": 25.782, "distance_travelled_max": 61.1595}, "hist_stats": {"episode_reward": [-3149.2216454104105, -2999.0104674251434, -4715.227142105473, -3624.1146305042703, -2437.5253071365014, -3476.1018096085472, -2223.5850728506134, -1587.3832139963795, -2437.4159707421045, -307.361612267589, -3453.443739646122, -2805.7238855061046, -3383.0815935524156, -3302.7837833964195], "episode_lengths": [695, 912, 738, 854, 369, 812, 320, 364, 344, 36, 491, 765, 432, 564], "policy_AGENT-0_reward": [-1449.2889914817863, -1446.3185153178713, -2285.9484588064124, -1810.022344402602, -1120.4521280111583, -1685.8009817838881, -1008.6236486895634, -769.2925853361295, -1119.9375846617515, -126.1413482447828, -1605.915813976947, -1350.853508778611, -1578.4631453349234, -1602.2026200871073], "policy_AGENT-3_reward": [-1498.688809252255, -1497.599594294826, -2238.067341569322, -1760.5022164281609, -1120.5507590260395, -1735.1348798209451, -1008.6825488442571, -769.5548028873793, -1130.497381455677, -126.14275526460419, -1657.6774840146063, -1401.2435486627392, -1603.4649588332122, -1650.9610585053235], "policy_AGENT-2_reward": [-100.59939446244535, -27.560871648396066, -95.60242509581374, -26.828953446357765, -98.25397124462933, -27.609815479164542, -103.06749259205907, -24.21194013526126, -93.46629171146128, -27.550197030839634, -94.96449019129744, -26.784337678002583, -100.49297671190479, -24.841415638019168], "policy_AGENT-1_reward": [-100.64445021391563, -27.531486164048896, -95.60891663393832, -26.761116227148072, -98.26844885467443, -27.556132524562514, -103.2113827247297, -24.323885637609997, -93.5147129132202, -27.527311727362367, -94.8859514632691, -26.842490386754747, -100.66051267237943, -24.778689165974832]}, "sampler_perf": {"mean_env_wait_ms": 30.81686824222972, "mean_processing_ms": 0.6660716174092893, "mean_inference_ms": 1.3702220541997767}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 64000, "timers": {"sample_time_ms": 131175.929, "sample_throughput": 30.493, "load_time_ms": 405.419, "load_throughput": 9866.348, "learn_time_ms": 6074.76, "learn_throughput": 658.462, "update_time_ms": 5.18}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.10444712638855, "policy_loss": -0.019331879913806915, "vf_loss": 3.1217949390411377, "vf_explained_var": 0.9730592370033264, "kl": 0.0099199078977108, "entropy": 0.5537686944007874, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 22.942668914794922, "policy_loss": -0.15442872047424316, "vf_loss": 23.095447540283203, "vf_explained_var": 0.6273869872093201, "kl": 0.008263150230050087, "entropy": 1.3445770740509033, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 46.059593200683594, "policy_loss": -0.037242744117975235, "vf_loss": 46.093563079833984, "vf_explained_var": 0.6303590536117554, "kl": 0.01636158674955368, "entropy": 1.3185131549835205, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.1036248207092285, "policy_loss": -0.02106223814189434, "vf_loss": 4.122395038604736, "vf_explained_var": 0.9690309166908264, "kl": 0.011460227891802788, "entropy": 0.4816668927669525, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 64000, "num_steps_trained": 64000}, "done": false, "episodes_total": 447, "training_iteration": 16, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-40-06", "timestamp": 1638384006, "time_this_iter_s": 135.4331784248352, "time_total_s": 2228.6367814540863, "pid": 60874, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f839f950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f839fa70>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839fcb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f839fef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839fcb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f839fef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839fcb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f839fef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839fcb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f839fef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f839f710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 277.7559027671814, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 18.258549222797924, "ram_util_percent": 93.13108808290157}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -307.361612267589, "episode_reward_min": -4715.227142105473, "episode_reward_mean": -3084.102588652872, "episode_len_mean": 640.2222222222222, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-0": -2285.9484588064124, "AGENT-3": -2238.067341569322, "AGENT-2": -103.06749259205907, "AGENT-1": -103.2113827247297}, "policy_reward_max": {"AGENT-0": -126.1413482447828, "AGENT-3": -126.14275526460419, "AGENT-2": -24.21194013526126, "AGENT-1": -24.323885637609997}, "policy_reward_mean": {"AGENT-0": -1471.9922156376588, "AGENT-3": -1488.1146169902381, "AGENT-2": -61.99185482093112, "AGENT-1": -62.003901204045455}, "custom_metrics": {"mean_ego_speed_mean": 20.107041666666667, "mean_ego_speed_min": 12.5415, "mean_ego_speed_max": 37.589, "distance_travelled_mean": 51.168875, "distance_travelled_min": 25.782, "distance_travelled_max": 61.1595}, "hist_stats": {"episode_reward": [-3519.4810471770293, -4158.631884211986, -4117.879869154978, -3815.8739210596104, -2223.5850728506134, -1587.3832139963795, -2437.4159707421045, -307.361612267589, -3453.443739646122, -2805.7238855061046, -3383.0815935524156, -3302.7837833964195, -3149.2216454104105, -2999.0104674251434, -4715.227142105473, -3624.1146305042703, -2437.5253071365014, -3476.1018096085472], "episode_lengths": [831, 999, 999, 999, 320, 364, 344, 36, 491, 765, 432, 564, 695, 912, 738, 854, 369, 812], "policy_AGENT-0_reward": [-1638.885905920319, -2054.1749386845977, -1962.5350679689732, -1881.0022939904336, -1008.6236486895634, -769.2925853361295, -1119.9375846617515, -126.1413482447828, -1605.915813976947, -1350.853508778611, -1578.4631453349234, -1602.2026200871073, -1449.2889914817863, -1446.3185153178713, -2285.9484588064124, -1810.022344402602, -1120.4521280111583, -1685.8009817838881], "policy_AGENT-3_reward": [-1688.8891464807728, -2054.4947631071295, -1962.7776016207122, -1881.1334557563302, -1008.6825488442571, -769.5548028873793, -1130.497381455677, -126.14275526460419, -1657.6774840146063, -1401.2435486627392, -1603.4649588332122, -1650.9610585053235, -1498.688809252255, -1497.599594294826, -2238.067341569322, -1760.5022164281609, -1120.5507590260395, -1735.1348798209451], "policy_AGENT-2_reward": [-95.87962024178222, -24.972795260220998, -96.28411632186766, -26.88228188723731, -103.06749259205907, -24.21194013526126, -93.46629171146128, -27.550197030839634, -94.96449019129744, -26.784337678002583, -100.49297671190479, -24.841415638019168, -100.59939446244535, -27.560871648396066, -95.60242509581374, -26.828953446357765, -98.25397124462933, -27.609815479164542], "policy_AGENT-1_reward": [-95.82637453416885, -24.989387160043478, -96.28308324340705, -26.855889425610613, -103.2113827247297, -24.323885637609997, -93.5147129132202, -27.527311727362367, -94.8859514632691, -26.842490386754747, -100.66051267237943, -24.778689165974832, -100.64445021391563, -27.531486164048896, -95.60891663393832, -26.761116227148072, -98.26844885467443, -27.556132524562514]}, "sampler_perf": {"mean_env_wait_ms": 30.770051078604936, "mean_processing_ms": 0.6501536916792896, "mean_inference_ms": 1.3588912095540502}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 68000, "timers": {"sample_time_ms": 130305.213, "sample_throughput": 30.697, "load_time_ms": 273.984, "load_throughput": 14599.416, "learn_time_ms": 5846.32, "learn_throughput": 684.191, "update_time_ms": 5.177}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 1.7513505220413208, "policy_loss": -0.014781170524656773, "vf_loss": 1.7646458148956299, "vf_explained_var": 0.9860585331916809, "kl": 0.007429609540849924, "entropy": 0.3290642499923706, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 1.7363152503967285, "policy_loss": -0.019070520997047424, "vf_loss": 1.753544569015503, "vf_explained_var": 0.9845371246337891, "kl": 0.009205326437950134, "entropy": 0.32313260436058044, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 36.344722747802734, "policy_loss": -0.07107438147068024, "vf_loss": 36.41393280029297, "vf_explained_var": 0.6126881837844849, "kl": 0.00933083239942789, "entropy": 1.34488844871521, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 50.47206497192383, "policy_loss": 0.026703566312789917, "vf_loss": 50.443115234375, "vf_explained_var": 0.6469022035598755, "kl": 0.011227527633309364, "entropy": 1.3362500667572021, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 68000, "num_steps_trained": 68000}, "done": false, "episodes_total": 451, "training_iteration": 17, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-42-21", "timestamp": 1638384141, "time_this_iter_s": 133.98410320281982, "time_total_s": 2362.620884656906, "pid": 60874, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f83bfb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f839f440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839f830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a8c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839f830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a8c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839f830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a8c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f839f830>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f839f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f849aef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f849a8c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f83b2440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 411.7400059700012, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 18.313471502590673, "ram_util_percent": 93.24507772020726}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": -307.361612267589, "episode_reward_min": -4715.227142105473, "episode_reward_mean": -3283.644267330847, "episode_len_mean": 684.5909090909091, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-0": -2285.9484588064124, "AGENT-3": -2238.067341569322, "AGENT-2": -103.06749259205907, "AGENT-1": -103.2113827247297}, "policy_reward_max": {"AGENT-0": -126.1413482447828, "AGENT-3": -126.14275526460419, "AGENT-2": -22.140524543447697, "AGENT-1": -22.156323100383474}, "policy_reward_mean": {"AGENT-0": -1570.9949468739103, "AGENT-3": -1589.7557712691616, "AGENT-2": -61.44356190841675, "AGENT-1": -61.44998727935833}, "custom_metrics": {"mean_ego_speed_mean": 19.487863636363638, "mean_ego_speed_min": 11.75075, "mean_ego_speed_max": 37.589, "distance_travelled_mean": 52.420181818181824, "distance_travelled_min": 25.782, "distance_travelled_max": 61.1595}, "hist_stats": {"episode_reward": [-4031.8245136537666, -4276.267500144081, -4447.338541379734, -3970.8967303493446, -2223.5850728506134, -1587.3832139963795, -2437.4159707421045, -307.361612267589, -3453.443739646122, -2805.7238855061046, -3383.0815935524156, -3302.7837833964195, -3149.2216454104105, -2999.0104674251434, -4715.227142105473, -3624.1146305042703, -2437.5253071365014, -3476.1018096085472, -3519.4810471770293, -4158.631884211986, -4117.879869154978, -3815.8739210596104], "episode_lengths": [765, 964, 809, 999, 320, 364, 344, 36, 491, 765, 432, 564, 695, 912, 738, 854, 369, 812, 831, 999, 999, 999], "policy_AGENT-0_reward": [-1894.4112977176835, -2088.3830771719045, -2120.057434517524, -1963.1771403410573, -1008.6236486895634, -769.2925853361295, -1119.9375846617515, -126.1413482447828, -1605.915813976947, -1350.853508778611, -1578.4631453349234, -1602.2026200871073, -1449.2889914817863, -1446.3185153178713, -2285.9484588064124, -1810.022344402602, -1120.4521280111583, -1685.8009817838881, -1638.885905920319, -2054.1749386845977, -1962.5350679689732, -1881.0022939904336], "policy_AGENT-3_reward": [-1944.7200331531599, -2139.1575321437117, -2141.2635544359246, -1963.422742364467, -1008.6825488442571, -769.5548028873793, -1130.497381455677, -126.14275526460419, -1657.6774840146063, -1401.2435486627392, -1603.4649588332122, -1650.9610585053235, -1498.688809252255, -1497.599594294826, -2238.067341569322, -1760.5022164281609, -1120.5507590260395, -1735.1348798209451, -1688.8891464807728, -2054.4947631071295, -1962.7776016207122, -1881.1334557563302], "policy_AGENT-2_reward": [-96.35999627456756, -24.388452217734805, -93.01600217265832, -22.140524543447697, -103.06749259205907, -24.21194013526126, -93.46629171146128, -27.550197030839634, -94.96449019129744, -26.784337678002583, -100.49297671190479, -24.841415638019168, -100.59939446244535, -27.560871648396066, -95.60242509581374, -26.828953446357765, -98.25397124462933, -27.609815479164542, -95.87962024178222, -24.972795260220998, -96.28411632186766, -26.88228188723731], "policy_AGENT-1_reward": [-96.33318650833705, -24.338438610712515, -93.00155025363195, -22.156323100383474, -103.2113827247297, -24.323885637609997, -93.5147129132202, -27.527311727362367, -94.8859514632691, -26.842490386754747, -100.66051267237943, -24.778689165974832, -100.64445021391563, -27.531486164048896, -95.60891663393832, -26.761116227148072, -98.26844885467443, -27.556132524562514, -95.82637453416885, -24.989387160043478, -96.28308324340705, -26.855889425610613]}, "sampler_perf": {"mean_env_wait_ms": 30.747780203259484, "mean_processing_ms": 0.6371759094189184, "mean_inference_ms": 1.3506849188230403}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 72000, "timers": {"sample_time_ms": 130354.511, "sample_throughput": 30.686, "load_time_ms": 208.075, "load_throughput": 19223.795, "learn_time_ms": 5709.287, "learn_throughput": 700.613, "update_time_ms": 5.368}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.1925435066223145, "policy_loss": -0.015537860803306103, "vf_loss": 2.206430196762085, "vf_explained_var": 0.974054217338562, "kl": 0.008256854489445686, "entropy": 0.4163966476917267, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 2.435417890548706, "policy_loss": -0.015404555946588516, "vf_loss": 2.4498722553253174, "vf_explained_var": 0.9821938276290894, "kl": 0.004754040855914354, "entropy": 0.35012635588645935, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 15.726333618164062, "policy_loss": -0.19077157974243164, "vf_loss": 15.916027069091797, "vf_explained_var": 0.7867275476455688, "kl": 0.005383198149502277, "entropy": 1.3469173908233643, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 34.17125701904297, "policy_loss": -0.12174646556377411, "vf_loss": 34.29067611694336, "vf_explained_var": 0.7494333982467651, "kl": 0.011675218120217323, "entropy": 1.3231608867645264, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 72000, "num_steps_trained": 72000}, "done": false, "episodes_total": 455, "training_iteration": 18, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-44-37", "timestamp": 1638384277, "time_this_iter_s": 135.83297157287598, "time_total_s": 2498.453856229782, "pid": 60874, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f83b2680>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f83b2560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2170>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8348170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8348290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83483b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2170>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8348170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8348290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83483b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2170>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8348170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8348290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83483b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83b2170>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8348170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f8348290>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f83483b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f849ab00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 547.5729775428772, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 20.124742268041235, "ram_util_percent": 93.3185567010309}, "trial_id": "29e89_00000", "experiment_tag": "0"}
{"episode_reward_max": 2090.001717709853, "episode_reward_min": -90.24669442422122, "episode_reward_mean": 1322.8090040380298, "episode_len_mean": 335.27272727272725, "episodes_this_iter": 11, "policy_reward_min": {"AGENT-0": -34.27487726096196, "AGENT-2": -11.948884725819214, "AGENT-1": -11.764585074931396, "AGENT-3": -34.32854395024849}, "policy_reward_max": {"AGENT-0": 1032.5306075836475, "AGENT-2": 33.987510023119775, "AGENT-1": 33.91336563879317, "AGENT-3": 992.6130755804257}, "policy_reward_mean": {"AGENT-0": 662.3493541666685, "AGENT-2": 12.568684315325312, "AGENT-1": 12.590266856741694, "AGENT-3": 635.3006986992937}, "custom_metrics": {"mean_ego_speed_mean": 26.207977272727273, "mean_ego_speed_min": 13.63475, "mean_ego_speed_max": 36.539, "distance_travelled_mean": 50.16863636363637, "distance_travelled_min": 24.034499999999998, "distance_travelled_max": 60.98925}, "hist_stats": {"episode_reward": [1906.930123217097, 1928.4475029508162, 984.5125793790191, -78.47928109729331, 511.62700401351054, 1819.4156856001891, 1505.718612222492, 1920.2104845426686, 2052.761310304194, -90.24669442422122, 2090.001717709853], "episode_lengths": [394, 545, 375, 32, 108, 560, 295, 570, 326, 30, 453], "policy_AGENT-0_reward": [940.7738527245374, 995.0680620726799, 482.08632372304663, -28.67010652804723, 221.823561054638, 935.192528589139, 739.262434965594, 992.1626940146836, 1009.8878148943979, -34.27487726096196, 1032.5306075836475], "policy_AGENT-2_reward": [32.828962101981816, -11.491837893237074, 30.1798181602255, -10.491893194351729, 33.987510023119775, -11.18682724768298, 33.104505667338046, -11.948884725819214, 31.731393658775033, -10.92557063383478, 32.46835155206403], "policy_AGENT-1_reward": [32.77783372201827, -11.436462094921795, 30.154065886222714, -10.470917529730968, 33.91336563879317, -11.120299478253276, 33.076596077357614, -11.764585074931396, 31.691357863065665, -10.71770257917601, 32.38968299371466], "policy_AGENT-3_reward": [900.5494746685599, 956.3077408662949, 442.0923716095267, -28.84636384516337, 221.90256729695983, 906.5302837369837, 700.2750755122019, 951.761260328735, 979.4507438879555, -34.32854395024849, 992.6130755804257]}, "sampler_perf": {"mean_env_wait_ms": 30.40569235580738, "mean_processing_ms": 0.7943743558205297, "mean_inference_ms": 1.3858956773410405}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 76000, "timers": {"sample_time_ms": 130865.865, "sample_throughput": 30.566, "load_time_ms": 809.999, "load_throughput": 4938.276, "learn_time_ms": 6751.015, "learn_throughput": 592.504, "update_time_ms": 5.193}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.316883563995361, "policy_loss": -0.021243909373879433, "vf_loss": 4.335925579071045, "vf_explained_var": 0.9599287509918213, "kl": 0.01101160328835249, "entropy": 0.6298560500144958, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.614054203033447, "policy_loss": -0.0886959657073021, "vf_loss": 6.70084285736084, "vf_explained_var": 0.9413012266159058, "kl": 0.00953244511038065, "entropy": 1.2589337825775146, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 15.03538703918457, "policy_loss": -0.06769533455371857, "vf_loss": 15.099749565124512, "vf_explained_var": 0.7787513136863708, "kl": 0.01666313037276268, "entropy": 1.3606295585632324, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.285845994949341, "policy_loss": -0.03229353576898575, "vf_loss": 3.3145883083343506, "vf_explained_var": 0.9642767906188965, "kl": 0.017754610627889633, "entropy": 0.8169394731521606, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 76000, "num_steps_trained": 76000}, "done": false, "episodes_total": 466, "training_iteration": 19, "experiment_id": "cedaba75a69448cabeaa4cd1ba1389b3", "date": "2021-12-01_13-48-42", "timestamp": 1638384522, "time_this_iter_s": 140.8739161491394, "time_total_s": 2639.3277723789215, "pid": 61848, "hostname": "sam-Precision-Tower-5810", "node_ip": "10.116.70.179", "config": {"num_workers": 1, "num_envs_per_worker": 1, "rollout_fragment_length": 200, "sample_batch_size": -1, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"conv_filters": null, "conv_activation": "relu", "fcnet_activation": "tanh", "fcnet_hiddens": [256, 256], "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "state_shape": null, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "custom_options": -1}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f99f849a8c0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f99f8386c20>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f9b88a10b00>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/home/semantibasu/smarts_new/SMARTS/benchmark/scenarios/intersections/4lane"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83867a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8386f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83860e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8369290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83867a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8386f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83860e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8369290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83867a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8386f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83860e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8369290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f99f83867a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f99f8386f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f99f83860e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f99f8369290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "no_eager_on_workers": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f99f8366cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "replay_sequence_length": 1, "use_pytorch": -1, "eager": -1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 140.8739161491394, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.83578431372549, "ram_util_percent": 94.65441176470588}, "trial_id": "29e89_00000", "experiment_tag": "0"}
